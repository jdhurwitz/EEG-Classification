{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sNbiI9AOPlq6"
   },
   "source": [
    "# Neural Network Testing Framework\n",
    "This notebook is intended to be a general framework for testing Neural Neworks on the EEG data set. While the initial iteration of this notebook is used for a simple Convolutional Neural Network (CNN), other networks using PyTorch can be implemented and assigned to the neural network variable. Many of the beginning cells are used to intialize for a Google Drive Colaboratory notebook GPU usability and can be ignored as necessary.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2hlystw2Pzbg"
   },
   "source": [
    "## Initialization\n",
    "Google Drive access, PyTorch, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "aEly-WUNrG_n"
   },
   "outputs": [],
   "source": [
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_ioKx_tQsFg"
   },
   "source": [
    "This section provides access to the user's Google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "output_extras": [
      {
       "item_id": 4
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18486,
     "status": "ok",
     "timestamp": 1521440181161,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "nyJiSCniN5Sn",
    "outputId": "d73f8117-bc7a-404e-9689-4fe00c4efd06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
      "··········\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "Please enter the verification code: Access token retrieved correctly.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eADEBx-EQNg5"
   },
   "source": [
    "This section creates a drive that links to the user's Google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "YzXqllGHQK6E"
   },
   "outputs": [],
   "source": [
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jUfqAB83QuPc"
   },
   "source": [
    "This section installs PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "vS4vRAnsQw2J"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-rpQls3uI1M7"
   },
   "source": [
    "This section installs keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "output_extras": [
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2055,
     "status": "ok",
     "timestamp": 1521440219782,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "IZCK_1IgIzBt",
    "outputId": "991bee61-491c-4d99-951a-2993984979bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LaZWU_TlQ7Yx"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uo96B36sQURz"
   },
   "source": [
    "Imports can be added as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UgT3bxtlRT0U"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.cuda\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "j_c_F9ulNdAU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "grHWp1FlZm-x"
   },
   "source": [
    "## Flags and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "HuD3UwNQYPwG"
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RoLPc0SzSM2_"
   },
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "55Aaa8JmQZpb"
   },
   "source": [
    "### EEGDataset\n",
    "This class inherits the torch.utils.data.Dataset class to be used with the torch.utils.data.Dataloader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 232,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 349,
     "status": "error",
     "timestamp": 1521428637964,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "ak2uqN0pSPZL",
    "outputId": "201ea787-6b8f-473c-d0ea-3583e7485121"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fcbb0552131e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mEEGDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;34m\"\"\"EEG dataset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class EEGDataset(Dataset):\n",
    "  \"\"\"EEG dataset.\"\"\"\n",
    "  \n",
    "  def __init__(self, x, y, transform=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      x (numpy array): Input data of shape \n",
    "                       num_trials x num_electrodes x num_time_bins.\n",
    "      y (numpy array): Output data of shape num_trials x 1.\n",
    "      transform (callable, optional): Optional transform to be applied.\n",
    "    \"\"\"\n",
    "    self.x = x\n",
    "    self.y = y\n",
    "    self.transform = transform\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    x_sample = torch.from_numpy(self.x[idx])\n",
    "    y_sample = torch.IntTensor([int(self.y[idx])])\n",
    "    \n",
    "    if self.transform:\n",
    "      pass #FIXME\n",
    "    \n",
    "    return x_sample, y_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjPbOPYgQj0f"
   },
   "source": [
    "### EEGMinimalContainer\n",
    "This class holds a train and test EEGDataset. It processes the data into a (N, C, H, W) format in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "6dk7JLAftaXB"
   },
   "outputs": [],
   "source": [
    "class EEGMinimalContainer():\n",
    "  \"\"\"EEG container for training and testing datasets.\"\"\"\n",
    "  \n",
    "  def __init__(self, data_dir, train_subject=None, test_subject=None, \n",
    "               remove_eog_channels=True, seed=42):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      data_dir (string): Path to all A0iT_slice.mat files for i in [1, 9].\n",
    "      train_subject(int): Subject to train on. If None, train on all.\n",
    "      test_subject(int): Subject to test on. If None, train on all except for\n",
    "                         train_subject. Only used if train_subject is not None.\n",
    "    \"\"\"\n",
    "    self.X_train = None\n",
    "    self.y_train = None\n",
    "    self.X_test = None\n",
    "    self.y_test = None\n",
    "    self.train_dataset = None\n",
    "    self.test_dataset = None\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if train_subject is None:\n",
    "      # Step 1: Append all of the input and output data together\n",
    "      X = None\n",
    "      y = None\n",
    "      end = np.empty(9)\n",
    "      for i in np.arange(9):\n",
    "        A0iT = h5py.File(data_dir + ('/A0%dT_slice.mat' % (i+1)), 'r')\n",
    "        X_temp = np.copy(A0iT['image'])\n",
    "        y_temp = np.copy(A0iT['type'])\n",
    "#        print(X_temp.shape)\n",
    " #       print(y_temp.shape)\n",
    "        y_temp = y_temp[0,0:X_temp.shape[0]:1]\n",
    "        y_temp = np.asarray(y_temp, dtype=np.int32)\n",
    "        X = X_temp if X is None else np.append(X, X_temp, axis=0)\n",
    "        y = y_temp if y is None else np.append(y, y_temp, axis=0)\n",
    "        end[i] = X_temp.shape[0] if i == 0 else X_temp.shape[0] + end[i-1]\n",
    "      X = np.expand_dims(X, axis=1)\n",
    "      y -= 769\n",
    "      # Step 2: Remove the EOG\n",
    "      if remove_eog_channels:\n",
    "        X = X[:, :, 0:22, :] \n",
    "      # Step 3: Remove NaN trials\n",
    "      remove_list = []\n",
    "      for i in range(len(X)):\n",
    "        if np.isnan(X[i]).any():\n",
    "          remove_list.append(i)\n",
    "      for trial_row in remove_list:\n",
    "        end[end > trial_row] -= 1\n",
    "      X = np.delete(X, remove_list, axis=0)\n",
    "      y = np.delete(y, remove_list, axis=0)\n",
    "      # Step 4: Generate an train/test split\n",
    "      remove_list = []\n",
    "      self.X_test = {}\n",
    "      self.y_test = {}\n",
    "      self.test_dataset = {}\n",
    "      sloc = 0\n",
    "      for i, eloc in enumerate(end, 1):\n",
    "        t_list = np.random.choice(np.arange(sloc, eloc), 50, replace=False)\n",
    "        t_list = t_list.astype(int)\n",
    "        self.X_test[str(i)] = X[t_list, :, :, :]\n",
    "        self.y_test[str(i)] = y[t_list]\n",
    "        self.test_dataset[str(i)] = EEGDataset(X[t_list, :, :, :], y[t_list])\n",
    "        remove_list = remove_list + t_list.tolist()\n",
    "        sloc = eloc\n",
    "      self.X_train = np.delete(X, remove_list, axis=0)\n",
    "      self.y_train = np.delete(y, remove_list, axis=0)\n",
    "      self.train_dataset = EEGDataset(self.X_train, self.y_train)\n",
    "      \n",
    "      print('EEGContainer X_train: ' + str(self.X_train.shape))\n",
    "      print('EEGContainer y_train: ' + str(self.y_train.shape))\n",
    "      for i in range(1, 10):\n",
    "        print(('EEGContainer X_test%d: ' %i) + str(self.X_test[str(i)].shape))\n",
    "        print(('EEGContainer y_test%d: ' %i) + str(self.y_test[str(i)].shape))\n",
    "    \n",
    "    else:\n",
    "      pass #FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bF93DV3g4nKf"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ZtX31_wU67Iu"
   },
   "outputs": [],
   "source": [
    "#data_dir = 'drive/School/EE239/project_datasets'\n",
    "data_dir = 'project_datasets'\n",
    "learning_rate=0.001\n",
    "batch_size=100\n",
    "seq_len= 1000\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 232,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 397,
     "status": "error",
     "timestamp": 1521440281662,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "TSyYi0jr5jMk",
    "outputId": "a4f7df4b-a8d8-46ad-b69f-cebec5ba3772"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EEGMinimalContainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c0ee98308d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mEEGset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEEGMinimalContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m train_loader = torch.utils.data.DataLoader(EEGset.train_dataset,\n\u001b[1;32m      4\u001b[0m                                            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                            shuffle=True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EEGMinimalContainer' is not defined"
     ]
    }
   ],
   "source": [
    "EEGset = EEGMinimalContainer(data_dir)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(EEGset.train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(EEGset.test_dataset,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "m5wBhJxkYPwr"
   },
   "outputs": [],
   "source": [
    "# Step 1: Append all of the input and output data together\n",
    "X = None\n",
    "y = None\n",
    "end = np.empty(9)\n",
    "for i in np.arange(9):\n",
    "    A0iT = h5py.File(data_dir + ('/A0%dT_slice.mat' % (i+1)), 'r')\n",
    "    X_temp = np.copy(A0iT['image'])\n",
    "    y_temp = np.copy(A0iT['type'])\n",
    "    #        print(X_temp.shape)\n",
    "    #       print(y_temp.shape)\n",
    "    y_temp = y_temp[0,0:X_temp.shape[0]:1]\n",
    "    y_temp = np.asarray(y_temp, dtype=np.int32)\n",
    "    X = X_temp if X is None else np.append(X, X_temp, axis=0)\n",
    "    y = y_temp if y is None else np.append(y, y_temp, axis=0)\n",
    "    end[i] = X_temp.shape[0] if i == 0 else X_temp.shape[0] + end[i-1]\n",
    "X = np.expand_dims(X, axis=1)\n",
    "y -= 769\n",
    "# Step 2: Remove the EOG\n",
    "X = X[:, :, 0:22, :] \n",
    "\n",
    "# Step 3: Remove NaN trials\n",
    "remove_list = []\n",
    "for i in range(len(X)):\n",
    "    if np.isnan(X[i]).any():\n",
    "        remove_list.append(i)\n",
    "for trial_row in remove_list:\n",
    "    end[end > trial_row] -= 1\n",
    "X = np.delete(X, remove_list, axis=0)\n",
    "y = np.delete(y, remove_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ADjA_XTcqYl"
   },
   "source": [
    "# Visualizing the Class Balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 396,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 3
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1521407025870,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "lLqzM7yUYPwu",
    "outputId": "a5299db9-a26f-482b-debe-97aa1f84a093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Class Balance')"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFZCAYAAABJ+lxSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b50c1bdd8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c0, c1, c2, c3 = 0,0,0,0\n",
    "for c in y:\n",
    "    if c == 0:\n",
    "        c0+=1\n",
    "    elif c == 1:\n",
    "        c1+=1\n",
    "    elif c == 2:\n",
    "        c2+=1\n",
    "    elif c == 3:\n",
    "        c3+=1\n",
    "        \n",
    "data = {'class0':c0, 'class1':c1, 'class2':c2, 'class3':c3}\n",
    "print((c0+c1+c2+c3) == X.shape[0])\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "plt.bar(names,values)\n",
    "plt.title(\"Class Balance\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdyywnIac2iB"
   },
   "source": [
    "# Data Manipulation \n",
    "Tensor dimensions were adjusted to fit pytorch's LSTM requirements, and data was split into train and test groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "nWSHoRR_YPwy"
   },
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(X)\n",
    "X = torch.squeeze(X)\n",
    "X = X.numpy()\n",
    "#samples, features, time -> samples, time, features\n",
    "X = np.transpose(X, (0,2,1))#batch x time x features \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# use strat. shuffle split to get indices for test and training data \n",
    "sss = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state=42)\n",
    "sss.get_n_splits(X, y)\n",
    "\n",
    "# take the indices generated by stratified shuffle split and make the test and training datasets\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1521407026690,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "kFDY4auokvK0",
    "outputId": "2dfd3103-c1e9-4a9e-f09c-39a2514a8543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2046, 1000, 22) (2046,)\n",
      "(512, 1000, 22) (512,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1521428061408,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "Haol_QIPd88B",
    "outputId": "6e90022d-04c1-41a9-8d56-f49431ab7b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2558, 22, 1000, 1)\n",
      "(2558,)\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "def create_one_hot(vec):\n",
    "    vec_new = []\n",
    "    for val in vec:\n",
    "        if val == 0:\n",
    "            vec_new.append([1,0,0,0])\n",
    "        elif val == 1:\n",
    "            vec_new.append([0,1,0,0])\n",
    "        elif val == 2: \n",
    "            vec_new.append([0,0,1,0])\n",
    "        elif val == 3:\n",
    "            vec_new.append([0,0,0,1])\n",
    "\n",
    "    return vec_new\n",
    "\n",
    "y_test_new = np.array(create_one_hot(y_test))\n",
    "y_train_new = np.array(create_one_hot(y_train))\n",
    "y_total_new = np.array(create_one_hot(y))\n",
    "\n",
    "print(len(y_train_new) == len(y_train))\n",
    "print(len(y_test_new) == len(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eRyPgV4rP8K5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def eval_model(rnn, data_loader):\n",
    "    # Test the Model\n",
    "    correct, total = 0, 0\n",
    "    for batch_X, batch_y in data_loader:\n",
    "        points = Variable(torch.from_numpy(batch_X))\n",
    "        labels = torch.from_numpy(batch_y)\n",
    "        if next(rnn.parameters()).is_cuda:\n",
    "            points, labels = points.cuda(), labels.cuda()\n",
    "        outputs = rnn(points)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    return correct / total\n",
    "  \n",
    "def dataloader(train_dataset, batch_size):\n",
    "    # for i, (images, labels) in enumerate(train_loader)\n",
    "    X, y = train_dataset\n",
    "    xA, xD = pywt.dwt(X, 'db1')\n",
    "    X = xA\n",
    "    \n",
    "    arr = np.arange(X.shape[0])\n",
    "    np.random.shuffle(arr)\n",
    "    batches, batch_x, batch_y = [], [], []\n",
    "    for a, i in enumerate(arr):\n",
    "        batch_x.append(X[i])\n",
    "        batch_y.append(y[i])\n",
    "        if a == len(arr)-1 or len(batch_x) == batch_size:\n",
    "            batches.append((np.stack(batch_x).astype(np.float32), np.array(batch_y).astype(int)))\n",
    "            batch_x, batch_y = [], []\n",
    "    return batches\n",
    "  \n",
    "#test loader\n",
    "test_loader = dataloader((X_test, y_test), batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7gi2F3c6jFOc"
   },
   "source": [
    "# RNN\n",
    "Basic RNN (LSTM and GRU) can be tested here, since the intialization of the RNN can take either 'GRU' or 'LSTM' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "t8TmYk4mjHRS"
   },
   "outputs": [],
   "source": [
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, rnn_type, input_size, hidden_size=100, num_layers=10, num_classes=4, dropout=0):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = getattr(nn, rnn_type)(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).cuda()\n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).cuda()\n",
    "\n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.rnn(x, h0)#(h0, c0))\n",
    "\n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1521337068833,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "zWMuJXKVjI1W",
    "outputId": "9b729706-d76c-46d8-f3ee-0d0caf08c2e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUDA\n"
     ]
    }
   ],
   "source": [
    "#create the model\n",
    "use_cuda = True\n",
    "rnn = RNN('GRU', input_size=11, hidden_size=100, num_layers=2, num_classes=4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "  print(\"using CUDA\")\n",
    "  rnn, criterion = rnn.cuda(), criterion.cuda() \n",
    "  \n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "  \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 663,
     "output_extras": [
      {
       "item_id": 33
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 247909,
     "status": "ok",
     "timestamp": 1521337317375,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "IE3TFCSPYPw-",
    "outputId": "8626d98d-e4f1-4753-b334-86686abe1f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.3882\n",
      "training accuracy = 0.2478\n",
      "test accuracy = 0.2168\n",
      "best test accuracy found\n",
      "Epoch [5/50], Loss: 1.3057\n",
      "training accuracy = 0.3998\n",
      "test accuracy = 0.2461\n",
      "best test accuracy found\n",
      "Epoch [10/50], Loss: 1.1844\n",
      "training accuracy = 0.5132\n",
      "test accuracy = 0.2480\n",
      "best test accuracy found\n",
      "Epoch [15/50], Loss: 0.9326\n",
      "training accuracy = 0.6779\n",
      "test accuracy = 0.2539\n",
      "best test accuracy found\n",
      "Epoch [20/50], Loss: 0.5641\n",
      "training accuracy = 0.8045\n",
      "test accuracy = 0.2422\n",
      "Epoch [24/50], Loss: 0.2846\n",
      "training accuracy = 0.9638\n",
      "test accuracy = 0.2441\n",
      "Epoch [29/50], Loss: 0.0735\n",
      "training accuracy = 0.9976\n",
      "test accuracy = 0.2422\n",
      "Epoch [34/50], Loss: 0.0085\n",
      "training accuracy = 1.0000\n",
      "test accuracy = 0.2520\n",
      "Epoch [39/50], Loss: 0.0036\n",
      "training accuracy = 1.0000\n",
      "test accuracy = 0.2461\n",
      "Epoch [43/50], Loss: 0.0031\n",
      "training accuracy = 1.0000\n",
      "test accuracy = 0.2559\n",
      "best test accuracy found\n",
      "Epoch [48/50], Loss: 0.0019\n",
      "training accuracy = 1.0000\n",
      "test accuracy = 0.2559\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "num_epochs = 50\n",
    "\n",
    "i = 0 # updates\n",
    "best_test_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    # Generate random batches every epoch\n",
    "    train_loader = dataloader((X_train, y_train), batch_size=batch_size)\n",
    "    for batch_X, batch_y in train_loader:\n",
    "\n",
    "        points = Variable(torch.from_numpy(batch_X))\n",
    "        labels = Variable(torch.from_numpy(batch_y))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            points, labels = points.cuda(), labels.cuda()\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "#        import pdb; pdb.set_trace()\n",
    "\n",
    "        outputs = rnn(points)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0: # every 100 updates, evaluate on test set\n",
    "            print ('Epoch [%d/%d], Loss: %.4f' % (epoch+1, num_epochs, loss.data[0]))\n",
    "            print(\"training accuracy = %.4f\" % eval_model(rnn, train_loader))\n",
    "            test_acc = eval_model(rnn, test_loader)\n",
    "            print(\"test accuracy = %.4f\" % test_acc)\n",
    "            if test_acc > best_test_acc:\n",
    "                print (\"best test accuracy found\")\n",
    "                best_test_acc = test_acc\n",
    "                torch.save(rnn.state_dict(), 'rnn_best.pkl')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t1GH_Qttdogl"
   },
   "source": [
    "Basic RNNs, including variations of the LSTM and GRU, could not perform above 0.25, yet would easily overfit the data. Adding more cells or depth did not help this at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WYYqWkf2m0Ga"
   },
   "source": [
    "# Convolutional RNN\n",
    "Conv layer for feature selection and LSTM for sequence dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2_Wgx8Nd-WB"
   },
   "source": [
    "Adding in more cells and layers to the RNN-based models, such as the GRU and LSTM, resulted in faster and faster overfitting without higher validation accuracy. The more complex models could quickly memorize the data but were unable to generalize. The intuition behind this was that the models were simply memorizing the input signals rather than learning activations on the specific features that pertain to an output class. This lead us to try and investigate better methods of feature selection, and inspired the use of a conv layer to do feature selection before passing the output to an RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5376,
     "status": "ok",
     "timestamp": 1521440327991,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "lqKEOm68YPxA",
    "outputId": "8cd78bb8-749a-4fa7-cceb-b8b042440048"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Conv2D, Convolution2D, InputLayer, MaxPooling2D, MaxPooling1D, GRU, LSTM\n",
    "from keras.layers import Activation, Flatten, TimeDistributed, Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau, Callback\n",
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbTzUqPxgGOb"
   },
   "source": [
    "## GPU Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tFZjtZexJAdH"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 289,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1521440347332,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "nUT0I5GqJULK",
    "outputId": "45e53c80-c2e5-4624-9102-856c393064e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8047684423982747399\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GPU setup\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "dlKFF2WTLWtL"
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto( device_count = {'GPU': 0} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNjdHhKOgIPO"
   },
   "source": [
    "## Auxilary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JF56CrMjgMQc"
   },
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1521440356335,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "sYoh-IH4JBv6",
    "outputId": "2999925f-22a8-4ce6-cd03-4cbed3642617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2558, 1, 22, 1000)\n",
      "(2558, 22, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "shape = X.shape\n",
    "print(shape)\n",
    "input_shape = X.shape\n",
    "\n",
    "#Keras requires NHWC for tf backend\n",
    "#I have NCHW \n",
    "#0 1 2 3 -> 0 2 3 1\n",
    "X = np.transpose(X, (0,2,3,1))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 875,
     "status": "ok",
     "timestamp": 1521440359586,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "kG_i8t12JDCH",
    "outputId": "0583d644-0fe9-4d1e-92e9-35f8a3db4d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2046, 22, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# use strat. shuffle split to get indices for test and training data \n",
    "sss = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state=42)\n",
    "sss.get_n_splits(X, y)\n",
    "\n",
    "# take the indices generated by stratified shuffle split and make the test and training datasets\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1521440360948,
     "user": {
      "displayName": "Jonathan Hurwitz",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106365511578683231950"
     },
     "user_tz": 420
    },
    "id": "kB98zMOMJEKQ",
    "outputId": "90d99666-1cfa-4729-c0ca-b636640c97bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def create_one_hot(vec):\n",
    "    vec_new = []\n",
    "    for val in vec:\n",
    "        if val == 0:\n",
    "            vec_new.append([1,0,0,0])\n",
    "        elif val == 1:\n",
    "            vec_new.append([0,1,0,0])\n",
    "        elif val == 2: \n",
    "            vec_new.append([0,0,1,0])\n",
    "        elif val == 3:\n",
    "            vec_new.append([0,0,0,1])\n",
    "\n",
    "    return vec_new\n",
    "\n",
    "\n",
    "y_test_new = np.array(create_one_hot(y_test))\n",
    "y_train_new = np.array(create_one_hot(y_train))\n",
    "y_total_new = np.array(create_one_hot(y))\n",
    "\n",
    "print(len(y_train_new) == len(y_train))\n",
    "print(len(y_test_new) == len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qknNAGoDhE1S"
   },
   "source": [
    "## Model Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQaUfHZdhJ4_"
   },
   "source": [
    "### Single Conv Layer + LSTM \n",
    "Using 32 filters. <br>\n",
    "Baseline validation accuracy settles at around 0.4 using only EEG channels, with a peak of 0.46.\n",
    "Validation accuracy with EEG+EOG settles at around 0.61, with a peak of 0.64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 122,
     "output_extras": [
      {
       "item_id": 65
      }
     ]
    },
    "colab_type": "code",
    "id": "FoliYvZghD8E",
    "outputId": "961241b3-37bb-4d27-8e0a-ace928f9402c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2046 samples, validate on 512 samples\n",
      "Epoch 1/50\n",
      "2046/2046 [==============================] - 137s 67ms/step - loss: 1.4199 - acc: 0.2444 - val_loss: 1.3870 - val_acc: 0.2422\n",
      "Epoch 2/50\n",
      "2046/2046 [==============================] - 109s 53ms/step - loss: 1.3875 - acc: 0.2478 - val_loss: 1.3863 - val_acc: 0.2539\n",
      "Epoch 3/50\n",
      "2046/2046 [==============================] - 102s 50ms/step - loss: 1.3863 - acc: 0.2424 - val_loss: 1.3860 - val_acc: 0.2500\n",
      "Epoch 4/50\n",
      "2046/2046 [==============================] - 106s 52ms/step - loss: 1.3878 - acc: 0.2473 - val_loss: 1.3867 - val_acc: 0.2539\n",
      "Epoch 5/50\n",
      "2046/2046 [==============================] - 105s 51ms/step - loss: 1.3891 - acc: 0.2346 - val_loss: 1.3878 - val_acc: 0.2539\n",
      "Epoch 6/50\n",
      "2046/2046 [==============================] - 113s 55ms/step - loss: 1.3877 - acc: 0.2468 - val_loss: 1.3855 - val_acc: 0.2656\n",
      "Epoch 7/50\n",
      "2046/2046 [==============================] - 120s 59ms/step - loss: 1.3849 - acc: 0.2522 - val_loss: 1.3856 - val_acc: 0.2598\n",
      "Epoch 8/50\n",
      "2046/2046 [==============================] - 123s 60ms/step - loss: 1.3827 - acc: 0.2874 - val_loss: 1.3818 - val_acc: 0.2852\n",
      "Epoch 9/50\n",
      "2046/2046 [==============================] - 109s 53ms/step - loss: 1.3753 - acc: 0.3089 - val_loss: 1.3827 - val_acc: 0.2695\n",
      "Epoch 10/50\n",
      "2046/2046 [==============================] - 108s 53ms/step - loss: 1.3769 - acc: 0.2874 - val_loss: 1.3804 - val_acc: 0.2676\n",
      "Epoch 11/50\n",
      "2046/2046 [==============================] - 108s 53ms/step - loss: 1.3721 - acc: 0.3172 - val_loss: 1.3782 - val_acc: 0.3105\n",
      "Epoch 12/50\n",
      "1100/2046 [===============>..............] - ETA: 47s - loss: 1.3684 - acc: 0.3373"
     ]
    }
   ],
   "source": [
    "num_filters=32\n",
    "kernel=(3,3)\n",
    "output_classes=4\n",
    "\n",
    "\n",
    "model1=Sequential()\n",
    "#The input generated by the generator \n",
    "#should have shape:[batch_size, num_timesteps, img_width, img_height, img_channels].\n",
    "model1.add(Conv2D(32, (3, 3), activation='relu', input_shape=(22,1000,1)))\n",
    "model1.add(TimeDistributed(Activation(\"relu\")))\n",
    "model1.add(TimeDistributed(MaxPooling1D(pool_size=(2))))\n",
    "model1.add(TimeDistributed(Flatten()))\n",
    "model1.add(TimeDistributed(Dropout(0.25)))\n",
    "model1.add(LSTM(units=100))\n",
    "model1.add(Dense(output_classes))\n",
    "model1.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model1.fit(X, y_total_new, batch_size=50, epochs=50, validation_split=0.2)\n",
    "model1.save('model1.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UjqfeVfvjjcO"
   },
   "source": [
    "### Two Conv Layers + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "1cenQuNujpbQ"
   },
   "outputs": [],
   "source": [
    "num_filters=32\n",
    "kernel=(3,3)\n",
    "output_classes=4\n",
    "\n",
    "\n",
    "model3=Sequential()\n",
    "#The input generated by the generator \n",
    "#should have shape:[batch_size, num_timesteps, img_width, img_height, img_channels].\n",
    "model3.add(Conv2D(32, (3, 3), activation='relu', input_shape=(22,1000,1)))\n",
    "model3.add(TimeDistributed(Activation(\"relu\")))\n",
    "model3.add(TimeDistributed(MaxPooling1D(pool_size=(2))))\n",
    "model3.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model3.add(TimeDistributed(Activation(\"relu\")))\n",
    "model3.add(TimeDistributed(MaxPooling1D(pool_size=(2))))\n",
    "model3.add(TimeDistributed(Flatten()))\n",
    "model3.add(TimeDistributed(Dropout(0.25)))\n",
    "\n",
    "model3.add(LSTM(units=100))\n",
    "\n",
    "model3.add(Dense(output_classes))\n",
    "model3.add(Activation(\"softmax\"))\n",
    "\n",
    "# Set a learning rate annealer\n",
    "#learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                         #   patience=3, \n",
    "                                          #  verbose=1, \n",
    "                                          #  factor=0.5, \n",
    "                                          #  min_lr=0.00001)\n",
    "model3.summary()\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model3.fit(X, y_total_new, batch_size=50, epochs=50, validation_split=0.2)\n",
    "model3.save('model3.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w2YbHgMdj0WB"
   },
   "source": [
    "### Two Conv Layers + 2 LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "3dMJtO1xjxyi"
   },
   "outputs": [],
   "source": [
    "num_filters=32\n",
    "kernel=(3,3)\n",
    "output_classes=4\n",
    "\n",
    "\n",
    "model4=Sequential()\n",
    "#The input generated by the generator \n",
    "#should have shape:[batch_size, num_timesteps, img_width, img_height, img_channels].\n",
    "model4.add(Conv2D(32, (3, 3), activation='relu', input_shape=(22,1000,1)))\n",
    "model4.add(TimeDistributed(Activation(\"relu\")))\n",
    "model4.add(TimeDistributed(MaxPooling1D(pool_size=(2))))\n",
    "model4.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model4.add(TimeDistributed(Activation(\"relu\")))\n",
    "model4.add(TimeDistributed(MaxPooling1D(pool_size=(2))))\n",
    "model4.add(TimeDistributed(Flatten()))\n",
    "model4.add(TimeDistributed(Dropout(0.25)))\n",
    "\n",
    "model4.add(LSTM(units=100, return_sequences=True))\n",
    "model4.add(LSTM(units=100))\n",
    "\n",
    "model4.add(Dense(output_classes))\n",
    "model4.add(Activation(\"softmax\"))\n",
    "\n",
    "# Set a learning rate annealer\n",
    "#learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                         #   patience=3, \n",
    "                                          #  verbose=1, \n",
    "                                          #  factor=0.5, \n",
    "                                          #  min_lr=0.00001)\n",
    "model4.summary()\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model4.fit(X, y_total_new, batch_size=50, epochs=50, validation_split=0.2)\n",
    "model4.save('model4.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9xxZD3-d3rsO"
   },
   "source": [
    "# With EOG channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "1XoO4em23tkC"
   },
   "outputs": [],
   "source": [
    "# Step 1: Append all of the input and output data together\n",
    "X = None\n",
    "y = None\n",
    "end = np.empty(9)\n",
    "for i in np.arange(9):\n",
    "    A0iT = h5py.File(data_dir + ('/A0%dT_slice.mat' % (i+1)), 'r')\n",
    "    X_temp = np.copy(A0iT['image'])\n",
    "    y_temp = np.copy(A0iT['type'])\n",
    "    #        print(X_temp.shape)\n",
    "    #       print(y_temp.shape)\n",
    "    y_temp = y_temp[0,0:X_temp.shape[0]:1]\n",
    "    y_temp = np.asarray(y_temp, dtype=np.int32)\n",
    "    X = X_temp if X is None else np.append(X, X_temp, axis=0)\n",
    "    y = y_temp if y is None else np.append(y, y_temp, axis=0)\n",
    "    end[i] = X_temp.shape[0] if i == 0 else X_temp.shape[0] + end[i-1]\n",
    "X = np.expand_dims(X, axis=1)\n",
    "y -= 769\n",
    "# Step 2: Remove the EOG\n",
    "X = X[:, :, 0:25, :] \n",
    "\n",
    "# Step 3: Remove NaN trials\n",
    "remove_list = []\n",
    "for i in range(len(X)):\n",
    "    if np.isnan(X[i]).any():\n",
    "        remove_list.append(i)\n",
    "for trial_row in remove_list:\n",
    "    end[end > trial_row] -= 1\n",
    "X = np.delete(X, remove_list, axis=0)\n",
    "y = np.delete(y, remove_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ad0Y7cOZ6x3v"
   },
   "source": [
    "### Conv + LSTM\n",
    "EOG Channels included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ac-v5wTl38l4"
   },
   "outputs": [],
   "source": [
    "num_filters=32\n",
    "kernel=(3,3)\n",
    "output_classes=4\n",
    "\n",
    "\n",
    "model5=Sequential()\n",
    "#The input generated by the generator \n",
    "#should have shape:[batch_size, num_timesteps, img_width, img_height, img_channels].\n",
    "model5.add(Conv2D(32, (3, 3), activation='relu', input_shape=(25,1000,1)))\n",
    "model5.add(TimeDistributed(Activation(\"relu\")))\n",
    "model5.add(TimeDistributed(MaxPooling1D(pool_size=(2))))\n",
    "model5.add(TimeDistributed(Flatten()))\n",
    "model5.add(TimeDistributed(Dropout(0.25)))\n",
    "model5.add(LSTM(units=100))\n",
    "model5.add(Dense(output_classes))\n",
    "model5.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model5.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model5.fit(X, y_total_new, batch_size=50, epochs=50, validation_split=0.2)\n",
    "model5.save('model5.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAoqj_XL6mk3"
   },
   "source": [
    "### Two Conv Layers + LSTM\n",
    "EOG channels included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "bvrFgS5x4FoX"
   },
   "outputs": [],
   "source": [
    "num_filters=32\n",
    "kernel=(3,3)\n",
    "output_classes=4\n",
    "\n",
    "\n",
    "model6=Sequential()\n",
    "#The input generated by the generator \n",
    "#should have shape:[batch_size, num_timesteps, img_width, img_height, img_channels].\n",
    "model6.add(Conv2D(32, (3, 3), activation='relu', input_shape=(25,1000,1)))\n",
    "model6.add(TimeDistributed(Activation(\"relu\")))\n",
    "model6.add(TimeDistributed(MaxPooling1D(pool_size=(2))))\n",
    "model6.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model6.add(TimeDistributed(Activation(\"relu\")))\n",
    "model6.add(TimeDistributed(MaxPooling1D(pool_size=(2))))\n",
    "model6.add(TimeDistributed(Flatten()))\n",
    "model6.add(TimeDistributed(Dropout(0.25)))\n",
    "\n",
    "model6.add(LSTM(units=100))\n",
    "\n",
    "model6.add(Dense(output_classes))\n",
    "model6.add(Activation(\"softmax\"))\n",
    "\n",
    "# Set a learning rate annealer\n",
    "#learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                         #   patience=3, \n",
    "                                          #  verbose=1, \n",
    "                                          #  factor=0.5, \n",
    "                                          #  min_lr=0.00001)\n",
    "model6.summary()\n",
    "model6.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model6.fit(X, y_total_new, batch_size=50, epochs=50, validation_split=0.2)\n",
    "model6.save('model6.h5')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I_a3o_Gf6q76"
   },
   "source": [
    "### Two Conv + 2 LSTM\n",
    "EOG channels included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "5U3_r0qk4P0e"
   },
   "outputs": [],
   "source": [
    "num_filters=32\n",
    "kernel=(3,3)\n",
    "output_classes=4\n",
    "\n",
    "\n",
    "model7=Sequential()\n",
    "#The input generated by the generator \n",
    "#should have shape:[batch_size, num_timesteps, img_width, img_height, img_channels].\n",
    "model7.add(Conv2D(32, (3, 3), activation='relu', input_shape=(25,1000,1)))\n",
    "model7.add(TimeDistributed(Activation(\"relu\")))\n",
    "model7.add(TimeDistributed(MaxPooling1D(pool_size=(2))))\n",
    "model7.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model7.add(TimeDistributed(Activation(\"relu\")))\n",
    "model7.add(TimeDistributed(MaxPooling1D(pool_size=(2))))\n",
    "model7.add(TimeDistributed(Flatten()))\n",
    "model7.add(TimeDistributed(Dropout(0.25)))\n",
    "\n",
    "model7.add(LSTM(units=100, return_sequences=True))\n",
    "model7.add(LSTM(units=100))\n",
    "\n",
    "model7.add(Dense(output_classes))\n",
    "model7.add(Activation(\"softmax\"))\n",
    "\n",
    "# Set a learning rate annealer\n",
    "#learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                         #   patience=3, \n",
    "                                          #  verbose=1, \n",
    "                                          #  factor=0.5, \n",
    "                                          #  min_lr=0.00001)\n",
    "model7.summary()\n",
    "model7.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model7.fit(X, y_total_new, batch_size=50, epochs=50, validation_split=0.2)\n",
    "model7.save('model7.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dD4O5-LV7p-M"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JwUcaseoXXV"
   },
   "source": [
    "### Print MATLAB Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0nSce2gzkAZa"
   },
   "outputs": [],
   "source": [
    "# Print Loss\n",
    "print('Loss = [', end='')\n",
    "for lossval in np.nditer(loss_arr):\n",
    "  print('%.5f, ' % lossval, end='')\n",
    "print('];')\n",
    "\n",
    "# Print Training Accuracy\n",
    "print('Training_Accuracy = [', end='')\n",
    "for acc in np.nditer(training_acc_arr):\n",
    "  print('%.5f, ' % acc, end='')\n",
    "print('];')\n",
    "\n",
    "# Print Testing Accuracy\n",
    "print('Testing_Accuracy = [', end='')\n",
    "for subject in range(9):\n",
    "  for acc in np.nditer(testing_acc_arr[subject, :]):\n",
    "    print('%.5f, ' % acc, end='')\n",
    "  print('; ', end='')\n",
    "print('];')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "GF7H5mKFYPxT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0TQbDPf7h-yB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rnn_framework.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
