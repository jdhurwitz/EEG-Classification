{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"testing_framework.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"sNbiI9AOPlq6","colab_type":"text"},"cell_type":"markdown","source":["# Neural Network Testing Framework\n","This notebook is intended to be a general framework for testing Neural Neworks on the EEG data set. While the initial iteration of this notebook is used for a simple Convolutional Neural Network (CNN), other networks using PyTorch can be implemented and assigned to the neural network variable. Many of the beginning cells are used to intialize for a Google Drive Colaboratory notebook GPU usability and can be ignored as necessary.\n","\n","---\n","\n"]},{"metadata":{"id":"2hlystw2Pzbg","colab_type":"text"},"cell_type":"markdown","source":["##Initialization\n","Google Drive access, PyTorch, etc."]},{"metadata":{"id":"aEly-WUNrG_n","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!kill -9 -1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3_ioKx_tQsFg","colab_type":"text"},"cell_type":"markdown","source":["This section provides access to the user's Google drive."]},{"metadata":{"id":"nyJiSCniN5Sn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eADEBx-EQNg5","colab_type":"text"},"cell_type":"markdown","source":["This section creates a drive that links to the user's Google drive."]},{"metadata":{"id":"YzXqllGHQK6E","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":52},"outputId":"e14188c2-33bb-4d5d-946d-08cd33c38dc2","executionInfo":{"status":"ok","timestamp":1520379354307,"user_tz":480,"elapsed":2420,"user":{"displayName":"Nathan Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"106327691903472177650"}}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":46,"outputs":[{"output_type":"stream","text":["fuse: mountpoint is not empty\r\n","fuse: if you are sure this is safe, use the 'nonempty' mount option\r\n"],"name":"stdout"}]},{"metadata":{"id":"jUfqAB83QuPc","colab_type":"text"},"cell_type":"markdown","source":["This section installs PyTorch."]},{"metadata":{"id":"vS4vRAnsQw2J","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# http://pytorch.org/\n","from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LaZWU_TlQ7Yx","colab_type":"text"},"cell_type":"markdown","source":["##Imports"]},{"metadata":{"id":"Uo96B36sQURz","colab_type":"text"},"cell_type":"markdown","source":["Imports can be added as necessary."]},{"metadata":{"id":"UgT3bxtlRT0U","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","import h5py\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.cuda\n","from torch.utils.data import Dataset\n","from torch.autograd import Variable"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RoLPc0SzSM2_","colab_type":"text"},"cell_type":"markdown","source":["##Classes"]},{"metadata":{"id":"55Aaa8JmQZpb","colab_type":"text"},"cell_type":"markdown","source":["###EEGDataset\n","This class inherits the torch.utils.data.Dataset class to be used with the torch.utils.data.Dataloader class."]},{"metadata":{"id":"ak2uqN0pSPZL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class EEGDataset(Dataset):\n","  \"\"\"EEG dataset.\"\"\"\n","  \n","  def __init__(self, x, y, transform=None):\n","    \"\"\"\n","    Args:\n","      x (numpy array): Input data of shape \n","                       num_trials x num_electrodes x num_time_bins.\n","      y (numpy array): Output data of shape num_trials x 1.\n","      transform (callable, optional): Optional transform to be applied.\n","    \"\"\"\n","    self.x = x\n","    self.y = y\n","    self.transform = transform\n","    \n","  def __len__(self):\n","    return len(self.x)\n","  \n","  def __getitem__(self, idx):\n","    x_sample = torch.from_numpy(self.x[idx])\n","    y_sample = torch.IntTensor([int(self.y[idx])])\n","    \n","    if self.transform:\n","      pass #FIXME\n","    \n","    return x_sample, y_sample"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PjPbOPYgQj0f","colab_type":"text"},"cell_type":"markdown","source":["###EEGMinimalContainer\n","This class holds a train and test EEGDataset. It processes the data into a (N, C, H, W) format in time."]},{"metadata":{"id":"6dk7JLAftaXB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class EEGMinimalContainer():\n","  \"\"\"EEG container for training and testing datasets.\"\"\"\n","  \n","  def __init__(self, data_dir, train_subject=None, test_subject=None, \n","               remove_eog_channels=True, seed=42):\n","    \"\"\"\n","    Args:\n","      data_dir (string): Path to all A0iT_slice.mat files for i in [1, 9].\n","      train_subject(int): Subject to train on. If None, train on all.\n","      test_subject(int): Subject to test on. If None, train on all except for\n","                         train_subject. Only used if train_subject is not None.\n","    \"\"\"\n","    self.X_train = None\n","    self.y_train = None\n","    self.X_test = None\n","    self.y_test = None\n","    self.train_dataset = None\n","    self.test_dataset = None\n","    np.random.seed(seed)\n","    \n","    if train_subject is None:\n","      # Step 1: Append all of the input and output data together\n","      X = None\n","      y = None\n","      end = np.empty(9)\n","      for i in np.arange(9):\n","        A0iT = h5py.File(data_dir + ('/A0%dT_slice.mat' % (i+1)), 'r')\n","        X_temp = np.copy(A0iT['image'])\n","        y_temp = np.copy(A0iT['type'])\n","        y_temp = y_temp[0,0:X_temp.shape[0]:1]\n","        y_temp = np.asarray(y_temp, dtype=np.int32)\n","        X = X_temp if X is None else np.append(X, X_temp, axis=0)\n","        y = y_temp if y is None else np.append(y, y_temp, axis=0)\n","        end[i] = X_temp.shape[0] if i == 0 else X_temp.shape[0] + end[i-1]\n","      X = np.expand_dims(X, axis=1)\n","      y -= 769\n","      # Step 2: Remove the EOG\n","      if remove_eog_channels:\n","        X = X[:, :, 0:22, :] \n","      # Step 3: Remove NaN trials\n","      remove_list = []\n","      for i in range(len(X)):\n","        if np.isnan(X[i]).any():\n","          remove_list.append(i)\n","      for trial_row in remove_list:\n","        end[end > trial_row] -= 1\n","      X = np.delete(X, remove_list, axis=0)\n","      y = np.delete(y, remove_list, axis=0)\n","      # Step 4: Generate an train/test split\n","      remove_list = []\n","      self.X_test = {}\n","      self.y_test = {}\n","      self.test_dataset = {}\n","      sloc = 0\n","      for i, eloc in enumerate(end, 1):\n","        t_list = np.random.choice(np.arange(sloc, eloc), 50, replace=False)\n","        t_list = t_list.astype(int)\n","        self.X_test[str(i)] = X[t_list, :, :, :]\n","        self.y_test[str(i)] = y[t_list]\n","        self.test_dataset[str(i)] = EEGDataset(X[t_list, :, :, :], y[t_list])\n","        remove_list = remove_list + t_list.tolist()\n","        sloc = eloc\n","      self.X_train = np.delete(X, remove_list, axis=0)\n","      self.y_train = np.delete(y, remove_list, axis=0)\n","      self.train_dataset = EEGDataset(self.X_train, self.y_train)\n","      \n","      print('EEGContainer X_train: ' + str(self.X_train.shape))\n","      print('EEGContainer y_train: ' + str(self.y_train.shape))\n","      for i in range(1, 10):\n","        print(('EEGContainer X_test%d: ' %i) + str(self.X_test[str(i)].shape))\n","        print(('EEGContainer y_test%d: ' %i) + str(self.y_test[str(i)].shape))\n","    \n","    else:\n","      pass #FIXME"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mqvKa42SB80Z","colab_type":"text"},"cell_type":"markdown","source":["###Fully-Connected Neural Network"]},{"metadata":{"id":"fWSfDiQfiTKx","colab_type":"text"},"cell_type":"markdown","source":["####FNN1\n","\n","Extremely Vanilla FNN"]},{"metadata":{"id":"JB85J15zCA3e","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class FNN1(nn.Module):\n","  def __init__(self):\n","    super(FNN1, self).__init__()\n","    self.input_size = 1 * 22 * 1000\n","    self.fc1 = nn.Linear(self.input_size, 1000)\n","    self.fc2 = nn.Linear(1000, 500)\n","    self.fc3 = nn.Linear(500, 120)\n","    self.fc4 = nn.Linear(120, 80)\n","    self.fc5 = nn.Linear(80, 4)\n","    \n","  def forward(self, x):\n","    x = x.view(-1, self.input_size)\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = F.relu(self.fc3(x))\n","    x = F.relu(self.fc4(x))\n","    x = F.relu(self.fc5(x))\n","    return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vdkmP_PkYU-B","colab_type":"text"},"cell_type":"markdown","source":["###Convolutional Neural Network"]},{"metadata":{"id":"O8qhkxygMgcI","colab_type":"text"},"cell_type":"markdown","source":["####CNN1\n","Extremely Vanilla CNN. Note the 3x3 convolutions do not take advantage of the temporal information.\n","\n","conv+relu - conv+relu - pool - fc+relu - fc+relu - fc"]},{"metadata":{"id":"1Cq6x1TpQ5v7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class CNN1(nn.Module):\n","  def __init__(self):\n","    super(CNN1, self).__init__()\n","    self.conv1 = nn.Conv2d(1, 4, 3, stride=1, padding=1)\n","    self.conv2 = nn.Conv2d(4, 8, 3, stride=1, padding=1)\n","    self.pool = nn.MaxPool2d(2, 2)\n","    self.fc1 = nn.Linear(8 * 11 * 500, 120)\n","    self.fc2 = nn.Linear(120, 80)\n","    self.fc3 = nn.Linear(80, 4)\n","  \n","  def forward(self, x):\n","    # x is 1 x 22 x 1000\n","    x = self.pool(F.relu(self.conv2(F.relu(self.conv1(x)))))\n","    # x is 8 x 11 x  500\n","    x = x.view(-1, 8 * 11 * 500)\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.fc3(x)\n","    return x    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"bF93DV3g4nKf","colab_type":"text"},"cell_type":"markdown","source":["##Setup"]},{"metadata":{"id":"ZtX31_wU67Iu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["data_dir = 'drive/ee239as/project_datasets'\n","batch_size = 17\n","num_epochs = 20\n","learning_rate = 1e-3\n","\n","use_cuda = True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TSyYi0jr5jMk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":369},"outputId":"659525d1-9f61-4bfe-ba33-ea5e2c24558a","executionInfo":{"status":"ok","timestamp":1520379368811,"user_tz":480,"elapsed":7174,"user":{"displayName":"Nathan Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"106327691903472177650"}}},"cell_type":"code","source":["EEGset = EEGMinimalContainer(data_dir)\n","\n","train_loader = torch.utils.data.DataLoader(EEGset.train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","\n","test_loader = {}\n","for i in range(1, 10):\n","  test_loader[str(i)] = torch.utils.data.DataLoader(EEGset.test_dataset[str(i)],\n","                                                    batch_size=10,\n","                                                    shuffle=False)"],"execution_count":54,"outputs":[{"output_type":"stream","text":["EEGContainer X_train: (2108, 1, 22, 1000)\n","EEGContainer y_train: (2108,)\n","EEGContainer X_test1: (50, 1, 22, 1000)\n","EEGContainer y_test1: (50,)\n","EEGContainer X_test2: (50, 1, 22, 1000)\n","EEGContainer y_test2: (50,)\n","EEGContainer X_test3: (50, 1, 22, 1000)\n","EEGContainer y_test3: (50,)\n","EEGContainer X_test4: (50, 1, 22, 1000)\n","EEGContainer y_test4: (50,)\n","EEGContainer X_test5: (50, 1, 22, 1000)\n","EEGContainer y_test5: (50,)\n","EEGContainer X_test6: (50, 1, 22, 1000)\n","EEGContainer y_test6: (50,)\n","EEGContainer X_test7: (50, 1, 22, 1000)\n","EEGContainer y_test7: (50,)\n","EEGContainer X_test8: (50, 1, 22, 1000)\n","EEGContainer y_test8: (50,)\n","EEGContainer X_test9: (50, 1, 22, 1000)\n","EEGContainer y_test9: (50,)\n"],"name":"stdout"}]},{"metadata":{"id":"1vXM-eEX7niy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["net = CNN1()\n","\n","if use_cuda and torch.cuda.is_available():\n","  net.cuda()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FdodrAOa6CyS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dD4O5-LV7p-M","colab_type":"text"},"cell_type":"markdown","source":["##Training"]},{"metadata":{"id":"S_EVgnxX7rEa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":45},{"item_id":85}],"base_uri":"https://localhost:8080/","height":2481},"outputId":"a6aaea2c-bacb-499c-845d-9d7044779582","executionInfo":{"status":"ok","timestamp":1520379435280,"user_tz":480,"elapsed":64500,"user":{"displayName":"Nathan Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"106327691903472177650"}}},"cell_type":"code","source":["loss_arr = np.empty(num_epochs * (len(EEGset.train_dataset)//batch_size))\n","training_acc_arr = np.empty(num_epochs)\n","testing_acc_arr = np.empty((9, num_epochs))\n","\n","j = 0\n","for epoch in range(num_epochs):\n","  for i, (signals, labels) in enumerate(train_loader):\n","    \n","    signals = signals.type(torch.FloatTensor)\n","    signals = Variable(signals)\n","    labels = labels.type(torch.LongTensor)\n","    labels = Variable(torch.squeeze(labels))\n","    \n","    if use_cuda and torch.cuda.is_available():\n","      signals = signals.cuda()\n","      labels = labels.cuda()\n","    \n","    optimizer.zero_grad()\n","    outputs = net(signals)\n","    \n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","    \n","    loss_arr[j] = loss.data[0]\n","    j += 1\n","    \n","    if (i+1) % 31 == 0:\n","      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n","            % (epoch+1, num_epochs, i+1, len(EEGset.train_dataset)//batch_size, \n","               loss.data[0]))\n","  \n","  # Training accuracy\n","  total = 0\n","  correct = 0\n","  for signals, labels in train_loader:\n","    signals = signals.type(torch.FloatTensor)\n","    signals = Variable(signals)\n","    labels = torch.squeeze(labels.type(torch.LongTensor))\n","    if use_cuda and torch.cuda.is_available():\n","      signals = signals.cuda()\n","      labels = labels.cuda()\n","    outputs = net(signals)\n","    _, predicted = torch.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum()\n","  training_acc_arr[epoch] = (correct/total)\n","  print ('Training Accuracy: %.5f' % training_acc_arr[epoch])\n","  \n","  \n","  # Testing accuracy\n","  for subject in range(9):\n","    total = 0\n","    correct = 0\n","    for signals, labels in test_loader[str(subject+1)]:\n","      signals = signals.type(torch.FloatTensor)\n","      signals = Variable(signals)\n","      labels = torch.squeeze(labels.type(torch.LongTensor))\n","      if use_cuda and torch.cuda.is_available():\n","        signals = signals.cuda()\n","        labels = labels.cuda()\n","      outputs = net(signals)\n","      _, predicted = torch.max(outputs.data, 1)\n","      total += labels.size(0)\n","      correct += (predicted == labels).sum()\n","    testing_acc_arr[subject, epoch] = (correct/total)\n","  print ('Testing Accuracy: ' + str(testing_acc_arr[:, epoch]))\n","  print ('Testing Accuracy Average: %.5f' % np.average(testing_acc_arr[:, epoch]))"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Epoch [1/20], Step [31/124], Loss: 1.5090\n","Epoch [1/20], Step [62/124], Loss: 1.3263\n","Epoch [1/20], Step [93/124], Loss: 1.3644\n","Epoch [1/20], Step [124/124], Loss: 1.4613\n","Training Accuracy: 0.46395\n","Testing Accuracy: [0.26 0.3  0.36 0.28 0.28 0.3  0.32 0.22 0.26]\n","Testing Accuracy Average: 0.28667\n","Epoch [2/20], Step [31/124], Loss: 1.1848\n","Epoch [2/20], Step [62/124], Loss: 1.3234\n","Epoch [2/20], Step [93/124], Loss: 1.2599\n","Epoch [2/20], Step [124/124], Loss: 1.2096\n","Training Accuracy: 0.60104\n","Testing Accuracy: [0.28 0.28 0.24 0.32 0.36 0.2  0.38 0.38 0.26]\n","Testing Accuracy Average: 0.30000\n","Epoch [3/20], Step [31/124], Loss: 0.6771\n","Epoch [3/20], Step [62/124], Loss: 0.5387\n","Epoch [3/20], Step [93/124], Loss: 0.6532\n","Epoch [3/20], Step [124/124], Loss: 0.7100\n","Training Accuracy: 0.89374\n","Testing Accuracy: [0.38 0.32 0.34 0.3  0.32 0.28 0.5  0.36 0.4 ]\n","Testing Accuracy Average: 0.35556\n","Epoch [4/20], Step [31/124], Loss: 0.3586\n","Epoch [4/20], Step [62/124], Loss: 0.2464\n","Epoch [4/20], Step [93/124], Loss: 0.2360\n","Epoch [4/20], Step [124/124], Loss: 0.3071\n","Training Accuracy: 0.98814\n","Testing Accuracy: [0.38 0.38 0.4  0.38 0.36 0.3  0.46 0.28 0.5 ]\n","Testing Accuracy Average: 0.38222\n","Epoch [5/20], Step [31/124], Loss: 0.0715\n","Epoch [5/20], Step [62/124], Loss: 0.0306\n","Epoch [5/20], Step [93/124], Loss: 0.0370\n","Epoch [5/20], Step [124/124], Loss: 0.0255\n","Training Accuracy: 0.99051\n","Testing Accuracy: [0.36 0.42 0.36 0.42 0.42 0.38 0.56 0.36 0.4 ]\n","Testing Accuracy Average: 0.40889\n","Epoch [6/20], Step [31/124], Loss: 0.0160\n","Epoch [6/20], Step [62/124], Loss: 0.1162\n","Epoch [6/20], Step [93/124], Loss: 0.0306\n","Epoch [6/20], Step [124/124], Loss: 0.0863\n","Training Accuracy: 0.99099\n","Testing Accuracy: [0.46 0.4  0.34 0.42 0.38 0.36 0.44 0.3  0.46]\n","Testing Accuracy Average: 0.39556\n","Epoch [7/20], Step [31/124], Loss: 0.0065\n","Epoch [7/20], Step [62/124], Loss: 0.0018\n","Epoch [7/20], Step [93/124], Loss: 0.0062\n","Epoch [7/20], Step [124/124], Loss: 0.0059\n","Training Accuracy: 0.99905\n","Testing Accuracy: [0.5  0.34 0.3  0.44 0.38 0.34 0.46 0.4  0.52]\n","Testing Accuracy Average: 0.40889\n","Epoch [8/20], Step [31/124], Loss: 0.0030\n","Epoch [8/20], Step [62/124], Loss: 0.0010\n","Epoch [8/20], Step [93/124], Loss: 0.0012\n","Epoch [8/20], Step [124/124], Loss: 0.0006\n","Training Accuracy: 0.99953\n","Testing Accuracy: [0.5  0.4  0.28 0.44 0.44 0.38 0.52 0.46 0.52]\n","Testing Accuracy Average: 0.43778\n","Epoch [9/20], Step [31/124], Loss: 0.0003\n","Epoch [9/20], Step [62/124], Loss: 0.1775\n","Epoch [9/20], Step [93/124], Loss: 0.0698\n","Epoch [9/20], Step [124/124], Loss: 0.1361\n","Training Accuracy: 0.98529\n","Testing Accuracy: [0.42 0.34 0.32 0.44 0.38 0.32 0.44 0.4  0.48]\n","Testing Accuracy Average: 0.39333\n","Epoch [10/20], Step [31/124], Loss: 0.0142\n","Epoch [10/20], Step [62/124], Loss: 0.0046\n","Epoch [10/20], Step [93/124], Loss: 0.1439\n","Epoch [10/20], Step [124/124], Loss: 0.1045\n","Training Accuracy: 0.98767\n","Testing Accuracy: [0.42 0.42 0.34 0.44 0.36 0.34 0.5  0.46 0.38]\n","Testing Accuracy Average: 0.40667\n","Epoch [11/20], Step [31/124], Loss: 0.0055\n","Epoch [11/20], Step [62/124], Loss: 0.0015\n","Epoch [11/20], Step [93/124], Loss: 0.0706\n","Epoch [11/20], Step [124/124], Loss: 0.0361\n","Training Accuracy: 0.99004\n","Testing Accuracy: [0.42 0.38 0.44 0.38 0.32 0.34 0.48 0.38 0.42]\n","Testing Accuracy Average: 0.39556\n","Epoch [12/20], Step [31/124], Loss: 0.0632\n","Epoch [12/20], Step [62/124], Loss: 0.0069\n","Epoch [12/20], Step [93/124], Loss: 0.0289\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [12/20], Step [124/124], Loss: 0.0151\n","Training Accuracy: 0.99953\n","Testing Accuracy: [0.4  0.32 0.24 0.36 0.44 0.32 0.44 0.42 0.44]\n","Testing Accuracy Average: 0.37556\n","Epoch [13/20], Step [31/124], Loss: 0.0050\n","Epoch [13/20], Step [62/124], Loss: 0.0005\n","Epoch [13/20], Step [93/124], Loss: 0.0005\n","Epoch [13/20], Step [124/124], Loss: 0.0013\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.44 0.38 0.28 0.36 0.38 0.4  0.44 0.48 0.38]\n","Testing Accuracy Average: 0.39333\n","Epoch [14/20], Step [31/124], Loss: 0.0006\n","Epoch [14/20], Step [62/124], Loss: 0.0005\n","Epoch [14/20], Step [93/124], Loss: 0.0002\n","Epoch [14/20], Step [124/124], Loss: 0.0002\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.46 0.38 0.28 0.4  0.4  0.38 0.44 0.48 0.44]\n","Testing Accuracy Average: 0.40667\n","Epoch [15/20], Step [31/124], Loss: 0.0005\n","Epoch [15/20], Step [62/124], Loss: 0.0005\n","Epoch [15/20], Step [93/124], Loss: 0.0003\n","Epoch [15/20], Step [124/124], Loss: 0.0000\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.48 0.38 0.28 0.4  0.4  0.36 0.44 0.48 0.44]\n","Testing Accuracy Average: 0.40667\n","Epoch [16/20], Step [31/124], Loss: 0.0000\n","Epoch [16/20], Step [62/124], Loss: 0.0003\n","Epoch [16/20], Step [93/124], Loss: 0.0004\n","Epoch [16/20], Step [124/124], Loss: 0.0002\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.48 0.38 0.28 0.4  0.42 0.38 0.44 0.48 0.44]\n","Testing Accuracy Average: 0.41111\n","Epoch [17/20], Step [31/124], Loss: 0.0001\n","Epoch [17/20], Step [62/124], Loss: 0.0003\n","Epoch [17/20], Step [93/124], Loss: 0.0001\n","Epoch [17/20], Step [124/124], Loss: 0.0001\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.48 0.38 0.28 0.4  0.42 0.38 0.44 0.48 0.44]\n","Testing Accuracy Average: 0.41111\n","Epoch [18/20], Step [31/124], Loss: 0.0001\n","Epoch [18/20], Step [62/124], Loss: 0.0002\n","Epoch [18/20], Step [93/124], Loss: 0.0002\n","Epoch [18/20], Step [124/124], Loss: 0.0002\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.46 0.38 0.3  0.4  0.4  0.38 0.44 0.48 0.44]\n","Testing Accuracy Average: 0.40889\n","Epoch [19/20], Step [31/124], Loss: 0.0002\n","Epoch [19/20], Step [62/124], Loss: 0.0001\n","Epoch [19/20], Step [93/124], Loss: 0.0001\n","Epoch [19/20], Step [124/124], Loss: 0.0002\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.48 0.38 0.3  0.4  0.4  0.38 0.44 0.5  0.44]\n","Testing Accuracy Average: 0.41333\n","Epoch [20/20], Step [31/124], Loss: 0.0000\n","Epoch [20/20], Step [62/124], Loss: 0.0000\n","Epoch [20/20], Step [93/124], Loss: 0.0002\n","Epoch [20/20], Step [124/124], Loss: 0.0001\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.48 0.38 0.3  0.4  0.4  0.38 0.44 0.5  0.44]\n","Testing Accuracy Average: 0.41333\n"],"name":"stdout"}]},{"metadata":{"id":"2JwUcaseoXXV","colab_type":"text"},"cell_type":"markdown","source":["###Print MATLAB Format"]},{"metadata":{"id":"0nSce2gzkAZa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Print Loss\n","print('Loss = [', end='')\n","for lossval in np.nditer(loss_arr):\n","  print('%.5f, ' % lossval, end='')\n","print('];')\n","\n","# Print Training Accuracy\n","print('Training_Accuracy = [', end='')\n","for acc in np.nditer(training_acc_arr):\n","  print('%.5f, ' % acc, end='')\n","print('];')\n","\n","# Print Testing Accuracy\n","print('Testing_Accuracy = [', end='')\n","for subject in range(9):\n","  for acc in np.nditer(testing_acc_arr[subject, :]):\n","    print('%.5f, ' % acc, end='')\n","  print('; ', end='')\n","print('];')"],"execution_count":0,"outputs":[]}]}