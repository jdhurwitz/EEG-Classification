{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"subject_framework.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":["55Aaa8JmQZpb","grXwmYxOv27g"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"sNbiI9AOPlq6","colab_type":"text"},"cell_type":"markdown","source":["# Neural Network Testing Framework\n","This notebook is intended to be a general framework for testing Neural Neworks on the EEG data set. While the initial iteration of this notebook is used for a simple Convolutional Neural Network (CNN), other networks using PyTorch can be implemented and assigned to the neural network variable. Many of the beginning cells are used to intialize for a Google Drive Colaboratory notebook GPU usability and can be ignored as necessary.\n","\n","---\n","\n"]},{"metadata":{"id":"2hlystw2Pzbg","colab_type":"text"},"cell_type":"markdown","source":["##Initialization\n","Google Drive access, PyTorch, etc."]},{"metadata":{"id":"aEly-WUNrG_n","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!kill -9 -1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3_ioKx_tQsFg","colab_type":"text"},"cell_type":"markdown","source":["This section provides access to the user's Google drive."]},{"metadata":{"id":"nyJiSCniN5Sn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":4}],"base_uri":"https://localhost:8080/","height":107},"outputId":"d06d7138-21e6-41f4-bf05-78174656e684","executionInfo":{"status":"ok","timestamp":1521067435323,"user_tz":420,"elapsed":9944,"user":{"displayName":"Nathan Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"106327691903472177650"}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"eADEBx-EQNg5","colab_type":"text"},"cell_type":"markdown","source":["This section creates a drive that links to the user's Google drive."]},{"metadata":{"id":"YzXqllGHQK6E","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":52},"outputId":"b318d771-d1b9-4ad9-969a-eb94d3fdbfbb","executionInfo":{"status":"ok","timestamp":1521067666530,"user_tz":420,"elapsed":1693,"user":{"displayName":"Nathan Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"106327691903472177650"}}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":9,"outputs":[{"output_type":"stream","text":["fuse: mountpoint is not empty\r\n","fuse: if you are sure this is safe, use the 'nonempty' mount option\r\n"],"name":"stdout"}]},{"metadata":{"id":"jUfqAB83QuPc","colab_type":"text"},"cell_type":"markdown","source":["This section installs PyTorch."]},{"metadata":{"id":"vS4vRAnsQw2J","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# http://pytorch.org/\n","from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LaZWU_TlQ7Yx","colab_type":"text"},"cell_type":"markdown","source":["##Imports"]},{"metadata":{"id":"Uo96B36sQURz","colab_type":"text"},"cell_type":"markdown","source":["Imports can be added as necessary."]},{"metadata":{"id":"UgT3bxtlRT0U","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","import h5py\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.cuda\n","from torch.utils.data import Dataset\n","from torch.autograd import Variable\n","from scipy import stats"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RoLPc0SzSM2_","colab_type":"text"},"cell_type":"markdown","source":["##Classes"]},{"metadata":{"id":"55Aaa8JmQZpb","colab_type":"text"},"cell_type":"markdown","source":["###EEGDataset\n","This class inherits the torch.utils.data.Dataset class to be used with the torch.utils.data.Dataloader class."]},{"metadata":{"id":"ak2uqN0pSPZL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class EEGDataset(Dataset):\n","  \"\"\"EEG dataset.\"\"\"\n","  \n","  def __init__(self, x, y, transform=None):\n","    \"\"\"\n","    Args:\n","      x (numpy array): Input data of shape \n","                       num_trials x num_electrodes x num_time_bins.\n","      y (numpy array): Output data of shape num_trials x 1.\n","      transform (callable, optional): Optional transform to be applied.\n","    \"\"\"\n","    self.x = x\n","    self.y = y\n","    self.transform = transform\n","    \n","  def __len__(self):\n","    return len(self.x)\n","  \n","  def __getitem__(self, idx):\n","    x_sample = torch.from_numpy(self.x[idx])\n","    y_sample = torch.IntTensor([int(self.y[idx])])\n","    \n","    if self.transform:\n","      pass #FIXME\n","    \n","    return x_sample, y_sample"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PjPbOPYgQj0f","colab_type":"text"},"cell_type":"markdown","source":["###EEGMinimalContainer\n","This class holds a train and test EEGDataset. It processes the data into a (N, C, H, W) format in time."]},{"metadata":{"id":"6dk7JLAftaXB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class EEGMinimalContainer():\n","  \"\"\"EEG container for training and testing datasets.\"\"\"\n","  \n","  def __init__(self, data_dir, train_subject, seed=42):\n","    \"\"\"\n","    Args:\n","      data_dir (string): Path to all A0iT_slice.mat files for i in [1, 9].\n","      train_subject(int): Subject to train on. If None, train on all.\n","      test_subject(int): Subject to test on. If None, test on all except for\n","                         train_subject. Only used if train_subject is not None.\n","    \"\"\"\n","    self.X_train = None\n","    self.y_train = None\n","    self.X_test = None\n","    self.y_test = None\n","    self.train_dataset = None\n","    self.test_dataset = None\n","    np.random.seed(seed)\n","    \n","    # Step 1: Obtain Training Set\n","    A0iT = h5py.File(data_dir + ('/A0%dT_slice.mat' % (train_subject)), 'r')\n","    X = np.copy(A0iT['image'])\n","    X = np.expand_dims(X, axis=1)\n","    X = X[:, :, 0:22, :] \n","    y = np.copy(A0iT['type'])\n","    y = y[0,0:X.shape[0]:1]\n","    y = np.asarray(y, dtype=np.int32)\n","    y -= 769\n","    remove_list = []\n","    for i in range(len(X)):\n","      if np.isnan(X[i]).any():\n","        remove_list.append(i)\n","    X = np.delete(X, remove_list, axis=0)\n","    y = np.delete(y, remove_list, axis=0)\n","    self.X_train = X\n","    self.y_train = y\n","    self.train_dataset = EEGDataset(X, y)\n","    # Step 2: Obtain Test Set\n","    self.X_test = {}\n","    self.y_test = {}\n","    self.test_dataset = {}\n","    for i in np.arange(1, 10):\n","      if i == train_subject:\n","        continue\n","      A0iT = h5py.File(data_dir + ('/A0%dT_slice.mat' % (i)), 'r')\n","      X = np.copy(A0iT['image'])\n","      X = np.expand_dims(X, axis=1)\n","      X = X[:, :, 0:22, :] \n","      y = np.copy(A0iT['type'])\n","      y = y[0,0:X.shape[0]:1]\n","      y = np.asarray(y, dtype=np.int32)\n","      y -= 769\n","      remove_list = []\n","      for j in range(len(X)):\n","        if np.isnan(X[j]).any():\n","          remove_list.append(j)\n","      X = np.delete(X, remove_list, axis=0)\n","      y = np.delete(y, remove_list, axis=0)\n","      self.X_test[str(i)] = X\n","      self.y_test[str(i)] = y\n","      self.test_dataset[str(i)] = EEGDataset(X, y)\n","      \n","    print('EEGContainer X_train: ' + str(self.X_train.shape))\n","    print('EEGContainer y_train: ' + str(self.y_train.shape))\n","    for i in range(1, 10):\n","      if i == train_subject:\n","        continue\n","      print(('EEGContainer X_test%d: ' %i) + str(self.X_test[str(i)].shape))\n","      print(('EEGContainer y_test%d: ' %i) + str(self.y_test[str(i)].shape))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vdkmP_PkYU-B","colab_type":"text"},"cell_type":"markdown","source":["###Convolutional Neural Network"]},{"metadata":{"id":"2yZwUujCMnGB","colab_type":"text"},"cell_type":"markdown","source":["###CNN"]},{"metadata":{"id":"bq6nPGoGMlbI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class CNN(nn.Module):\n","  def __init__(self):\n","    super(CNN, self).__init__()\n","    self.conv1 = nn.Conv2d( 1, 16, (1, 11), stride=(1, 1), padding=0)\n","    self.conv2 = nn.Conv2d(16, 16, (22, 1), stride=(1, 1), padding=0)\n","    self.conv3 = nn.Conv2d( 1, 16, (1, 11), stride=(1, 1), padding=0)\n","    self.conv4 = nn.Conv2d(16, 16, (16, 1), stride=(1, 1), padding=0)\n","    self.conv5 = nn.Conv2d( 1, 16, 3, stride=1, padding=1)\n","    self.conv6 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n","    self.conv7 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n","    self.fc1 = nn.Linear(64 * 2 * 10, 200)\n","    self.fc2 = nn.Linear(200, 100)\n","    self.fc3 = nn.Linear(100, 4)\n","  \n","  def forward(self, x):\n","    dropval = 0.7\n","    x = F.dropout2d(F.relu(self.conv1(x)), p=0.2)\n","    x = F.dropout2d(F.relu(self.conv2(x)), p=dropval)\n","    x = x.permute(0, 2, 1, 3)\n","    x = F.max_pool2d(x, (1, 3), (1, 3))\n","    x = F.dropout2d(F.relu(self.conv3(x)), p=dropval)\n","    x = F.dropout2d(F.relu(self.conv4(x)), p=dropval)\n","    x = x.permute(0, 2, 1, 3)\n","    x = F.max_pool2d(x, (1, 4), (1, 4))\n","    x = F.dropout2d(F.relu(self.conv5(x)), p=dropval)\n","    x = F.max_pool2d(x, 2, 2)\n","    x = F.dropout2d(F.relu(self.conv6(x)), p=dropval)\n","    x = F.max_pool2d(x, 2, 2)\n","    x = F.dropout2d(F.relu(self.conv7(x)), p=dropval)\n","    x = F.max_pool2d(x, 2, 2)\n","    x = x.view(-1, 64 * 2 * 10)\n","    x = F.dropout(F.relu(self.fc1(x)), p=dropval)\n","    x = F.dropout(F.relu(self.fc2(x)), p=dropval)\n","    x = self.fc3(x)\n","    return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bQQ6aLypwDGe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":55},"outputId":"6196ba09-201d-4c6b-aa57-a088d3d65dda","executionInfo":{"status":"ok","timestamp":1521070773828,"user_tz":420,"elapsed":325,"user":{"displayName":"Nathan Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"106327691903472177650"}}},"cell_type":"code","source":["'''\n","# N x 1 x 22 x 534\n","class CNN(nn.Module):\n","  def __init__(self):\n","    super(CNN, self).__init__()\n","    self.conv1 = nn.Conv2d( 1, 40, (1, 25))\n","    #nn.init.xavier_uniform(self.conv1.weight)\n","    self.bnc1 = nn.BatchNorm2d(40)\n","    self.conv2 = nn.Conv2d(40, 40, (22, 1))\n","    #nn.init.xavier_uniform(self.conv2.weight)\n","    self.bnc2 = nn.BatchNorm2d(40)\n","    self.fc = nn.Linear(30 * 40, 4)\n","    #nn.init.xavier_uniform(self.fc.weight)\n","  \n","  def forward(self, x):\n","    x = F.elu(self.bnc1(self.conv1(x)))\n","    x = F.elu(self.bnc2(self.conv2(x)))\n","    x = F.dropout2d(x, p=0.5)\n","    x = F.max_pool2d(x.permute(0, 2, 1, 3), (1, 75), stride=(1, 15))\n","    x = x.view(-1, 30 * 40)\n","    x = self.fc(x)\n","    return x\n","'''"],"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# N x 1 x 22 x 534\\nclass CNN(nn.Module):\\n  def __init__(self):\\n    super(CNN, self).__init__()\\n    self.conv1 = nn.Conv2d( 1, 40, (1, 25))\\n    #nn.init.xavier_uniform(self.conv1.weight)\\n    self.bnc1 = nn.BatchNorm2d(40)\\n    self.conv2 = nn.Conv2d(40, 40, (22, 1))\\n    #nn.init.xavier_uniform(self.conv2.weight)\\n    self.bnc2 = nn.BatchNorm2d(40)\\n    self.fc = nn.Linear(30 * 40, 4)\\n    #nn.init.xavier_uniform(self.fc.weight)\\n  \\n  def forward(self, x):\\n    x = F.elu(self.bnc1(self.conv1(x)))\\n    x = F.elu(self.bnc2(self.conv2(x)))\\n    x = F.dropout2d(x, p=0.5)\\n    x = F.max_pool2d(x.permute(0, 2, 1, 3), (1, 75), stride=(1, 15))\\n    x = x.view(-1, 30 * 40)\\n    x = self.fc(x)\\n    return x\\n'"]},"metadata":{"tags":[]},"execution_count":92}]},{"metadata":{"id":"bF93DV3g4nKf","colab_type":"text"},"cell_type":"markdown","source":["##Setup"]},{"metadata":{"id":"ZtX31_wU67Iu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["data_dir = 'drive/ee239as/project_datasets'\n","batch_size = 36\n","train_subject = 9\n","time_batch = 534"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TSyYi0jr5jMk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":334},"outputId":"d3f14e2f-14f4-435b-ec24-0fd16873844e","executionInfo":{"status":"ok","timestamp":1521073899615,"user_tz":420,"elapsed":5944,"user":{"displayName":"Nathan Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"106327691903472177650"}}},"cell_type":"code","source":["EEGset = EEGMinimalContainer(data_dir, train_subject)"],"execution_count":164,"outputs":[{"output_type":"stream","text":["EEGContainer X_train: (278, 1, 22, 1000)\n","EEGContainer y_train: (278,)\n","EEGContainer X_test1: (287, 1, 22, 1000)\n","EEGContainer y_test1: (287,)\n","EEGContainer X_test2: (286, 1, 22, 1000)\n","EEGContainer y_test2: (286,)\n","EEGContainer X_test3: (286, 1, 22, 1000)\n","EEGContainer y_test3: (286,)\n","EEGContainer X_test4: (284, 1, 22, 1000)\n","EEGContainer y_test4: (284,)\n","EEGContainer X_test5: (282, 1, 22, 1000)\n","EEGContainer y_test5: (282,)\n","EEGContainer X_test6: (285, 1, 22, 1000)\n","EEGContainer y_test6: (285,)\n","EEGContainer X_test7: (288, 1, 22, 1000)\n","EEGContainer y_test7: (288,)\n","EEGContainer X_test8: (282, 1, 22, 1000)\n","EEGContainer y_test8: (282,)\n"],"name":"stdout"}]},{"metadata":{"id":"R_3tUksmH5ch","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(EEGset.train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","\n","test_loader = {}\n","for i in range(1, 10):\n","  if train_subject == i:\n","    continue\n","  test_loader[str(i)] = torch.utils.data.DataLoader(EEGset.test_dataset[str(i)],\n","                                                    batch_size=batch_size,\n","                                                    shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4DQOGwwWo0TB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["num_epochs = 200\n","learning_rate = 1e-4\n","\n","use_cuda = True\n","\n","net = CNN()\n","criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FdodrAOa6CyS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["if use_cuda and torch.cuda.is_available():\n","  net.cuda()\n","\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-3)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dD4O5-LV7p-M","colab_type":"text"},"cell_type":"markdown","source":["##Training"]},{"metadata":{"id":"GeNQKAq8vznn","colab_type":"text"},"cell_type":"markdown","source":["###For 1000 time units"]},{"metadata":{"id":"xOZTFTO5L6IF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":52},{"item_id":92},{"item_id":107},{"item_id":123},{"item_id":139},{"item_id":167},{"item_id":218},{"item_id":270},{"item_id":322},{"item_id":373},{"item_id":425},{"item_id":476},{"item_id":492},{"item_id":507},{"item_id":522},{"item_id":538},{"item_id":550}],"base_uri":"https://localhost:8080/","height":24657},"outputId":"03311d30-13eb-42ab-fe91-b09732b8d7ac","executionInfo":{"status":"ok","timestamp":1521074147707,"user_tz":420,"elapsed":246880,"user":{"displayName":"Nathan Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"106327691903472177650"}}},"cell_type":"code","source":["training_acc_arr = np.empty(num_epochs)\n","testing_acc_arr = np.empty((9, num_epochs))\n","\n","for epoch in range(num_epochs):\n","  \n","  net.train()\n","  \n","  for i, (signals, labels) in enumerate(train_loader):\n","    \n","    signals = signals.type(torch.FloatTensor)\n","    signals = Variable(signals)\n","    labels = labels.type(torch.LongTensor)\n","    labels = Variable(torch.squeeze(labels))\n","    \n","    if use_cuda and torch.cuda.is_available():\n","      signals = signals.cuda()\n","      labels = labels.cuda()\n","    \n","    optimizer.zero_grad()\n","    outputs = net(signals)\n","    \n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if (i+1) % 2 == 0:\n","      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n","            % (epoch+1, num_epochs, i+1, len(EEGset.train_dataset)//batch_size, \n","               loss.data[0]))\n","  \n","  net.eval()\n","  \n","  # Training accuracy\n","  total = 0\n","  correct = 0\n","  for signals, labels in train_loader:\n","    signals = signals.type(torch.FloatTensor)\n","    signals = Variable(signals)\n","    labels = torch.squeeze(labels.type(torch.LongTensor))\n","    if use_cuda and torch.cuda.is_available():\n","      signals = signals.cuda()\n","      labels = labels.cuda()\n","    outputs = net(signals)\n","    _, predicted = torch.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum()\n","  training_acc_arr[epoch] = (correct/total)\n","  print ('Training Accuracy: %.5f' % training_acc_arr[epoch])\n","  \n","  \n","  # Testing accuracy\n","  print ('Testing Accuracy: [', end='')\n","  avg_total = 0\n","  avg_correct = 0\n","  for subject in range(9):\n","    if subject + 1 == train_subject:\n","      print ('x ', end='')\n","      continue\n","    total = 0\n","    correct = 0\n","    for signals, labels in test_loader[str(subject+1)]:\n","      signals = signals.type(torch.FloatTensor)\n","      signals = Variable(signals)\n","      labels = torch.squeeze(labels.type(torch.LongTensor))\n","      if use_cuda and torch.cuda.is_available():\n","        signals = signals.cuda()\n","        labels = labels.cuda()\n","      outputs = net(signals)\n","      _, predicted = torch.max(outputs.data, 1)\n","      total += labels.size(0)\n","      correct += (predicted == labels).sum()\n","    testing_acc_arr[subject, epoch] = (correct/total)\n","    print ('%.5f ' %(correct/total), end='')\n","    avg_total += total\n","    avg_correct += correct\n","  print (']')\n","  print ('Testing Accuracy Average: %.5f' % (avg_correct/avg_total))"],"execution_count":168,"outputs":[{"output_type":"stream","text":["Epoch [1/200], Step [2/7], Loss: 1.3777\n","Epoch [1/200], Step [4/7], Loss: 1.4018\n","Epoch [1/200], Step [6/7], Loss: 1.3832\n","Epoch [1/200], Step [8/7], Loss: 1.3940\n","Training Accuracy: 0.24460\n","Testing Accuracy: [0.25087 0.24476 0.24825 0.25000 0.25532 0.24912 0.25000 0.25532 x ]\n","Testing Accuracy Average: 0.25044\n","Epoch [2/200], Step [2/7], Loss: 1.3808\n","Epoch [2/200], Step [4/7], Loss: 1.3688\n","Epoch [2/200], Step [6/7], Loss: 1.3854\n","Epoch [2/200], Step [8/7], Loss: 1.3946\n","Training Accuracy: 0.24460\n","Testing Accuracy: [0.25087 0.24476 0.24825 0.25000 0.25532 0.24912 0.25000 0.25532 x ]\n","Testing Accuracy Average: 0.25044\n","Epoch [3/200], Step [2/7], Loss: 1.3973\n","Epoch [3/200], Step [4/7], Loss: 1.3876\n","Epoch [3/200], Step [6/7], Loss: 1.3743\n","Epoch [3/200], Step [8/7], Loss: 1.3740\n","Training Accuracy: 0.24460\n","Testing Accuracy: [0.25087 0.24476 0.24825 0.25000 0.25532 0.24912 0.25000 0.25532 x ]\n","Testing Accuracy Average: 0.25044\n","Epoch [4/200], Step [2/7], Loss: 1.3859\n","Epoch [4/200], Step [4/7], Loss: 1.3728\n","Epoch [4/200], Step [6/7], Loss: 1.3859\n","Epoch [4/200], Step [8/7], Loss: 1.3952\n","Training Accuracy: 0.24460\n","Testing Accuracy: [0.25087 0.24476 0.24825 0.25000 0.25532 0.24912 0.25000 0.25532 x ]\n","Testing Accuracy Average: 0.25044\n","Epoch [5/200], Step [2/7], Loss: 1.3732\n","Epoch [5/200], Step [4/7], Loss: 1.3899\n","Epoch [5/200], Step [6/7], Loss: 1.3938\n","Epoch [5/200], Step [8/7], Loss: 1.3599\n","Training Accuracy: 0.24460\n","Testing Accuracy: [0.25087 0.24476 0.24825 0.25000 0.25532 0.24912 0.25000 0.25532 x ]\n","Testing Accuracy Average: 0.25044\n","Epoch [6/200], Step [2/7], Loss: 1.3897\n","Epoch [6/200], Step [4/7], Loss: 1.3925\n","Epoch [6/200], Step [6/7], Loss: 1.3763\n","Epoch [6/200], Step [8/7], Loss: 1.3528\n","Training Accuracy: 0.24820\n","Testing Accuracy: [0.25436 0.24476 0.24825 0.25000 0.28723 0.24561 0.28125 0.25532 x ]\n","Testing Accuracy Average: 0.25833\n","Epoch [7/200], Step [2/7], Loss: 1.3936\n","Epoch [7/200], Step [4/7], Loss: 1.3726\n","Epoch [7/200], Step [6/7], Loss: 1.3807\n","Epoch [7/200], Step [8/7], Loss: 1.3747\n","Training Accuracy: 0.24460\n","Testing Accuracy: [0.25436 0.24476 0.24825 0.25000 0.30142 0.24912 0.27778 0.25532 x ]\n","Testing Accuracy Average: 0.26009\n","Epoch [8/200], Step [2/7], Loss: 1.3734\n","Epoch [8/200], Step [4/7], Loss: 1.3785\n","Epoch [8/200], Step [6/7], Loss: 1.3809\n","Epoch [8/200], Step [8/7], Loss: 1.3790\n","Training Accuracy: 0.28417\n","Testing Accuracy: [0.29617 0.28671 0.28322 0.33099 0.26596 0.23509 0.30556 0.28723 x ]\n","Testing Accuracy Average: 0.28640\n","Epoch [9/200], Step [2/7], Loss: 1.3713\n","Epoch [9/200], Step [4/7], Loss: 1.3670\n","Epoch [9/200], Step [6/7], Loss: 1.3572\n","Epoch [9/200], Step [8/7], Loss: 1.3646\n","Training Accuracy: 0.32734\n","Testing Accuracy: [0.29965 0.29021 0.31469 0.29225 0.24113 0.22807 0.28125 0.31560 x ]\n","Testing Accuracy Average: 0.28289\n","Epoch [10/200], Step [2/7], Loss: 1.3600\n","Epoch [10/200], Step [4/7], Loss: 1.3347\n","Epoch [10/200], Step [6/7], Loss: 1.3452\n","Epoch [10/200], Step [8/7], Loss: 1.3372\n","Training Accuracy: 0.36691\n","Testing Accuracy: [0.29617 0.29720 0.29720 0.32746 0.23759 0.24912 0.28472 0.30851 x ]\n","Testing Accuracy Average: 0.28728\n","Epoch [11/200], Step [2/7], Loss: 1.3489\n","Epoch [11/200], Step [4/7], Loss: 1.3060\n","Epoch [11/200], Step [6/7], Loss: 1.3335\n","Epoch [11/200], Step [8/7], Loss: 1.2626\n","Training Accuracy: 0.39928\n","Testing Accuracy: [0.33449 0.30769 0.31119 0.33099 0.26596 0.23158 0.28125 0.30851 x ]\n","Testing Accuracy Average: 0.29649\n","Epoch [12/200], Step [2/7], Loss: 1.3148\n","Epoch [12/200], Step [4/7], Loss: 1.3163\n","Epoch [12/200], Step [6/7], Loss: 1.2295\n","Epoch [12/200], Step [8/7], Loss: 1.2663\n","Training Accuracy: 0.43525\n","Testing Accuracy: [0.34843 0.31119 0.31119 0.36620 0.27660 0.24211 "],"name":"stdout"},{"output_type":"stream","text":["0.26736 0.32624 x ]\n","Testing Accuracy Average: 0.30614\n","Epoch [13/200], Step [2/7], Loss: 1.2366\n","Epoch [13/200], Step [4/7], Loss: 1.2221\n","Epoch [13/200], Step [6/7], Loss: 1.3253\n","Epoch [13/200], Step [8/7], Loss: 1.3210\n","Training Accuracy: 0.50719\n","Testing Accuracy: [0.33101 0.31119 0.31818 0.30986 0.28014 0.26667 0.28819 0.34397 x ]\n","Testing Accuracy Average: 0.30614\n","Epoch [14/200], Step [2/7], Loss: 1.3193\n","Epoch [14/200], Step [4/7], Loss: 1.0889\n","Epoch [14/200], Step [6/7], Loss: 1.1387\n","Epoch [14/200], Step [8/7], Loss: 1.0991\n","Training Accuracy: 0.46763\n","Testing Accuracy: [0.31010 0.29720 0.30070 0.35915 0.28369 0.24561 0.27778 0.32624 x ]\n","Testing Accuracy Average: 0.30000\n","Epoch [15/200], Step [2/7], Loss: 1.1277\n","Epoch [15/200], Step [4/7], Loss: 1.1799\n","Epoch [15/200], Step [6/7], Loss: 1.3172\n","Epoch [15/200], Step [8/7], Loss: 1.2206\n","Training Accuracy: 0.44604\n","Testing Accuracy: [0.34146 0.33916 0.29371 0.36268 0.29787 0.24211 0.27778 0.31915 x ]\n","Testing Accuracy Average: 0.30921\n","Epoch [16/200], Step [2/7], Loss: 1.1987\n","Epoch [16/200], Step [4/7], Loss: 1.2334\n","Epoch [16/200], Step [6/7], Loss: 1.1395\n","Epoch [16/200], Step [8/7], Loss: 1.0400\n","Training Accuracy: 0.51079\n","Testing Accuracy: [0.33798 0.27972 0.31469 0.32394 0.29787 0.28421 0.27431 0.31560 x ]\n","Testing Accuracy Average: 0.30351\n","Epoch [17/200], Step [2/7], Loss: 1.0054\n","Epoch [17/200], Step [4/7], Loss: 1.0737\n","Epoch [17/200], Step [6/7], Loss: 1.1173\n","Epoch [17/200], Step [8/7], Loss: 1.0874\n","Training Accuracy: 0.51079\n","Testing Accuracy: [0.35192 0.31469 0.33916 0.36972 0.25887 0.21754 0.27431 0.34397 x ]\n","Testing Accuracy Average: 0.30877\n","Epoch [18/200], Step [2/7], Loss: 1.1141\n","Epoch [18/200], Step [4/7], Loss: 1.0416\n","Epoch [18/200], Step [6/7], Loss: 1.0119\n","Epoch [18/200], Step [8/7], Loss: 1.1625\n","Training Accuracy: 0.53957\n","Testing Accuracy: [0.36934 0.29720 0.32168 0.34859 0.27660 0.23860 0.24653 0.30851 x ]\n","Testing Accuracy Average: 0.30088\n","Epoch [19/200], Step [2/7], Loss: 0.9641\n","Epoch [19/200], Step [4/7], Loss: 1.0102\n","Epoch [19/200], Step [6/7], Loss: 1.0779\n","Epoch [19/200], Step [8/7], Loss: 1.1957\n","Training Accuracy: 0.57914\n","Testing Accuracy: [0.32404 0.25874 0.29371 0.35915 0.25532 0.26667 0.23264 0.31206 x ]\n","Testing Accuracy Average: 0.28772\n","Epoch [20/200], Step [2/7], Loss: 1.1160\n","Epoch [20/200], Step [4/7], Loss: 1.0962\n","Epoch [20/200], Step [6/7], Loss: 1.0514\n","Epoch [20/200], Step [8/7], Loss: 1.1215\n","Training Accuracy: 0.55036\n","Testing Accuracy: [0.36585 0.28671 0.31818 0.36268 0.26596 0.23860 0.24306 0.33333 x ]\n","Testing Accuracy Average: 0.30175\n","Epoch [21/200], Step [2/7], Loss: 0.8736\n","Epoch [21/200], Step [4/7], Loss: 0.9973\n","Epoch [21/200], Step [6/7], Loss: 1.0067\n","Epoch [21/200], Step [8/7], Loss: 1.0470\n","Training Accuracy: 0.58273\n","Testing Accuracy: [0.36237 0.25874 0.32867 0.35211 0.25177 0.22807 0.22917 0.31560 x ]\n","Testing Accuracy Average: 0.29079\n","Epoch [22/200], Step [2/7], Loss: 0.9384\n","Epoch [22/200], Step [4/7], Loss: 1.0986\n","Epoch [22/200], Step [6/7], Loss: 1.0462\n","Epoch [22/200], Step [8/7], Loss: 0.8328\n","Training Accuracy: 0.58633\n","Testing Accuracy: [0.30662 0.26224 0.27622 0.32042 0.26950 0.26667 0.22222 0.32979 x ]\n","Testing Accuracy Average: 0.28158\n","Epoch [23/200], Step [2/7], Loss: 0.8948\n","Epoch [23/200], Step [4/7], Loss: 1.0474\n","Epoch [23/200], Step [6/7], Loss: 0.8357\n","Epoch [23/200], Step [8/7], Loss: 1.1829\n","Training Accuracy: 0.61871\n","Testing Accuracy: [0.36585 0.25175 0.34965 0.35211 0.24468 0.23509 0.22222 0.32979 x ]\n","Testing Accuracy Average: 0.29386\n","Epoch [24/200], Step [2/7], Loss: 0.9884\n","Epoch [24/200], Step [4/7], Loss: 0.9071\n","Epoch [24/200], Step [6/7], Loss: 0.8993\n","Epoch [24/200], Step [8/7], Loss: 0.9959\n","Training Accuracy: 0.61871\n","Testing Accuracy: [0.35192 0.25874 0.32867 "],"name":"stdout"},{"output_type":"stream","text":["0.34859 0.26241 0.22105 0.24653 0.32270 x ]\n","Testing Accuracy Average: 0.29254\n","Epoch [25/200], Step [2/7], Loss: 0.8424\n","Epoch [25/200], Step [4/7], Loss: 0.9901\n","Epoch [25/200], Step [6/7], Loss: 0.9131\n","Epoch [25/200], Step [8/7], Loss: 0.9988\n","Training Accuracy: 0.64029\n","Testing Accuracy: [0.29268 0.22378 0.30769 0.30282 0.25887 0.28070 0.21875 0.30851 x ]\n","Testing Accuracy Average: 0.27412\n","Epoch [26/200], Step [2/7], Loss: 0.8275\n","Epoch [26/200], Step [4/7], Loss: 0.8964\n","Epoch [26/200], Step [6/7], Loss: 1.1592\n","Epoch [26/200], Step [8/7], Loss: 0.9194\n","Training Accuracy: 0.65108\n","Testing Accuracy: [0.33101 0.25524 0.34266 0.35563 0.25532 0.24561 0.22569 0.32624 x ]\n","Testing Accuracy Average: 0.29211\n","Epoch [27/200], Step [2/7], Loss: 0.9181\n","Epoch [27/200], Step [4/7], Loss: 1.0671\n","Epoch [27/200], Step [6/7], Loss: 0.9291\n","Epoch [27/200], Step [8/7], Loss: 0.8475\n","Training Accuracy: 0.65468\n","Testing Accuracy: [0.32404 0.21678 0.33566 0.31690 0.26596 0.23158 0.22917 0.32270 x ]\n","Testing Accuracy Average: 0.28026\n","Epoch [28/200], Step [2/7], Loss: 0.9258\n","Epoch [28/200], Step [4/7], Loss: 0.9035\n","Epoch [28/200], Step [6/7], Loss: 0.9237\n","Epoch [28/200], Step [8/7], Loss: 0.8265\n","Training Accuracy: 0.61151\n","Testing Accuracy: [0.29268 0.27972 0.26573 0.27465 0.25887 0.27368 0.23264 0.31915 x ]\n","Testing Accuracy Average: 0.27456\n","Epoch [29/200], Step [2/7], Loss: 0.8884\n","Epoch [29/200], Step [4/7], Loss: 0.6437\n","Epoch [29/200], Step [6/7], Loss: 1.1590\n","Epoch [29/200], Step [8/7], Loss: 0.7871\n","Training Accuracy: 0.64748\n","Testing Accuracy: [0.30662 0.26923 0.30070 0.29577 0.25532 0.29123 0.22917 0.30142 x ]\n","Testing Accuracy Average: 0.28114\n","Epoch [30/200], Step [2/7], Loss: 1.0018\n","Epoch [30/200], Step [4/7], Loss: 0.8889\n","Epoch [30/200], Step [6/7], Loss: 0.8073\n","Epoch [30/200], Step [8/7], Loss: 0.8157\n","Training Accuracy: 0.66187\n","Testing Accuracy: [0.35540 0.24476 0.34965 0.34859 0.25887 0.23158 0.22917 0.34752 x ]\n","Testing Accuracy Average: 0.29561\n","Epoch [31/200], Step [2/7], Loss: 1.0112\n","Epoch [31/200], Step [4/7], Loss: 0.8840\n","Epoch [31/200], Step [6/7], Loss: 0.7458\n","Epoch [31/200], Step [8/7], Loss: 0.7965\n","Training Accuracy: 0.71223\n","Testing Accuracy: [0.32056 0.26573 0.31119 0.29577 0.25887 0.27719 0.22917 0.36525 x ]\n","Testing Accuracy Average: 0.29035\n","Epoch [32/200], Step [2/7], Loss: 0.9443\n","Epoch [32/200], Step [4/7], Loss: 0.7281\n","Epoch [32/200], Step [6/7], Loss: 0.8771\n","Epoch [32/200], Step [8/7], Loss: 0.7216\n","Training Accuracy: 0.72302\n","Testing Accuracy: [0.32753 0.26224 0.33217 0.27817 0.26241 0.27368 0.22569 0.31206 x ]\n","Testing Accuracy Average: 0.28421\n","Epoch [33/200], Step [2/7], Loss: 0.7641\n","Epoch [33/200], Step [4/7], Loss: 0.6573\n","Epoch [33/200], Step [6/7], Loss: 0.7546\n","Epoch [33/200], Step [8/7], Loss: 0.8339\n","Training Accuracy: 0.71223\n","Testing Accuracy: [0.31707 0.22727 0.31119 0.32042 0.25887 0.29123 0.22222 0.36525 x ]\n","Testing Accuracy Average: 0.28904\n","Epoch [34/200], Step [2/7], Loss: 0.7931\n","Epoch [34/200], Step [4/7], Loss: 0.7281\n","Epoch [34/200], Step [6/7], Loss: 0.7683\n","Epoch [34/200], Step [8/7], Loss: 0.8272\n","Training Accuracy: 0.70504\n","Testing Accuracy: [0.32404 0.25524 0.32867 0.27817 0.25887 0.25614 0.23264 0.35106 x ]\n","Testing Accuracy Average: 0.28553\n","Epoch [35/200], Step [2/7], Loss: 0.8892\n","Epoch [35/200], Step [4/7], Loss: 0.7169\n","Epoch [35/200], Step [6/7], Loss: 0.7885\n","Epoch [35/200], Step [8/7], Loss: 0.5947\n","Training Accuracy: 0.73381\n","Testing Accuracy: [0.30662 0.26224 0.30070 0.27817 0.25887 0.29474 0.21875 0.31560 x ]\n","Testing Accuracy Average: 0.27939\n","Epoch [36/200], Step [2/7], Loss: 0.8178\n","Epoch [36/200], Step [4/7], Loss: 0.6228\n","Epoch [36/200], Step [6/7], Loss: 0.7089\n","Epoch [36/200], Step [8/7], Loss: 0.6899\n","Training Accuracy: 0.74101\n","Testing Accuracy: [0.32404 0.26573 0.32517 "],"name":"stdout"},{"output_type":"stream","text":["0.28169 0.25887 0.30175 0.21528 0.35461 x ]\n","Testing Accuracy Average: 0.29079\n","Epoch [37/200], Step [2/7], Loss: 0.6881\n","Epoch [37/200], Step [4/7], Loss: 0.8126\n","Epoch [37/200], Step [6/7], Loss: 0.7892\n","Epoch [37/200], Step [8/7], Loss: 0.6732\n","Training Accuracy: 0.71583\n","Testing Accuracy: [0.34495 0.24825 0.33566 0.28521 0.25532 0.24561 0.21875 0.34043 x ]\n","Testing Accuracy Average: 0.28421\n","Epoch [38/200], Step [2/7], Loss: 0.7314\n","Epoch [38/200], Step [4/7], Loss: 0.8533\n","Epoch [38/200], Step [6/7], Loss: 0.7679\n","Epoch [38/200], Step [8/7], Loss: 0.5792\n","Training Accuracy: 0.75180\n","Testing Accuracy: [0.33101 0.25874 0.34266 0.27465 0.25532 0.28772 0.21528 0.35106 x ]\n","Testing Accuracy Average: 0.28947\n","Epoch [39/200], Step [2/7], Loss: 0.5561\n","Epoch [39/200], Step [4/7], Loss: 0.7199\n","Epoch [39/200], Step [6/7], Loss: 0.7042\n","Epoch [39/200], Step [8/7], Loss: 0.5737\n","Training Accuracy: 0.75899\n","Testing Accuracy: [0.31010 0.26224 0.30420 0.27465 0.25532 0.29825 0.22222 0.36525 x ]\n","Testing Accuracy Average: 0.28640\n","Epoch [40/200], Step [2/7], Loss: 0.6580\n","Epoch [40/200], Step [4/7], Loss: 0.6756\n","Epoch [40/200], Step [6/7], Loss: 0.5911\n","Epoch [40/200], Step [8/7], Loss: 0.5232\n","Training Accuracy: 0.72662\n","Testing Accuracy: [0.34146 0.23427 0.33916 0.32746 0.26241 0.27018 0.22917 0.34397 x ]\n","Testing Accuracy Average: 0.29342\n","Epoch [41/200], Step [2/7], Loss: 0.7210\n","Epoch [41/200], Step [4/7], Loss: 0.6861\n","Epoch [41/200], Step [6/7], Loss: 0.7285\n","Epoch [41/200], Step [8/7], Loss: 0.8225\n","Training Accuracy: 0.72662\n","Testing Accuracy: [0.34843 0.24476 0.36014 0.28873 0.25887 0.26667 0.23611 0.36525 x ]\n","Testing Accuracy Average: 0.29605\n","Epoch [42/200], Step [2/7], Loss: 0.7700\n","Epoch [42/200], Step [4/7], Loss: 0.5788\n","Epoch [42/200], Step [6/7], Loss: 0.5588\n","Epoch [42/200], Step [8/7], Loss: 0.8484\n","Training Accuracy: 0.76978\n","Testing Accuracy: [0.29965 0.25175 0.28671 0.27113 0.25532 0.30526 0.22222 0.30496 x ]\n","Testing Accuracy Average: 0.27456\n","Epoch [43/200], Step [2/7], Loss: 0.5769\n","Epoch [43/200], Step [4/7], Loss: 0.6246\n","Epoch [43/200], Step [6/7], Loss: 0.7700\n","Epoch [43/200], Step [8/7], Loss: 0.6469\n","Training Accuracy: 0.79496\n","Testing Accuracy: [0.32404 0.25524 0.33566 0.27465 0.26241 0.29123 0.22917 0.35106 x ]\n","Testing Accuracy Average: 0.29035\n","Epoch [44/200], Step [2/7], Loss: 0.6683\n","Epoch [44/200], Step [4/7], Loss: 0.7601\n","Epoch [44/200], Step [6/7], Loss: 0.5930\n","Epoch [44/200], Step [8/7], Loss: 0.4747\n","Training Accuracy: 0.78417\n","Testing Accuracy: [0.30314 0.24476 0.29371 0.26408 0.25532 0.30877 0.22569 0.31560 x ]\n","Testing Accuracy Average: 0.27632\n","Epoch [45/200], Step [2/7], Loss: 0.5498\n","Epoch [45/200], Step [4/7], Loss: 0.6726\n","Epoch [45/200], Step [6/7], Loss: 0.5684\n","Epoch [45/200], Step [8/7], Loss: 0.5146\n","Training Accuracy: 0.79856\n","Testing Accuracy: [0.34146 0.25175 0.33217 0.26761 0.25177 0.27368 0.21875 0.35106 x ]\n","Testing Accuracy Average: 0.28596\n","Epoch [46/200], Step [2/7], Loss: 0.6625\n","Epoch [46/200], Step [4/7], Loss: 0.6038\n","Epoch [46/200], Step [6/7], Loss: 0.5144\n","Epoch [46/200], Step [8/7], Loss: 0.5044\n","Training Accuracy: 0.77698\n","Testing Accuracy: [0.31707 0.25874 0.31818 0.27817 0.25177 0.29474 0.23264 0.33333 x ]\n","Testing Accuracy Average: 0.28553\n","Epoch [47/200], Step [2/7], Loss: 0.4809\n","Epoch [47/200], Step [4/7], Loss: 0.4772\n","Epoch [47/200], Step [6/7], Loss: 0.6032\n","Epoch [47/200], Step [8/7], Loss: 0.6087\n","Training Accuracy: 0.80216\n","Testing Accuracy: [0.31010 0.25175 0.27972 0.25352 0.25177 0.31579 0.21528 0.32270 x ]\n","Testing Accuracy Average: 0.27500\n","Epoch [48/200], Step [2/7], Loss: 0.5768\n","Epoch [48/200], Step [4/7], Loss: 0.6729\n","Epoch [48/200], Step [6/7], Loss: 0.6182\n","Epoch [48/200], Step [8/7], Loss: 0.8677\n","Training Accuracy: 0.78058\n","Testing Accuracy: [0.35540 0.26224 0.34615 "],"name":"stdout"},{"output_type":"stream","text":["0.28169 0.25887 0.25263 0.22569 0.36525 x ]\n","Testing Accuracy Average: 0.29342\n","Epoch [49/200], Step [2/7], Loss: 0.5263\n","Epoch [49/200], Step [4/7], Loss: 0.6195\n","Epoch [49/200], Step [6/7], Loss: 0.5159\n","Epoch [49/200], Step [8/7], Loss: 0.6647\n","Training Accuracy: 0.81655\n","Testing Accuracy: [0.35192 0.25874 0.32517 0.27817 0.25887 0.28421 0.23264 0.36879 x ]\n","Testing Accuracy Average: 0.29474\n","Epoch [50/200], Step [2/7], Loss: 0.6539\n","Epoch [50/200], Step [4/7], Loss: 0.5057\n","Epoch [50/200], Step [6/7], Loss: 0.7032\n","Epoch [50/200], Step [8/7], Loss: 0.4115\n","Training Accuracy: 0.79137\n","Testing Accuracy: [0.31707 0.24825 0.32867 0.26761 0.26241 0.27368 0.22917 0.33688 x ]\n","Testing Accuracy Average: 0.28289\n","Epoch [51/200], Step [2/7], Loss: 0.3709\n","Epoch [51/200], Step [4/7], Loss: 0.5415\n","Epoch [51/200], Step [6/7], Loss: 0.4099\n","Epoch [51/200], Step [8/7], Loss: 0.6357\n","Training Accuracy: 0.83094\n","Testing Accuracy: [0.30314 0.25874 0.29371 0.25000 0.24823 0.30175 0.22569 0.32979 x ]\n","Testing Accuracy Average: 0.27632\n","Epoch [52/200], Step [2/7], Loss: 0.4225\n","Epoch [52/200], Step [4/7], Loss: 0.6363\n","Epoch [52/200], Step [6/7], Loss: 0.5365\n","Epoch [52/200], Step [8/7], Loss: 0.5843\n","Training Accuracy: 0.82374\n","Testing Accuracy: [0.35889 0.24825 0.33916 0.26761 0.25532 0.28421 0.22222 0.36879 x ]\n","Testing Accuracy Average: 0.29298\n","Epoch [53/200], Step [2/7], Loss: 0.4178\n","Epoch [53/200], Step [4/7], Loss: 0.3945\n","Epoch [53/200], Step [6/7], Loss: 0.5658\n","Epoch [53/200], Step [8/7], Loss: 0.4460\n","Training Accuracy: 0.84532\n","Testing Accuracy: [0.34495 0.25874 0.32867 0.26408 0.25177 0.28421 0.22917 0.35816 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [54/200], Step [2/7], Loss: 0.5402\n","Epoch [54/200], Step [4/7], Loss: 0.4765\n","Epoch [54/200], Step [6/7], Loss: 0.3989\n","Epoch [54/200], Step [8/7], Loss: 0.7093\n","Training Accuracy: 0.85252\n","Testing Accuracy: [0.34495 0.24476 0.34965 0.26408 0.25887 0.28070 0.22569 0.36879 x ]\n","Testing Accuracy Average: 0.29211\n","Epoch [55/200], Step [2/7], Loss: 0.2637\n","Epoch [55/200], Step [4/7], Loss: 0.4754\n","Epoch [55/200], Step [6/7], Loss: 0.5416\n","Epoch [55/200], Step [8/7], Loss: 0.5825\n","Training Accuracy: 0.84173\n","Testing Accuracy: [0.36237 0.25524 0.31818 0.28169 0.25532 0.28421 0.23264 0.37589 x ]\n","Testing Accuracy Average: 0.29561\n","Epoch [56/200], Step [2/7], Loss: 0.5214\n","Epoch [56/200], Step [4/7], Loss: 0.3663\n","Epoch [56/200], Step [6/7], Loss: 0.4688\n","Epoch [56/200], Step [8/7], Loss: 0.2738\n","Training Accuracy: 0.80935\n","Testing Accuracy: [0.29965 0.24825 0.30420 0.26408 0.25887 0.28772 0.23611 0.32624 x ]\n","Testing Accuracy Average: 0.27807\n","Epoch [57/200], Step [2/7], Loss: 0.5134\n","Epoch [57/200], Step [4/7], Loss: 0.4693\n","Epoch [57/200], Step [6/7], Loss: 0.4408\n","Epoch [57/200], Step [8/7], Loss: 0.4936\n","Training Accuracy: 0.83453\n","Testing Accuracy: [0.29268 0.23776 0.29021 0.26056 0.25177 0.30175 0.22569 0.31206 x ]\n","Testing Accuracy Average: 0.27149\n","Epoch [58/200], Step [2/7], Loss: 0.6026\n","Epoch [58/200], Step [4/7], Loss: 0.4158\n","Epoch [58/200], Step [6/7], Loss: 0.5443\n","Epoch [58/200], Step [8/7], Loss: 0.5435\n","Training Accuracy: 0.85252\n","Testing Accuracy: [0.37282 0.25175 0.33916 0.29225 0.26241 0.25965 0.24306 0.38652 x ]\n","Testing Accuracy Average: 0.30088\n","Epoch [59/200], Step [2/7], Loss: 0.4333\n","Epoch [59/200], Step [4/7], Loss: 0.6234\n","Epoch [59/200], Step [6/7], Loss: 0.4249\n","Epoch [59/200], Step [8/7], Loss: 0.2417\n","Training Accuracy: 0.84532\n","Testing Accuracy: [0.34495 0.25524 0.33916 0.27465 0.26596 0.28070 0.23958 0.35106 x ]\n","Testing Accuracy Average: 0.29386\n","Epoch [60/200], Step [2/7], Loss: 0.5458\n","Epoch [60/200], Step [4/7], Loss: 0.4742\n","Epoch [60/200], Step [6/7], Loss: 0.3223\n","Epoch [60/200], Step [8/7], Loss: 0.6334\n","Training Accuracy: 0.87050\n","Testing Accuracy: [0.33449 0.24126 0.31119 "],"name":"stdout"},{"output_type":"stream","text":["0.25704 0.25532 0.32632 0.23264 0.36170 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [61/200], Step [2/7], Loss: 0.4669\n","Epoch [61/200], Step [4/7], Loss: 0.5588\n","Epoch [61/200], Step [6/7], Loss: 0.4775\n","Epoch [61/200], Step [8/7], Loss: 0.4442\n","Training Accuracy: 0.87770\n","Testing Accuracy: [0.33798 0.24825 0.32517 0.26056 0.25532 0.30175 0.23611 0.35461 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [62/200], Step [2/7], Loss: 0.4011\n","Epoch [62/200], Step [4/7], Loss: 0.4633\n","Epoch [62/200], Step [6/7], Loss: 0.4695\n","Epoch [62/200], Step [8/7], Loss: 0.2602\n","Training Accuracy: 0.86331\n","Testing Accuracy: [0.33798 0.25175 0.34266 0.27113 0.25887 0.28070 0.24306 0.33688 x ]\n","Testing Accuracy Average: 0.29035\n","Epoch [63/200], Step [2/7], Loss: 0.2750\n","Epoch [63/200], Step [4/7], Loss: 0.4551\n","Epoch [63/200], Step [6/7], Loss: 0.3958\n","Epoch [63/200], Step [8/7], Loss: 0.3145\n","Training Accuracy: 0.87410\n","Testing Accuracy: [0.31707 0.24476 0.29720 0.26056 0.25887 0.31930 0.23611 0.35106 x ]\n","Testing Accuracy Average: 0.28553\n","Epoch [64/200], Step [2/7], Loss: 0.3132\n","Epoch [64/200], Step [4/7], Loss: 0.4308\n","Epoch [64/200], Step [6/7], Loss: 0.3582\n","Epoch [64/200], Step [8/7], Loss: 0.3761\n","Training Accuracy: 0.87770\n","Testing Accuracy: [0.37282 0.24825 0.34965 0.27817 0.25532 0.25965 0.24306 0.39007 x ]\n","Testing Accuracy Average: 0.29956\n","Epoch [65/200], Step [2/7], Loss: 0.2999\n","Epoch [65/200], Step [4/7], Loss: 0.3852\n","Epoch [65/200], Step [6/7], Loss: 0.3204\n","Epoch [65/200], Step [8/7], Loss: 0.3347\n","Training Accuracy: 0.88129\n","Testing Accuracy: [0.38328 0.24825 0.32168 0.28873 0.25177 0.25263 0.24653 0.40071 x ]\n","Testing Accuracy Average: 0.29912\n","Epoch [66/200], Step [2/7], Loss: 0.3574\n","Epoch [66/200], Step [4/7], Loss: 0.2633\n","Epoch [66/200], Step [6/7], Loss: 0.2910\n","Epoch [66/200], Step [8/7], Loss: 0.3320\n","Training Accuracy: 0.89209\n","Testing Accuracy: [0.36237 0.25175 0.34965 0.28169 0.25177 0.25614 0.24306 0.39362 x ]\n","Testing Accuracy Average: 0.29868\n","Epoch [67/200], Step [2/7], Loss: 0.3356\n","Epoch [67/200], Step [4/7], Loss: 0.2901\n","Epoch [67/200], Step [6/7], Loss: 0.2619\n","Epoch [67/200], Step [8/7], Loss: 0.3606\n","Training Accuracy: 0.89928\n","Testing Accuracy: [0.34843 0.25874 0.32517 0.26761 0.25887 0.29474 0.23958 0.36170 x ]\n","Testing Accuracy Average: 0.29430\n","Epoch [68/200], Step [2/7], Loss: 0.2988\n","Epoch [68/200], Step [4/7], Loss: 0.2427\n","Epoch [68/200], Step [6/7], Loss: 0.2760\n","Epoch [68/200], Step [8/7], Loss: 0.2994\n","Training Accuracy: 0.91007\n","Testing Accuracy: [0.34495 0.25175 0.35315 0.26056 0.25887 0.26667 0.23958 0.36525 x ]\n","Testing Accuracy Average: 0.29254\n","Epoch [69/200], Step [2/7], Loss: 0.2827\n","Epoch [69/200], Step [4/7], Loss: 0.3041\n","Epoch [69/200], Step [6/7], Loss: 0.3353\n","Epoch [69/200], Step [8/7], Loss: 0.3318\n","Training Accuracy: 0.92446\n","Testing Accuracy: [0.36237 0.24825 0.33217 0.27817 0.24468 0.27018 0.24306 0.38652 x ]\n","Testing Accuracy Average: 0.29561\n","Epoch [70/200], Step [2/7], Loss: 0.2016\n","Epoch [70/200], Step [4/7], Loss: 0.2542\n","Epoch [70/200], Step [6/7], Loss: 0.2061\n","Epoch [70/200], Step [8/7], Loss: 0.3610\n","Training Accuracy: 0.92806\n","Testing Accuracy: [0.36237 0.24825 0.34965 0.28169 0.24823 0.26667 0.24306 0.39007 x ]\n","Testing Accuracy Average: 0.29868\n","Epoch [71/200], Step [2/7], Loss: 0.2629\n","Epoch [71/200], Step [4/7], Loss: 0.3488\n","Epoch [71/200], Step [6/7], Loss: 0.3544\n","Epoch [71/200], Step [8/7], Loss: 0.4157\n","Training Accuracy: 0.91727\n","Testing Accuracy: [0.34146 0.24825 0.33566 0.26408 0.26241 0.30877 0.24653 0.36525 x ]\n","Testing Accuracy Average: 0.29649\n","Epoch [72/200], Step [2/7], Loss: 0.2749\n","Epoch [72/200], Step [4/7], Loss: 0.1089\n","Epoch [72/200], Step [6/7], Loss: 0.2050\n","Epoch [72/200], Step [8/7], Loss: 0.2747\n","Training Accuracy: 0.93165\n","Testing Accuracy: [0.36237 0.24825 0.34965 "],"name":"stdout"},{"output_type":"stream","text":["0.27817 0.25532 0.28070 0.23958 0.38298 x ]\n","Testing Accuracy Average: 0.29956\n","Epoch [73/200], Step [2/7], Loss: 0.1919\n","Epoch [73/200], Step [4/7], Loss: 0.2747\n","Epoch [73/200], Step [6/7], Loss: 0.2313\n","Epoch [73/200], Step [8/7], Loss: 0.3174\n","Training Accuracy: 0.88489\n","Testing Accuracy: [0.37631 0.24126 0.34266 0.29225 0.24468 0.27018 0.22569 0.40071 x ]\n","Testing Accuracy Average: 0.29912\n","Epoch [74/200], Step [2/7], Loss: 0.2175\n","Epoch [74/200], Step [4/7], Loss: 0.1882\n","Epoch [74/200], Step [6/7], Loss: 0.4068\n","Epoch [74/200], Step [8/7], Loss: 0.1695\n","Training Accuracy: 0.94604\n","Testing Accuracy: [0.36585 0.25175 0.35315 0.28521 0.24113 0.25263 0.25347 0.40071 x ]\n","Testing Accuracy Average: 0.30044\n","Epoch [75/200], Step [2/7], Loss: 0.1761\n","Epoch [75/200], Step [4/7], Loss: 0.2017\n","Epoch [75/200], Step [6/7], Loss: 0.2398\n","Epoch [75/200], Step [8/7], Loss: 0.1973\n","Training Accuracy: 0.94604\n","Testing Accuracy: [0.35540 0.25175 0.36014 0.27113 0.24823 0.27368 0.25694 0.38652 x ]\n","Testing Accuracy Average: 0.30044\n","Epoch [76/200], Step [2/7], Loss: 0.1965\n","Epoch [76/200], Step [4/7], Loss: 0.1588\n","Epoch [76/200], Step [6/7], Loss: 0.2031\n","Epoch [76/200], Step [8/7], Loss: 0.2914\n","Training Accuracy: 0.96043\n","Testing Accuracy: [0.35889 0.24825 0.34615 0.27817 0.24823 0.25965 0.24306 0.37943 x ]\n","Testing Accuracy Average: 0.29518\n","Epoch [77/200], Step [2/7], Loss: 0.1346\n","Epoch [77/200], Step [4/7], Loss: 0.1974\n","Epoch [77/200], Step [6/7], Loss: 0.1922\n","Epoch [77/200], Step [8/7], Loss: 0.1887\n","Training Accuracy: 0.94604\n","Testing Accuracy: [0.35192 0.25524 0.33566 0.27465 0.25177 0.27018 0.25347 0.38652 x ]\n","Testing Accuracy Average: 0.29737\n","Epoch [78/200], Step [2/7], Loss: 0.2377\n","Epoch [78/200], Step [4/7], Loss: 0.1629\n","Epoch [78/200], Step [6/7], Loss: 0.2396\n","Epoch [78/200], Step [8/7], Loss: 0.2616\n","Training Accuracy: 0.94604\n","Testing Accuracy: [0.37979 0.24126 0.33916 0.27465 0.24823 0.25965 0.24653 0.42553 x ]\n","Testing Accuracy Average: 0.30175\n","Epoch [79/200], Step [2/7], Loss: 0.1883\n","Epoch [79/200], Step [4/7], Loss: 0.2769\n","Epoch [79/200], Step [6/7], Loss: 0.2026\n","Epoch [79/200], Step [8/7], Loss: 0.3813\n","Training Accuracy: 0.91007\n","Testing Accuracy: [0.37282 0.24476 0.34266 0.28521 0.24823 0.25263 0.23264 0.40780 x ]\n","Testing Accuracy Average: 0.29825\n","Epoch [80/200], Step [2/7], Loss: 0.1806\n","Epoch [80/200], Step [4/7], Loss: 0.1788\n","Epoch [80/200], Step [6/7], Loss: 0.1332\n","Epoch [80/200], Step [8/7], Loss: 0.0518\n","Training Accuracy: 0.88489\n","Testing Accuracy: [0.37979 0.24825 0.34266 0.29225 0.25532 0.24211 0.24653 0.39716 x ]\n","Testing Accuracy Average: 0.30044\n","Epoch [81/200], Step [2/7], Loss: 0.2015\n","Epoch [81/200], Step [4/7], Loss: 0.1285\n","Epoch [81/200], Step [6/7], Loss: 0.2382\n","Epoch [81/200], Step [8/7], Loss: 0.1873\n","Training Accuracy: 0.96043\n","Testing Accuracy: [0.35540 0.25175 0.34615 0.28521 0.24823 0.26667 0.26042 0.40071 x ]\n","Testing Accuracy Average: 0.30175\n","Epoch [82/200], Step [2/7], Loss: 0.2487\n","Epoch [82/200], Step [4/7], Loss: 0.1771\n","Epoch [82/200], Step [6/7], Loss: 0.1309\n","Epoch [82/200], Step [8/7], Loss: 0.1499\n","Training Accuracy: 0.97842\n","Testing Accuracy: [0.36237 0.24476 0.32867 0.28169 0.24823 0.25263 0.24653 0.35106 x ]\n","Testing Accuracy Average: 0.28947\n","Epoch [83/200], Step [2/7], Loss: 0.2253\n","Epoch [83/200], Step [4/7], Loss: 0.1724\n","Epoch [83/200], Step [6/7], Loss: 0.2100\n","Epoch [83/200], Step [8/7], Loss: 0.1023\n","Training Accuracy: 0.97482\n","Testing Accuracy: [0.35889 0.24476 0.35315 0.27465 0.25177 0.24912 0.25347 0.37234 x ]\n","Testing Accuracy Average: 0.29474\n","Epoch [84/200], Step [2/7], Loss: 0.2074\n","Epoch [84/200], Step [4/7], Loss: 0.1007\n","Epoch [84/200], Step [6/7], Loss: 0.1376\n","Epoch [84/200], Step [8/7], Loss: 0.0843\n","Training Accuracy: 0.97482\n","Testing Accuracy: [0.36237 0.24476 0.32517 "],"name":"stdout"},{"output_type":"stream","text":["0.28873 0.24468 0.25614 0.24653 0.35816 x ]\n","Testing Accuracy Average: 0.29079\n","Epoch [85/200], Step [2/7], Loss: 0.2416\n","Epoch [85/200], Step [4/7], Loss: 0.1276\n","Epoch [85/200], Step [6/7], Loss: 0.2743\n","Epoch [85/200], Step [8/7], Loss: 0.1610\n","Training Accuracy: 0.97122\n","Testing Accuracy: [0.35192 0.24825 0.34615 0.26761 0.24823 0.25614 0.26042 0.37234 x ]\n","Testing Accuracy Average: 0.29386\n","Epoch [86/200], Step [2/7], Loss: 0.1936\n","Epoch [86/200], Step [4/7], Loss: 0.2693\n","Epoch [86/200], Step [6/7], Loss: 0.1048\n","Epoch [86/200], Step [8/7], Loss: 0.1499\n","Training Accuracy: 0.97482\n","Testing Accuracy: [0.35540 0.25175 0.34965 0.27465 0.25177 0.25263 0.25694 0.37234 x ]\n","Testing Accuracy Average: 0.29561\n","Epoch [87/200], Step [2/7], Loss: 0.1448\n","Epoch [87/200], Step [4/7], Loss: 0.1384\n","Epoch [87/200], Step [6/7], Loss: 0.1261\n","Epoch [87/200], Step [8/7], Loss: 0.1500\n","Training Accuracy: 0.98201\n","Testing Accuracy: [0.34843 0.25175 0.33566 0.27465 0.25177 0.26667 0.25347 0.37589 x ]\n","Testing Accuracy Average: 0.29474\n","Epoch [88/200], Step [2/7], Loss: 0.1207\n","Epoch [88/200], Step [4/7], Loss: 0.1561\n","Epoch [88/200], Step [6/7], Loss: 0.1221\n","Epoch [88/200], Step [8/7], Loss: 0.1380\n","Training Accuracy: 0.91007\n","Testing Accuracy: [0.37282 0.24476 0.36364 0.28873 0.24823 0.26667 0.22569 0.41844 x ]\n","Testing Accuracy Average: 0.30351\n","Epoch [89/200], Step [2/7], Loss: 0.1399\n","Epoch [89/200], Step [4/7], Loss: 0.2196\n","Epoch [89/200], Step [6/7], Loss: 0.1482\n","Epoch [89/200], Step [8/7], Loss: 0.1550\n","Training Accuracy: 0.94604\n","Testing Accuracy: [0.36585 0.25524 0.34266 0.27465 0.24113 0.25614 0.21875 0.41489 x ]\n","Testing Accuracy Average: 0.29605\n","Epoch [90/200], Step [2/7], Loss: 0.1564\n","Epoch [90/200], Step [4/7], Loss: 0.1370\n","Epoch [90/200], Step [6/7], Loss: 0.2020\n","Epoch [90/200], Step [8/7], Loss: 0.1064\n","Training Accuracy: 0.98201\n","Testing Accuracy: [0.34495 0.25175 0.32168 0.26761 0.24823 0.28772 0.25694 0.37589 x ]\n","Testing Accuracy Average: 0.29430\n","Epoch [91/200], Step [2/7], Loss: 0.1210\n","Epoch [91/200], Step [4/7], Loss: 0.1375\n","Epoch [91/200], Step [6/7], Loss: 0.1324\n","Epoch [91/200], Step [8/7], Loss: 0.1411\n","Training Accuracy: 0.99281\n","Testing Accuracy: [0.36585 0.24476 0.32168 0.28521 0.24113 0.24912 0.25347 0.37234 x ]\n","Testing Accuracy Average: 0.29167\n","Epoch [92/200], Step [2/7], Loss: 0.1165\n","Epoch [92/200], Step [4/7], Loss: 0.0917\n","Epoch [92/200], Step [6/7], Loss: 0.0712\n","Epoch [92/200], Step [8/7], Loss: 0.1066\n","Training Accuracy: 0.98921\n","Testing Accuracy: [0.36934 0.24825 0.32168 0.28169 0.24113 0.24211 0.24306 0.37234 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [93/200], Step [2/7], Loss: 0.1020\n","Epoch [93/200], Step [4/7], Loss: 0.0838\n","Epoch [93/200], Step [6/7], Loss: 0.0718\n","Epoch [93/200], Step [8/7], Loss: 0.0708\n","Training Accuracy: 0.99640\n","Testing Accuracy: [0.35540 0.25175 0.32168 0.27465 0.24468 0.25614 0.25694 0.37589 x ]\n","Testing Accuracy Average: 0.29211\n","Epoch [94/200], Step [2/7], Loss: 0.0583\n","Epoch [94/200], Step [4/7], Loss: 0.0724\n","Epoch [94/200], Step [6/7], Loss: 0.1380\n","Epoch [94/200], Step [8/7], Loss: 0.0882\n","Training Accuracy: 0.98561\n","Testing Accuracy: [0.36934 0.24825 0.33916 0.26056 0.24823 0.25614 0.22222 0.40780 x ]\n","Testing Accuracy Average: 0.29386\n","Epoch [95/200], Step [2/7], Loss: 0.0733\n","Epoch [95/200], Step [4/7], Loss: 0.0751\n","Epoch [95/200], Step [6/7], Loss: 0.0572\n","Epoch [95/200], Step [8/7], Loss: 0.0711\n","Training Accuracy: 0.99640\n","Testing Accuracy: [0.35192 0.25175 0.32168 0.26408 0.24468 0.23509 0.25694 0.39362 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [96/200], Step [2/7], Loss: 0.0624\n","Epoch [96/200], Step [4/7], Loss: 0.0890\n","Epoch [96/200], Step [6/7], Loss: 0.1119\n","Epoch [96/200], Step [8/7], Loss: 0.1165\n","Training Accuracy: 0.99281\n","Testing Accuracy: [0.38328 0.25524 0.33566 "],"name":"stdout"},{"output_type":"stream","text":["0.26408 0.24113 0.24561 0.23611 0.39716 x ]\n","Testing Accuracy Average: 0.29474\n","Epoch [97/200], Step [2/7], Loss: 0.0862\n","Epoch [97/200], Step [4/7], Loss: 0.1186\n","Epoch [97/200], Step [6/7], Loss: 0.0846\n","Epoch [97/200], Step [8/7], Loss: 0.1018\n","Training Accuracy: 0.99281\n","Testing Accuracy: [0.35889 0.25175 0.31818 0.27465 0.24113 0.25614 0.25000 0.34752 x ]\n","Testing Accuracy Average: 0.28728\n","Epoch [98/200], Step [2/7], Loss: 0.0789\n","Epoch [98/200], Step [4/7], Loss: 0.0724\n","Epoch [98/200], Step [6/7], Loss: 0.0863\n","Epoch [98/200], Step [8/7], Loss: 0.0981\n","Training Accuracy: 0.99281\n","Testing Accuracy: [0.34146 0.25175 0.34266 0.26761 0.25887 0.25614 0.26042 0.34397 x ]\n","Testing Accuracy Average: 0.29035\n","Epoch [99/200], Step [2/7], Loss: 0.2207\n","Epoch [99/200], Step [4/7], Loss: 0.0343\n","Epoch [99/200], Step [6/7], Loss: 0.0989\n","Epoch [99/200], Step [8/7], Loss: 0.0483\n","Training Accuracy: 0.99640\n","Testing Accuracy: [0.35889 0.25874 0.31818 0.26408 0.23759 0.23860 0.23958 0.38652 x ]\n","Testing Accuracy Average: 0.28772\n","Epoch [100/200], Step [2/7], Loss: 0.0528\n","Epoch [100/200], Step [4/7], Loss: 0.1148\n","Epoch [100/200], Step [6/7], Loss: 0.0676\n","Epoch [100/200], Step [8/7], Loss: 0.1060\n","Training Accuracy: 0.99640\n","Testing Accuracy: [0.36934 0.24825 0.33217 0.25352 0.25532 0.25614 0.22222 0.41844 x ]\n","Testing Accuracy Average: 0.29430\n","Epoch [101/200], Step [2/7], Loss: 0.0797\n","Epoch [101/200], Step [4/7], Loss: 0.0829\n","Epoch [101/200], Step [6/7], Loss: 0.0672\n","Epoch [101/200], Step [8/7], Loss: 0.0629\n","Training Accuracy: 0.99281\n","Testing Accuracy: [0.35889 0.26224 0.33916 0.28169 0.24823 0.28772 0.25000 0.37943 x ]\n","Testing Accuracy Average: 0.30088\n","Epoch [102/200], Step [2/7], Loss: 0.1095\n","Epoch [102/200], Step [4/7], Loss: 0.1094\n","Epoch [102/200], Step [6/7], Loss: 0.0732\n","Epoch [102/200], Step [8/7], Loss: 0.0242\n","Training Accuracy: 0.99640\n","Testing Accuracy: [0.35192 0.25175 0.32517 0.27113 0.24468 0.24912 0.24653 0.35461 x ]\n","Testing Accuracy Average: 0.28684\n","Epoch [103/200], Step [2/7], Loss: 0.0657\n","Epoch [103/200], Step [4/7], Loss: 0.0435\n","Epoch [103/200], Step [6/7], Loss: 0.0428\n","Epoch [103/200], Step [8/7], Loss: 0.0532\n","Training Accuracy: 0.98921\n","Testing Accuracy: [0.36934 0.25175 0.33566 0.28521 0.23404 0.24211 0.23611 0.37943 x ]\n","Testing Accuracy Average: 0.29167\n","Epoch [104/200], Step [2/7], Loss: 0.0798\n","Epoch [104/200], Step [4/7], Loss: 0.0865\n","Epoch [104/200], Step [6/7], Loss: 0.0470\n","Epoch [104/200], Step [8/7], Loss: 0.1022\n","Training Accuracy: 0.99640\n","Testing Accuracy: [0.36585 0.24476 0.32517 0.26056 0.24113 0.23509 0.24653 0.39362 x ]\n","Testing Accuracy Average: 0.28904\n","Epoch [105/200], Step [2/7], Loss: 0.0312\n","Epoch [105/200], Step [4/7], Loss: 0.1098\n","Epoch [105/200], Step [6/7], Loss: 0.0530\n","Epoch [105/200], Step [8/7], Loss: 0.0307\n","Training Accuracy: 0.99281\n","Testing Accuracy: [0.36237 0.25524 0.32867 0.29225 0.24823 0.28070 0.25694 0.37943 x ]\n","Testing Accuracy Average: 0.30044\n","Epoch [106/200], Step [2/7], Loss: 0.0485\n","Epoch [106/200], Step [4/7], Loss: 0.0595\n","Epoch [106/200], Step [6/7], Loss: 0.0731\n","Epoch [106/200], Step [8/7], Loss: 0.0819\n","Training Accuracy: 0.99281\n","Testing Accuracy: [0.36237 0.25175 0.34266 0.26761 0.24823 0.25263 0.22917 0.38652 x ]\n","Testing Accuracy Average: 0.29254\n","Epoch [107/200], Step [2/7], Loss: 0.0424\n","Epoch [107/200], Step [4/7], Loss: 0.0538\n","Epoch [107/200], Step [6/7], Loss: 0.0517\n","Epoch [107/200], Step [8/7], Loss: 0.0284\n","Training Accuracy: 0.99640\n","Testing Accuracy: [0.35192 0.25524 0.32168 0.26408 0.24113 0.24561 0.24306 0.35106 x ]\n","Testing Accuracy Average: 0.28421\n","Epoch [108/200], Step [2/7], Loss: 0.0330\n","Epoch [108/200], Step [4/7], Loss: 0.0471\n","Epoch [108/200], Step [6/7], Loss: 0.0563\n","Epoch [108/200], Step [8/7], Loss: 0.0622\n","Training Accuracy: 0.99640\n","Testing Accuracy: [0.36585 0.24126 0.33566 "],"name":"stdout"},{"output_type":"stream","text":["0.27465 0.25532 0.25614 0.23958 0.38298 x ]\n","Testing Accuracy Average: 0.29386\n","Epoch [109/200], Step [2/7], Loss: 0.0479\n","Epoch [109/200], Step [4/7], Loss: 0.0293\n","Epoch [109/200], Step [6/7], Loss: 0.0602\n","Epoch [109/200], Step [8/7], Loss: 0.0387\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24825 0.33217 0.25704 0.24113 0.24912 0.22917 0.39716 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [110/200], Step [2/7], Loss: 0.0191\n","Epoch [110/200], Step [4/7], Loss: 0.0550\n","Epoch [110/200], Step [6/7], Loss: 0.0739\n","Epoch [110/200], Step [8/7], Loss: 0.0192\n","Training Accuracy: 0.99640\n","Testing Accuracy: [0.35889 0.24476 0.32517 0.26056 0.24468 0.26667 0.25000 0.32624 x ]\n","Testing Accuracy Average: 0.28465\n","Epoch [111/200], Step [2/7], Loss: 0.0487\n","Epoch [111/200], Step [4/7], Loss: 0.0489\n","Epoch [111/200], Step [6/7], Loss: 0.0421\n","Epoch [111/200], Step [8/7], Loss: 0.0798\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.37979 0.24126 0.33566 0.26408 0.23759 0.25614 0.23264 0.39716 x ]\n","Testing Accuracy Average: 0.29298\n","Epoch [112/200], Step [2/7], Loss: 0.0202\n","Epoch [112/200], Step [4/7], Loss: 0.0289\n","Epoch [112/200], Step [6/7], Loss: 0.0303\n","Epoch [112/200], Step [8/7], Loss: 0.0377\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.37282 0.24476 0.31119 0.25704 0.24823 0.24561 0.24306 0.38652 x ]\n","Testing Accuracy Average: 0.28860\n","Epoch [113/200], Step [2/7], Loss: 0.0247\n","Epoch [113/200], Step [4/7], Loss: 0.0282\n","Epoch [113/200], Step [6/7], Loss: 0.0456\n","Epoch [113/200], Step [8/7], Loss: 0.0432\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.25524 0.32867 0.26408 0.23759 0.24912 0.23958 0.39007 x ]\n","Testing Accuracy Average: 0.29123\n","Epoch [114/200], Step [2/7], Loss: 0.0365\n","Epoch [114/200], Step [4/7], Loss: 0.0248\n","Epoch [114/200], Step [6/7], Loss: 0.0248\n","Epoch [114/200], Step [8/7], Loss: 0.0173\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24825 0.33217 0.26056 0.24113 0.24561 0.23264 0.39716 x ]\n","Testing Accuracy Average: 0.29035\n","Epoch [115/200], Step [2/7], Loss: 0.0270\n","Epoch [115/200], Step [4/7], Loss: 0.0378\n","Epoch [115/200], Step [6/7], Loss: 0.0166\n","Epoch [115/200], Step [8/7], Loss: 0.0470\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.37282 0.25175 0.32168 0.25704 0.23404 0.24912 0.23264 0.37943 x ]\n","Testing Accuracy Average: 0.28728\n","Epoch [116/200], Step [2/7], Loss: 0.0274\n","Epoch [116/200], Step [4/7], Loss: 0.0301\n","Epoch [116/200], Step [6/7], Loss: 0.0356\n","Epoch [116/200], Step [8/7], Loss: 0.0273\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.25524 0.33566 0.26761 0.24468 0.24561 0.24653 0.39007 x ]\n","Testing Accuracy Average: 0.29342\n","Epoch [117/200], Step [2/7], Loss: 0.0146\n","Epoch [117/200], Step [4/7], Loss: 0.0421\n","Epoch [117/200], Step [6/7], Loss: 0.0324\n","Epoch [117/200], Step [8/7], Loss: 0.0178\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.25175 0.33916 0.26408 0.24823 0.24561 0.23264 0.39716 x ]\n","Testing Accuracy Average: 0.29342\n","Epoch [118/200], Step [2/7], Loss: 0.0198\n","Epoch [118/200], Step [4/7], Loss: 0.0193\n","Epoch [118/200], Step [6/7], Loss: 0.0233\n","Epoch [118/200], Step [8/7], Loss: 0.0093\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24825 0.32517 0.26408 0.24113 0.24561 0.23264 0.39007 x ]\n","Testing Accuracy Average: 0.28904\n","Epoch [119/200], Step [2/7], Loss: 0.0145\n","Epoch [119/200], Step [4/7], Loss: 0.0205\n","Epoch [119/200], Step [6/7], Loss: 0.0214\n","Epoch [119/200], Step [8/7], Loss: 0.0109\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.25524 0.32517 0.26408 0.24113 0.24211 0.24306 0.38298 x ]\n","Testing Accuracy Average: 0.29035\n","Epoch [120/200], Step [2/7], Loss: 0.0127\n","Epoch [120/200], Step [4/7], Loss: 0.0276\n","Epoch [120/200], Step [6/7], Loss: 0.0178\n","Epoch [120/200], Step [8/7], Loss: 0.0203\n","Training Accuracy: 1.00000\n","Testing Accuracy: ["],"name":"stdout"},{"output_type":"stream","text":["0.37282 0.24825 0.32517 0.26056 0.24823 0.24912 0.22222 0.39362 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [121/200], Step [2/7], Loss: 0.0205\n","Epoch [121/200], Step [4/7], Loss: 0.0292\n","Epoch [121/200], Step [6/7], Loss: 0.0214\n","Epoch [121/200], Step [8/7], Loss: 0.0481\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.25524 0.32867 0.26408 0.24468 0.24211 0.24306 0.39362 x ]\n","Testing Accuracy Average: 0.29167\n","Epoch [122/200], Step [2/7], Loss: 0.0119\n","Epoch [122/200], Step [4/7], Loss: 0.0228\n","Epoch [122/200], Step [6/7], Loss: 0.0199\n","Epoch [122/200], Step [8/7], Loss: 0.0091\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.24476 0.32867 0.26408 0.25177 0.24912 0.22569 0.39362 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [123/200], Step [2/7], Loss: 0.0127\n","Epoch [123/200], Step [4/7], Loss: 0.0167\n","Epoch [123/200], Step [6/7], Loss: 0.0144\n","Epoch [123/200], Step [8/7], Loss: 0.0317\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.25524 0.32517 0.26056 0.23759 0.25263 0.23958 0.38652 x ]\n","Testing Accuracy Average: 0.29035\n","Epoch [124/200], Step [2/7], Loss: 0.0171\n","Epoch [124/200], Step [4/7], Loss: 0.0259\n","Epoch [124/200], Step [6/7], Loss: 0.0162\n","Epoch [124/200], Step [8/7], Loss: 0.0135\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.24476 0.32517 0.26408 0.25177 0.24912 0.23264 0.39716 x ]\n","Testing Accuracy Average: 0.29167\n","Epoch [125/200], Step [2/7], Loss: 0.0121\n","Epoch [125/200], Step [4/7], Loss: 0.0163\n","Epoch [125/200], Step [6/7], Loss: 0.0270\n","Epoch [125/200], Step [8/7], Loss: 0.0182\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.25874 0.33566 0.26761 0.24468 0.24912 0.23264 0.38652 x ]\n","Testing Accuracy Average: 0.29211\n","Epoch [126/200], Step [2/7], Loss: 0.0183\n","Epoch [126/200], Step [4/7], Loss: 0.0194\n","Epoch [126/200], Step [6/7], Loss: 0.0180\n","Epoch [126/200], Step [8/7], Loss: 0.0084\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24476 0.32517 0.26408 0.25532 0.24211 0.22569 0.39362 x ]\n","Testing Accuracy Average: 0.28947\n","Epoch [127/200], Step [2/7], Loss: 0.0140\n","Epoch [127/200], Step [4/7], Loss: 0.0145\n","Epoch [127/200], Step [6/7], Loss: 0.0178\n","Epoch [127/200], Step [8/7], Loss: 0.0067\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.25524 0.32517 0.26056 0.24823 0.24912 0.23611 0.39007 x ]\n","Testing Accuracy Average: 0.29167\n","Epoch [128/200], Step [2/7], Loss: 0.0094\n","Epoch [128/200], Step [4/7], Loss: 0.0192\n","Epoch [128/200], Step [6/7], Loss: 0.0150\n","Epoch [128/200], Step [8/7], Loss: 0.0209\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.24126 0.32517 0.26408 0.25532 0.24912 0.22222 0.38652 x ]\n","Testing Accuracy Average: 0.28904\n","Epoch [129/200], Step [2/7], Loss: 0.0132\n","Epoch [129/200], Step [4/7], Loss: 0.0138\n","Epoch [129/200], Step [6/7], Loss: 0.0177\n","Epoch [129/200], Step [8/7], Loss: 0.0180\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.24126 0.32168 0.26408 0.25177 0.24561 0.22222 0.39007 x ]\n","Testing Accuracy Average: 0.28816\n","Epoch [130/200], Step [2/7], Loss: 0.0142\n","Epoch [130/200], Step [4/7], Loss: 0.0121\n","Epoch [130/200], Step [6/7], Loss: 0.0175\n","Epoch [130/200], Step [8/7], Loss: 0.0132\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.25874 0.32867 0.27113 0.24468 0.25614 0.22569 0.38652 x ]\n","Testing Accuracy Average: 0.29254\n","Epoch [131/200], Step [2/7], Loss: 0.0141\n","Epoch [131/200], Step [4/7], Loss: 0.0198\n","Epoch [131/200], Step [6/7], Loss: 0.0117\n","Epoch [131/200], Step [8/7], Loss: 0.0088\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.24825 0.34266 0.26408 0.24823 0.25263 0.22569 0.40426 x ]\n","Testing Accuracy Average: 0.29430\n","Epoch [132/200], Step [2/7], Loss: 0.0240\n","Epoch [132/200], Step [4/7], Loss: 0.0105\n","Epoch [132/200], Step [6/7], Loss: 0.0129\n","Epoch [132/200], Step [8/7], Loss: 0.0236\n","Training Accuracy: 1.00000\n","Testing Accuracy: ["],"name":"stdout"},{"output_type":"stream","text":["0.36237 0.25874 0.32517 0.26408 0.24468 0.25614 0.23264 0.37943 x ]\n","Testing Accuracy Average: 0.29035\n","Epoch [133/200], Step [2/7], Loss: 0.0162\n","Epoch [133/200], Step [4/7], Loss: 0.0055\n","Epoch [133/200], Step [6/7], Loss: 0.0154\n","Epoch [133/200], Step [8/7], Loss: 0.0100\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24476 0.32517 0.26408 0.25177 0.25263 0.22569 0.40071 x ]\n","Testing Accuracy Average: 0.29123\n","Epoch [134/200], Step [2/7], Loss: 0.0124\n","Epoch [134/200], Step [4/7], Loss: 0.0136\n","Epoch [134/200], Step [6/7], Loss: 0.0098\n","Epoch [134/200], Step [8/7], Loss: 0.0131\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.25874 0.32867 0.26408 0.24823 0.24912 0.22917 0.38652 x ]\n","Testing Accuracy Average: 0.29079\n","Epoch [135/200], Step [2/7], Loss: 0.0085\n","Epoch [135/200], Step [4/7], Loss: 0.0123\n","Epoch [135/200], Step [6/7], Loss: 0.0076\n","Epoch [135/200], Step [8/7], Loss: 0.0099\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.24126 0.33566 0.26408 0.25177 0.25614 0.22569 0.39716 x ]\n","Testing Accuracy Average: 0.29167\n","Epoch [136/200], Step [2/7], Loss: 0.0079\n","Epoch [136/200], Step [4/7], Loss: 0.0112\n","Epoch [136/200], Step [6/7], Loss: 0.0074\n","Epoch [136/200], Step [8/7], Loss: 0.0086\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.25874 0.32867 0.26408 0.25177 0.25263 0.22917 0.38298 x ]\n","Testing Accuracy Average: 0.29211\n","Epoch [137/200], Step [2/7], Loss: 0.0080\n","Epoch [137/200], Step [4/7], Loss: 0.0155\n","Epoch [137/200], Step [6/7], Loss: 0.0093\n","Epoch [137/200], Step [8/7], Loss: 0.0068\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24825 0.32867 0.26056 0.25177 0.25263 0.21875 0.39362 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [138/200], Step [2/7], Loss: 0.0104\n","Epoch [138/200], Step [4/7], Loss: 0.0153\n","Epoch [138/200], Step [6/7], Loss: 0.0051\n","Epoch [138/200], Step [8/7], Loss: 0.0096\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.25175 0.32517 0.26056 0.24823 0.25263 0.23611 0.38652 x ]\n","Testing Accuracy Average: 0.29123\n","Epoch [139/200], Step [2/7], Loss: 0.0184\n","Epoch [139/200], Step [4/7], Loss: 0.0086\n","Epoch [139/200], Step [6/7], Loss: 0.0059\n","Epoch [139/200], Step [8/7], Loss: 0.0085\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.24825 0.32867 0.26408 0.25532 0.25614 0.22222 0.39716 x ]\n","Testing Accuracy Average: 0.29254\n","Epoch [140/200], Step [2/7], Loss: 0.0091\n","Epoch [140/200], Step [4/7], Loss: 0.0072\n","Epoch [140/200], Step [6/7], Loss: 0.0078\n","Epoch [140/200], Step [8/7], Loss: 0.0076\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.24126 0.32517 0.26056 0.25177 0.24912 0.22917 0.38652 x ]\n","Testing Accuracy Average: 0.28904\n","Epoch [141/200], Step [2/7], Loss: 0.0077\n","Epoch [141/200], Step [4/7], Loss: 0.0099\n","Epoch [141/200], Step [6/7], Loss: 0.0075\n","Epoch [141/200], Step [8/7], Loss: 0.0088\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.24126 0.32517 0.26408 0.24823 0.25263 0.22917 0.39007 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [142/200], Step [2/7], Loss: 0.0096\n","Epoch [142/200], Step [4/7], Loss: 0.0107\n","Epoch [142/200], Step [6/7], Loss: 0.0075\n","Epoch [142/200], Step [8/7], Loss: 0.0074\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24476 0.32168 0.26056 0.25177 0.24561 0.22222 0.38652 x ]\n","Testing Accuracy Average: 0.28728\n","Epoch [143/200], Step [2/7], Loss: 0.0147\n","Epoch [143/200], Step [4/7], Loss: 0.0091\n","Epoch [143/200], Step [6/7], Loss: 0.0071\n","Epoch [143/200], Step [8/7], Loss: 0.0055\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24476 0.32517 0.26408 0.24823 0.25614 0.22569 0.38652 x ]\n","Testing Accuracy Average: 0.28947\n","Epoch [144/200], Step [2/7], Loss: 0.0047\n","Epoch [144/200], Step [4/7], Loss: 0.0077\n","Epoch [144/200], Step [6/7], Loss: 0.0077\n","Epoch [144/200], Step [8/7], Loss: 0.0090\n","Training Accuracy: 1.00000\n","Testing Accuracy: ["],"name":"stdout"},{"output_type":"stream","text":["0.36585 0.25175 0.32517 0.26408 0.25177 0.25614 0.22569 0.39362 x ]\n","Testing Accuracy Average: 0.29167\n","Epoch [145/200], Step [2/7], Loss: 0.0076\n","Epoch [145/200], Step [4/7], Loss: 0.0113\n","Epoch [145/200], Step [6/7], Loss: 0.0056\n","Epoch [145/200], Step [8/7], Loss: 0.0065\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.24126 0.31818 0.26056 0.25177 0.25263 0.22917 0.37943 x ]\n","Testing Accuracy Average: 0.28772\n","Epoch [146/200], Step [2/7], Loss: 0.0079\n","Epoch [146/200], Step [4/7], Loss: 0.0116\n","Epoch [146/200], Step [6/7], Loss: 0.0057\n","Epoch [146/200], Step [8/7], Loss: 0.0068\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24825 0.32517 0.26408 0.24823 0.24912 0.22222 0.39007 x ]\n","Testing Accuracy Average: 0.28904\n","Epoch [147/200], Step [2/7], Loss: 0.0072\n","Epoch [147/200], Step [4/7], Loss: 0.0050\n","Epoch [147/200], Step [6/7], Loss: 0.0070\n","Epoch [147/200], Step [8/7], Loss: 0.0041\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.24126 0.32517 0.26408 0.24468 0.25263 0.22917 0.38652 x ]\n","Testing Accuracy Average: 0.28904\n","Epoch [148/200], Step [2/7], Loss: 0.0050\n","Epoch [148/200], Step [4/7], Loss: 0.0080\n","Epoch [148/200], Step [6/7], Loss: 0.0126\n","Epoch [148/200], Step [8/7], Loss: 0.0054\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24825 0.32517 0.26056 0.25177 0.25263 0.22917 0.39362 x ]\n","Testing Accuracy Average: 0.29079\n","Epoch [149/200], Step [2/7], Loss: 0.0088\n","Epoch [149/200], Step [4/7], Loss: 0.0060\n","Epoch [149/200], Step [6/7], Loss: 0.0062\n","Epoch [149/200], Step [8/7], Loss: 0.0074\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24476 0.32168 0.26408 0.24823 0.25614 0.22569 0.39007 x ]\n","Testing Accuracy Average: 0.28947\n","Epoch [150/200], Step [2/7], Loss: 0.0071\n","Epoch [150/200], Step [4/7], Loss: 0.0056\n","Epoch [150/200], Step [6/7], Loss: 0.0077\n","Epoch [150/200], Step [8/7], Loss: 0.0046\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.25524 0.32517 0.26408 0.24823 0.25263 0.22569 0.38652 x ]\n","Testing Accuracy Average: 0.29079\n","Epoch [151/200], Step [2/7], Loss: 0.0083\n","Epoch [151/200], Step [4/7], Loss: 0.0077\n","Epoch [151/200], Step [6/7], Loss: 0.0046\n","Epoch [151/200], Step [8/7], Loss: 0.0024\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24825 0.32168 0.26408 0.25177 0.25263 0.22569 0.39362 x ]\n","Testing Accuracy Average: 0.29035\n","Epoch [152/200], Step [2/7], Loss: 0.0070\n","Epoch [152/200], Step [4/7], Loss: 0.0063\n","Epoch [152/200], Step [6/7], Loss: 0.0042\n","Epoch [152/200], Step [8/7], Loss: 0.0051\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24825 0.32517 0.26408 0.25177 0.25263 0.22569 0.38652 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [153/200], Step [2/7], Loss: 0.0058\n","Epoch [153/200], Step [4/7], Loss: 0.0057\n","Epoch [153/200], Step [6/7], Loss: 0.0065\n","Epoch [153/200], Step [8/7], Loss: 0.0071\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.24476 0.32517 0.26056 0.24468 0.24912 0.22917 0.38298 x ]\n","Testing Accuracy Average: 0.28816\n","Epoch [154/200], Step [2/7], Loss: 0.0057\n","Epoch [154/200], Step [4/7], Loss: 0.0058\n","Epoch [154/200], Step [6/7], Loss: 0.0085\n","Epoch [154/200], Step [8/7], Loss: 0.0053\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.25175 0.32867 0.26761 0.24823 0.25965 0.22917 0.39007 x ]\n","Testing Accuracy Average: 0.29211\n","Epoch [155/200], Step [2/7], Loss: 0.0067\n","Epoch [155/200], Step [4/7], Loss: 0.0032\n","Epoch [155/200], Step [6/7], Loss: 0.0079\n","Epoch [155/200], Step [8/7], Loss: 0.0036\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24476 0.31469 0.26056 0.25177 0.25263 0.22569 0.38298 x ]\n","Testing Accuracy Average: 0.28728\n","Epoch [156/200], Step [2/7], Loss: 0.0053\n","Epoch [156/200], Step [4/7], Loss: 0.0095\n","Epoch [156/200], Step [6/7], Loss: 0.0042\n","Epoch [156/200], Step [8/7], Loss: 0.0079\n","Training Accuracy: 1.00000\n","Testing Accuracy: ["],"name":"stdout"},{"output_type":"stream","text":["0.36237 0.25175 0.32517 0.26761 0.24823 0.25965 0.23264 0.38652 x ]\n","Testing Accuracy Average: 0.29167\n","Epoch [157/200], Step [2/7], Loss: 0.0080\n","Epoch [157/200], Step [4/7], Loss: 0.0078\n","Epoch [157/200], Step [6/7], Loss: 0.0047\n","Epoch [157/200], Step [8/7], Loss: 0.0056\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.25175 0.32168 0.26408 0.25177 0.25263 0.22917 0.39007 x ]\n","Testing Accuracy Average: 0.29079\n","Epoch [158/200], Step [2/7], Loss: 0.0063\n","Epoch [158/200], Step [4/7], Loss: 0.0048\n","Epoch [158/200], Step [6/7], Loss: 0.0059\n","Epoch [158/200], Step [8/7], Loss: 0.0058\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24825 0.32517 0.26408 0.24468 0.25263 0.22917 0.38298 x ]\n","Testing Accuracy Average: 0.28904\n","Epoch [159/200], Step [2/7], Loss: 0.0046\n","Epoch [159/200], Step [4/7], Loss: 0.0036\n","Epoch [159/200], Step [6/7], Loss: 0.0098\n","Epoch [159/200], Step [8/7], Loss: 0.0078\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.25175 0.32168 0.26761 0.25177 0.24912 0.22222 0.39362 x ]\n","Testing Accuracy Average: 0.29035\n","Epoch [160/200], Step [2/7], Loss: 0.0086\n","Epoch [160/200], Step [4/7], Loss: 0.0056\n","Epoch [160/200], Step [6/7], Loss: 0.0037\n","Epoch [160/200], Step [8/7], Loss: 0.0064\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.24825 0.32168 0.26056 0.25177 0.25263 0.22569 0.39007 x ]\n","Testing Accuracy Average: 0.28904\n","Epoch [161/200], Step [2/7], Loss: 0.0058\n","Epoch [161/200], Step [4/7], Loss: 0.0061\n","Epoch [161/200], Step [6/7], Loss: 0.0046\n","Epoch [161/200], Step [8/7], Loss: 0.0051\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.26224 0.32867 0.26761 0.24468 0.25965 0.22569 0.39007 x ]\n","Testing Accuracy Average: 0.29342\n","Epoch [162/200], Step [2/7], Loss: 0.0058\n","Epoch [162/200], Step [4/7], Loss: 0.0037\n","Epoch [162/200], Step [6/7], Loss: 0.0042\n","Epoch [162/200], Step [8/7], Loss: 0.0056\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.25175 0.32168 0.26056 0.25177 0.24912 0.22569 0.39007 x ]\n","Testing Accuracy Average: 0.28904\n","Epoch [163/200], Step [2/7], Loss: 0.0056\n","Epoch [163/200], Step [4/7], Loss: 0.0056\n","Epoch [163/200], Step [6/7], Loss: 0.0055\n","Epoch [163/200], Step [8/7], Loss: 0.0038\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24825 0.32168 0.26408 0.24468 0.25263 0.22569 0.38652 x ]\n","Testing Accuracy Average: 0.28860\n","Epoch [164/200], Step [2/7], Loss: 0.0036\n","Epoch [164/200], Step [4/7], Loss: 0.0051\n","Epoch [164/200], Step [6/7], Loss: 0.0037\n","Epoch [164/200], Step [8/7], Loss: 0.0041\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.25524 0.32168 0.26408 0.24468 0.25263 0.23264 0.39007 x ]\n","Testing Accuracy Average: 0.29079\n","Epoch [165/200], Step [2/7], Loss: 0.0039\n","Epoch [165/200], Step [4/7], Loss: 0.0051\n","Epoch [165/200], Step [6/7], Loss: 0.0039\n","Epoch [165/200], Step [8/7], Loss: 0.0042\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.25175 0.32168 0.26056 0.24823 0.25614 0.23264 0.39007 x ]\n","Testing Accuracy Average: 0.29079\n","Epoch [166/200], Step [2/7], Loss: 0.0059\n","Epoch [166/200], Step [4/7], Loss: 0.0045\n","Epoch [166/200], Step [6/7], Loss: 0.0056\n","Epoch [166/200], Step [8/7], Loss: 0.0044\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.25175 0.32168 0.26056 0.25177 0.25263 0.22917 0.39007 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [167/200], Step [2/7], Loss: 0.0030\n","Epoch [167/200], Step [4/7], Loss: 0.0043\n","Epoch [167/200], Step [6/7], Loss: 0.0065\n","Epoch [167/200], Step [8/7], Loss: 0.0065\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.25175 0.32168 0.26056 0.25177 0.25614 0.22917 0.38652 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [168/200], Step [2/7], Loss: 0.0036\n","Epoch [168/200], Step [4/7], Loss: 0.0035\n","Epoch [168/200], Step [6/7], Loss: 0.0046\n","Epoch [168/200], Step [8/7], Loss: 0.0053\n","Training Accuracy: 1.00000\n","Testing Accuracy: ["],"name":"stdout"},{"output_type":"stream","text":["0.36585 0.23427 0.33916 0.26408 0.25177 0.25263 0.22917 0.39362 x ]\n","Testing Accuracy Average: 0.29123\n","Epoch [169/200], Step [2/7], Loss: 0.0041\n","Epoch [169/200], Step [4/7], Loss: 0.0042\n","Epoch [169/200], Step [6/7], Loss: 0.0034\n","Epoch [169/200], Step [8/7], Loss: 0.0060\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.26224 0.32867 0.26761 0.24823 0.25263 0.22917 0.38298 x ]\n","Testing Accuracy Average: 0.29254\n","Epoch [170/200], Step [2/7], Loss: 0.0055\n","Epoch [170/200], Step [4/7], Loss: 0.0039\n","Epoch [170/200], Step [6/7], Loss: 0.0037\n","Epoch [170/200], Step [8/7], Loss: 0.0033\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.24126 0.33217 0.26408 0.25177 0.25263 0.22222 0.40071 x ]\n","Testing Accuracy Average: 0.29123\n","Epoch [171/200], Step [2/7], Loss: 0.0036\n","Epoch [171/200], Step [4/7], Loss: 0.0049\n","Epoch [171/200], Step [6/7], Loss: 0.0027\n","Epoch [171/200], Step [8/7], Loss: 0.0044\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.25175 0.31818 0.26408 0.24823 0.25263 0.23264 0.39007 x ]\n","Testing Accuracy Average: 0.29035\n","Epoch [172/200], Step [2/7], Loss: 0.0039\n","Epoch [172/200], Step [4/7], Loss: 0.0050\n","Epoch [172/200], Step [6/7], Loss: 0.0033\n","Epoch [172/200], Step [8/7], Loss: 0.0037\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.25175 0.32517 0.26761 0.24823 0.25614 0.23264 0.39362 x ]\n","Testing Accuracy Average: 0.29211\n","Epoch [173/200], Step [2/7], Loss: 0.0027\n","Epoch [173/200], Step [4/7], Loss: 0.0047\n","Epoch [173/200], Step [6/7], Loss: 0.0037\n","Epoch [173/200], Step [8/7], Loss: 0.0048\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.25524 0.32168 0.26408 0.25177 0.25614 0.22917 0.39007 x ]\n","Testing Accuracy Average: 0.29123\n","Epoch [174/200], Step [2/7], Loss: 0.0040\n","Epoch [174/200], Step [4/7], Loss: 0.0040\n","Epoch [174/200], Step [6/7], Loss: 0.0043\n","Epoch [174/200], Step [8/7], Loss: 0.0029\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.25175 0.32168 0.26056 0.25177 0.24912 0.22917 0.39362 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [175/200], Step [2/7], Loss: 0.0031\n","Epoch [175/200], Step [4/7], Loss: 0.0048\n","Epoch [175/200], Step [6/7], Loss: 0.0036\n","Epoch [175/200], Step [8/7], Loss: 0.0042\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.25524 0.32517 0.26761 0.25177 0.25263 0.22917 0.39362 x ]\n","Testing Accuracy Average: 0.29211\n","Epoch [176/200], Step [2/7], Loss: 0.0025\n","Epoch [176/200], Step [4/7], Loss: 0.0031\n","Epoch [176/200], Step [6/7], Loss: 0.0050\n","Epoch [176/200], Step [8/7], Loss: 0.0048\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.25524 0.31818 0.26761 0.24823 0.25263 0.23264 0.38652 x ]\n","Testing Accuracy Average: 0.29079\n","Epoch [177/200], Step [2/7], Loss: 0.0038\n","Epoch [177/200], Step [4/7], Loss: 0.0034\n","Epoch [177/200], Step [6/7], Loss: 0.0035\n","Epoch [177/200], Step [8/7], Loss: 0.0026\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.23776 0.32517 0.26056 0.25177 0.24561 0.22917 0.39362 x ]\n","Testing Accuracy Average: 0.28860\n","Epoch [178/200], Step [2/7], Loss: 0.0042\n","Epoch [178/200], Step [4/7], Loss: 0.0010\n","Epoch [178/200], Step [6/7], Loss: 0.0023\n","Epoch [178/200], Step [8/7], Loss: 0.0051\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.25524 0.31818 0.26408 0.24823 0.25614 0.23264 0.39362 x ]\n","Testing Accuracy Average: 0.29167\n","Epoch [179/200], Step [2/7], Loss: 0.0034\n","Epoch [179/200], Step [4/7], Loss: 0.0042\n","Epoch [179/200], Step [6/7], Loss: 0.0022\n","Epoch [179/200], Step [8/7], Loss: 0.0043\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.23776 0.33566 0.26761 0.25177 0.25614 0.22917 0.39362 x ]\n","Testing Accuracy Average: 0.29167\n","Epoch [180/200], Step [2/7], Loss: 0.0028\n","Epoch [180/200], Step [4/7], Loss: 0.0041\n","Epoch [180/200], Step [6/7], Loss: 0.0020\n","Epoch [180/200], Step [8/7], Loss: 0.0045\n","Training Accuracy: 1.00000\n","Testing Accuracy: ["],"name":"stdout"},{"output_type":"stream","text":["0.36237 0.25874 0.31818 0.26408 0.25177 0.24912 0.22569 0.38652 x ]\n","Testing Accuracy Average: 0.28947\n","Epoch [181/200], Step [2/7], Loss: 0.0027\n","Epoch [181/200], Step [4/7], Loss: 0.0043\n","Epoch [181/200], Step [6/7], Loss: 0.0028\n","Epoch [181/200], Step [8/7], Loss: 0.0040\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.35540 0.23776 0.32867 0.27113 0.25177 0.25614 0.23264 0.38652 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [182/200], Step [2/7], Loss: 0.0029\n","Epoch [182/200], Step [4/7], Loss: 0.0037\n","Epoch [182/200], Step [6/7], Loss: 0.0019\n","Epoch [182/200], Step [8/7], Loss: 0.0042\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36934 0.25524 0.32517 0.26408 0.24468 0.25263 0.23264 0.38652 x ]\n","Testing Accuracy Average: 0.29123\n","Epoch [183/200], Step [2/7], Loss: 0.0049\n","Epoch [183/200], Step [4/7], Loss: 0.0029\n","Epoch [183/200], Step [6/7], Loss: 0.0019\n","Epoch [183/200], Step [8/7], Loss: 0.0034\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.35540 0.23776 0.33217 0.27113 0.25177 0.25614 0.23264 0.39007 x ]\n","Testing Accuracy Average: 0.29079\n","Epoch [184/200], Step [2/7], Loss: 0.0032\n","Epoch [184/200], Step [4/7], Loss: 0.0031\n","Epoch [184/200], Step [6/7], Loss: 0.0033\n","Epoch [184/200], Step [8/7], Loss: 0.0039\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.25874 0.31818 0.26408 0.24823 0.25263 0.23264 0.39007 x ]\n","Testing Accuracy Average: 0.29123\n","Epoch [185/200], Step [2/7], Loss: 0.0038\n","Epoch [185/200], Step [4/7], Loss: 0.0032\n","Epoch [185/200], Step [6/7], Loss: 0.0039\n","Epoch [185/200], Step [8/7], Loss: 0.0021\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.35889 0.23776 0.32867 0.26408 0.25177 0.25614 0.22917 0.39362 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [186/200], Step [2/7], Loss: 0.0025\n","Epoch [186/200], Step [4/7], Loss: 0.0031\n","Epoch [186/200], Step [6/7], Loss: 0.0027\n","Epoch [186/200], Step [8/7], Loss: 0.0030\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.25524 0.31818 0.26761 0.24468 0.25263 0.23264 0.38652 x ]\n","Testing Accuracy Average: 0.29035\n","Epoch [187/200], Step [2/7], Loss: 0.0028\n","Epoch [187/200], Step [4/7], Loss: 0.0024\n","Epoch [187/200], Step [6/7], Loss: 0.0035\n","Epoch [187/200], Step [8/7], Loss: 0.0025\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.23776 0.32517 0.26056 0.25177 0.24561 0.22569 0.39007 x ]\n","Testing Accuracy Average: 0.28772\n","Epoch [188/200], Step [2/7], Loss: 0.0022\n","Epoch [188/200], Step [4/7], Loss: 0.0024\n","Epoch [188/200], Step [6/7], Loss: 0.0024\n","Epoch [188/200], Step [8/7], Loss: 0.0024\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.35889 0.25175 0.32517 0.26408 0.25177 0.25263 0.22917 0.39362 x ]\n","Testing Accuracy Average: 0.29079\n","Epoch [189/200], Step [2/7], Loss: 0.0032\n","Epoch [189/200], Step [4/7], Loss: 0.0031\n","Epoch [189/200], Step [6/7], Loss: 0.0027\n","Epoch [189/200], Step [8/7], Loss: 0.0012\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.25175 0.32168 0.26056 0.25177 0.25263 0.22917 0.39007 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [190/200], Step [2/7], Loss: 0.0026\n","Epoch [190/200], Step [4/7], Loss: 0.0040\n","Epoch [190/200], Step [6/7], Loss: 0.0022\n","Epoch [190/200], Step [8/7], Loss: 0.0018\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.24126 0.32517 0.26408 0.25177 0.24912 0.22569 0.39362 x ]\n","Testing Accuracy Average: 0.28904\n","Epoch [191/200], Step [2/7], Loss: 0.0036\n","Epoch [191/200], Step [4/7], Loss: 0.0022\n","Epoch [191/200], Step [6/7], Loss: 0.0027\n","Epoch [191/200], Step [8/7], Loss: 0.0042\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.35889 0.24825 0.32517 0.26408 0.25177 0.25614 0.23264 0.39362 x ]\n","Testing Accuracy Average: 0.29123\n","Epoch [192/200], Step [2/7], Loss: 0.0024\n","Epoch [192/200], Step [4/7], Loss: 0.0026\n","Epoch [192/200], Step [6/7], Loss: 0.0035\n","Epoch [192/200], Step [8/7], Loss: 0.0016\n","Training Accuracy: 1.00000\n","Testing Accuracy: ["],"name":"stdout"},{"output_type":"stream","text":["0.36585 0.24825 0.32517 0.26056 0.25177 0.24912 0.22917 0.39007 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [193/200], Step [2/7], Loss: 0.0028\n","Epoch [193/200], Step [4/7], Loss: 0.0029\n","Epoch [193/200], Step [6/7], Loss: 0.0020\n","Epoch [193/200], Step [8/7], Loss: 0.0018\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.35889 0.24825 0.32867 0.26408 0.25177 0.25263 0.23264 0.38652 x ]\n","Testing Accuracy Average: 0.29035\n","Epoch [194/200], Step [2/7], Loss: 0.0024\n","Epoch [194/200], Step [4/7], Loss: 0.0024\n","Epoch [194/200], Step [6/7], Loss: 0.0032\n","Epoch [194/200], Step [8/7], Loss: 0.0019\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.25175 0.32517 0.26408 0.25177 0.24912 0.22917 0.39007 x ]\n","Testing Accuracy Average: 0.29079\n","Epoch [195/200], Step [2/7], Loss: 0.0034\n","Epoch [195/200], Step [4/7], Loss: 0.0024\n","Epoch [195/200], Step [6/7], Loss: 0.0024\n","Epoch [195/200], Step [8/7], Loss: 0.0024\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.35889 0.24126 0.32517 0.26408 0.25177 0.25263 0.22569 0.39007 x ]\n","Testing Accuracy Average: 0.28860\n","Epoch [196/200], Step [2/7], Loss: 0.0021\n","Epoch [196/200], Step [4/7], Loss: 0.0023\n","Epoch [196/200], Step [6/7], Loss: 0.0029\n","Epoch [196/200], Step [8/7], Loss: 0.0034\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36237 0.24825 0.32168 0.26408 0.25177 0.24912 0.23611 0.38652 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [197/200], Step [2/7], Loss: 0.0022\n","Epoch [197/200], Step [4/7], Loss: 0.0024\n","Epoch [197/200], Step [6/7], Loss: 0.0036\n","Epoch [197/200], Step [8/7], Loss: 0.0015\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.36585 0.23427 0.33217 0.27113 0.25177 0.24912 0.22917 0.39716 x ]\n","Testing Accuracy Average: 0.29123\n","Epoch [198/200], Step [2/7], Loss: 0.0026\n","Epoch [198/200], Step [4/7], Loss: 0.0021\n","Epoch [198/200], Step [6/7], Loss: 0.0019\n","Epoch [198/200], Step [8/7], Loss: 0.0021\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.35889 0.24825 0.32517 0.26408 0.25177 0.24912 0.23264 0.38652 x ]\n","Testing Accuracy Average: 0.28947\n","Epoch [199/200], Step [2/7], Loss: 0.0022\n","Epoch [199/200], Step [4/7], Loss: 0.0018\n","Epoch [199/200], Step [6/7], Loss: 0.0028\n","Epoch [199/200], Step [8/7], Loss: 0.0023\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.35889 0.25175 0.32168 0.26408 0.25177 0.25263 0.22917 0.39007 x ]\n","Testing Accuracy Average: 0.28991\n","Epoch [200/200], Step [2/7], Loss: 0.0029\n","Epoch [200/200], Step [4/7], Loss: 0.0015\n","Epoch [200/200], Step [6/7], Loss: 0.0034\n","Epoch [200/200], Step [8/7], Loss: 0.0025\n","Training Accuracy: 1.00000\n","Testing Accuracy: [0.35889 0.23776 0.32517 0.26408 0.25177 0.25263 0.23264 0.39362 x ]\n","Testing Accuracy Average: 0.28947\n"],"name":"stdout"}]},{"metadata":{"id":"grXwmYxOv27g","colab_type":"text"},"cell_type":"markdown","source":["###For time_batch units"]},{"metadata":{"id":"G2_dXSMLv6T9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":55},"outputId":"aef59d10-e568-41d2-f5a3-9652404573be","executionInfo":{"status":"ok","timestamp":1521074148061,"user_tz":420,"elapsed":328,"user":{"displayName":"Nathan Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"106327691903472177650"}}},"cell_type":"code","source":["'''\n","training_acc_arr = np.zeros(num_epochs)\n","testing_acc_arr = np.zeros((9, num_epochs))\n","\n","for epoch in range(num_epochs):\n","  \n","  net.train()\n","  \n","  total = 0\n","  correct = 0\n","  \n","  for i, (signals, labels) in enumerate(train_loader):\n","    \n","    signals = signals.type(torch.FloatTensor)\n","    signals = Variable(signals)\n","    labels = labels.type(torch.LongTensor)\n","    labels_check = torch.squeeze(labels)\n","    labels = Variable(torch.squeeze(labels))\n","    loc = np.random.choice(1000-time_batch, 4, replace=False)\n","    s0 = signals[:, :, :, loc[0]:(loc[0]+time_batch)]\n","    s1 = signals[:, :, :, loc[1]:(loc[1]+time_batch)]\n","    s2 = signals[:, :, :, loc[2]:(loc[2]+time_batch)]\n","    s3 = signals[:, :, :, loc[3]:(loc[3]+time_batch)]\n","    signals = torch.cat((s0, s1, s2, s3), 0)\n","    labels_more = torch.cat([labels] * 4)\n","    if use_cuda and torch.cuda.is_available():\n","      signals = signals.cuda()\n","      labels_more = labels_more.cuda()\n","    optimizer.zero_grad()\n","    outputs = net(signals)\n","    loss = criterion(outputs, labels_more)\n","    loss.backward()\n","    optimizer.step()\n","    _, predicted = torch.max(outputs.data, 1)\n","    predicted = predicted.cpu()\n","    predicted = predicted.view(-1, 4).numpy()\n","    predicted, _ = stats.mode(predicted, axis=1)\n","    predicted = np.squeeze(predicted)\n","    total += labels.size(0)\n","    correct += (predicted == labels_check.numpy()).sum()\n","    \n","    if (i+1) % 8 == 0:\n","      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n","            % (epoch+1, num_epochs, i+1, len(EEGset.train_dataset)//batch_size, \n","               loss.data[0]))\n","  \n","  net.eval()\n","  \n","  # Training accuracy\n","  total = 0\n","  correct = 0\n","  for signals, labels in train_loader:\n","    signals = signals.type(torch.FloatTensor)\n","    signals = Variable(signals)\n","    labels = labels.type(torch.LongTensor)\n","    labels_check = torch.squeeze(labels)\n","    labels = Variable(torch.squeeze(labels))\n","    loc = np.random.choice(1000-time_batch, 4, replace=False)\n","    s0 = signals[:, :, :, loc[0]:(loc[0]+time_batch)]\n","    s1 = signals[:, :, :, loc[1]:(loc[1]+time_batch)]\n","    s2 = signals[:, :, :, loc[2]:(loc[2]+time_batch)]\n","    s3 = signals[:, :, :, loc[3]:(loc[3]+time_batch)]\n","    signals = torch.cat((s0, s1, s2, s3), 0)\n","    labels_more = torch.cat([labels] * 4)\n","    if use_cuda and torch.cuda.is_available():\n","      signals = signals.cuda()\n","      labels_more = labels_more.cuda()\n","    outputs = net(signals)\n","    _, predicted = torch.max(outputs.data, 1)\n","    predicted = predicted.cpu()\n","    predicted = predicted.view(-1, 4).numpy()\n","    predicted, _ = stats.mode(predicted, axis=1)\n","    predicted = np.squeeze(predicted)\n","    total += labels.size(0)\n","    correct += (predicted == labels_check.numpy()).sum()\n","  training_acc_arr[epoch] = (correct/total)\n","  print ('Training Accuracy: %.5f' % training_acc_arr[epoch])\n","  \n","  # Testing accuracy\n","  print ('Testing Accuracy: [', end='')\n","  for subject in range(9):\n","    if subject + 1 == train_subject:\n","      print ('x ', end='')\n","      continue\n","    total = 0\n","    correct = 0\n","    for signals, labels in test_loader[str(subject+1)]:\n","      signals = signals.type(torch.FloatTensor)\n","      signals = Variable(signals)\n","      labels = labels.type(torch.LongTensor)\n","      labels_check = torch.squeeze(labels)\n","      labels = Variable(torch.squeeze(labels))\n","      loc = np.random.choice(1000-time_batch, 4, replace=False)\n","      s0 = signals[:, :, :, loc[0]:(loc[0]+time_batch)]\n","      s1 = signals[:, :, :, loc[1]:(loc[1]+time_batch)]\n","      s2 = signals[:, :, :, loc[2]:(loc[2]+time_batch)]\n","      s3 = signals[:, :, :, loc[3]:(loc[3]+time_batch)]\n","      signals = torch.cat((s0, s1, s2, s3), 0)\n","      labels_more = torch.cat([labels] * 4)\n","      if use_cuda and torch.cuda.is_available():\n","        signals = signals.cuda()\n","        labels_more = labels_more.cuda()\n","      outputs = net(signals)\n","      _, predicted = torch.max(outputs.data, 1)\n","      predicted = predicted.cpu()\n","      predicted = predicted.view(-1, 4).numpy()\n","      predicted, _ = stats.mode(predicted, axis=1)\n","      predicted = np.squeeze(predicted)\n","      total += labels.size(0)\n","      correct += (predicted == labels_check.numpy()).sum()\n","    testing_acc_arr[subject, epoch] = (correct/total)\n","    print ('%.5f ' %(correct/total), end='')\n","  print (']')\n","  print ('Testing Accuracy Average: %.5f' % np.average(testing_acc_arr[np.delete(np.arange(9), train_subject - 1), epoch]))\n","'''"],"execution_count":169,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\ntraining_acc_arr = np.zeros(num_epochs)\\ntesting_acc_arr = np.zeros((9, num_epochs))\\n\\nfor epoch in range(num_epochs):\\n  \\n  net.train()\\n  \\n  total = 0\\n  correct = 0\\n  \\n  for i, (signals, labels) in enumerate(train_loader):\\n    \\n    signals = signals.type(torch.FloatTensor)\\n    signals = Variable(signals)\\n    labels = labels.type(torch.LongTensor)\\n    labels_check = torch.squeeze(labels)\\n    labels = Variable(torch.squeeze(labels))\\n    loc = np.random.choice(1000-time_batch, 4, replace=False)\\n    s0 = signals[:, :, :, loc[0]:(loc[0]+time_batch)]\\n    s1 = signals[:, :, :, loc[1]:(loc[1]+time_batch)]\\n    s2 = signals[:, :, :, loc[2]:(loc[2]+time_batch)]\\n    s3 = signals[:, :, :, loc[3]:(loc[3]+time_batch)]\\n    signals = torch.cat((s0, s1, s2, s3), 0)\\n    labels_more = torch.cat([labels] * 4)\\n    if use_cuda and torch.cuda.is_available():\\n      signals = signals.cuda()\\n      labels_more = labels_more.cuda()\\n    optimizer.zero_grad()\\n    outputs = net(signals)\\n    loss = criterion(outputs, labels_more)\\n    loss.backward()\\n    optimizer.step()\\n    _, predicted = torch.max(outputs.data, 1)\\n    predicted = predicted.cpu()\\n    predicted = predicted.view(-1, 4).numpy()\\n    predicted, _ = stats.mode(predicted, axis=1)\\n    predicted = np.squeeze(predicted)\\n    total += labels.size(0)\\n    correct += (predicted == labels_check.numpy()).sum()\\n    \\n    if (i+1) % 8 == 0:\\n      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \\n            % (epoch+1, num_epochs, i+1, len(EEGset.train_dataset)//batch_size, \\n               loss.data[0]))\\n  \\n  net.eval()\\n  \\n  # Training accuracy\\n  total = 0\\n  correct = 0\\n  for signals, labels in train_loader:\\n    signals = signals.type(torch.FloatTensor)\\n    signals = Variable(signals)\\n    labels = labels.type(torch.LongTensor)\\n    labels_check = torch.squeeze(labels)\\n    labels = Variable(torch.squeeze(labels))\\n    loc = np.random.choice(1000-time_batch, 4, replace=False)\\n    s0 = signals[:, :, :, loc[0]:(loc[0]+time_batch)]\\n    s1 = signals[:, :, :, loc[1]:(loc[1]+time_batch)]\\n    s2 = signals[:, :, :, loc[2]:(loc[2]+time_batch)]\\n    s3 = signals[:, :, :, loc[3]:(loc[3]+time_batch)]\\n    signals = torch.cat((s0, s1, s2, s3), 0)\\n    labels_more = torch.cat([labels] * 4)\\n    if use_cuda and torch.cuda.is_available():\\n      signals = signals.cuda()\\n      labels_more = labels_more.cuda()\\n    outputs = net(signals)\\n    _, predicted = torch.max(outputs.data, 1)\\n    predicted = predicted.cpu()\\n    predicted = predicted.view(-1, 4).numpy()\\n    predicted, _ = stats.mode(predicted, axis=1)\\n    predicted = np.squeeze(predicted)\\n    total += labels.size(0)\\n    correct += (predicted == labels_check.numpy()).sum()\\n  training_acc_arr[epoch] = (correct/total)\\n  print ('Training Accuracy: %.5f' % training_acc_arr[epoch])\\n  \\n  # Testing accuracy\\n  print ('Testing Accuracy: [', end='')\\n  for subject in range(9):\\n    if subject + 1 == train_subject:\\n      print ('x ', end='')\\n      continue\\n    total = 0\\n    correct = 0\\n    for signals, labels in test_loader[str(subject+1)]:\\n      signals = signals.type(torch.FloatTensor)\\n      signals = Variable(signals)\\n      labels = labels.type(torch.LongTensor)\\n      labels_check = torch.squeeze(labels)\\n      labels = Variable(torch.squeeze(labels))\\n      loc = np.random.choice(1000-time_batch, 4, replace=False)\\n      s0 = signals[:, :, :, loc[0]:(loc[0]+time_batch)]\\n      s1 = signals[:, :, :, loc[1]:(loc[1]+time_batch)]\\n      s2 = signals[:, :, :, loc[2]:(loc[2]+time_batch)]\\n      s3 = signals[:, :, :, loc[3]:(loc[3]+time_batch)]\\n      signals = torch.cat((s0, s1, s2, s3), 0)\\n      labels_more = torch.cat([labels] * 4)\\n      if use_cuda and torch.cuda.is_available():\\n        signals = signals.cuda()\\n        labels_more = labels_more.cuda()\\n      outputs = net(signals)\\n      _, predicted = torch.max(outputs.data, 1)\\n      predicted = predicted.cpu()\\n      predicted = predicted.view(-1, 4).numpy()\\n      predicted, _ = stats.mode(predicted, axis=1)\\n      predicted = np.squeeze(predicted)\\n      total += labels.size(0)\\n      correct += (predicted == labels_check.numpy()).sum()\\n    testing_acc_arr[subject, epoch] = (correct/total)\\n    print ('%.5f ' %(correct/total), end='')\\n  print (']')\\n  print ('Testing Accuracy Average: %.5f' % np.average(testing_acc_arr[np.delete(np.arange(9), train_subject - 1), epoch]))\\n\""]},"metadata":{"tags":[]},"execution_count":169}]},{"metadata":{"id":"2JwUcaseoXXV","colab_type":"text"},"cell_type":"markdown","source":["###Print MATLAB Format"]},{"metadata":{"id":"0nSce2gzkAZa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":72},"outputId":"500032b9-6e45-4f4b-cca2-077fdb6d9102","executionInfo":{"status":"ok","timestamp":1521074149202,"user_tz":420,"elapsed":523,"user":{"displayName":"Nathan Wong","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"106327691903472177650"}}},"cell_type":"code","source":["# Print Training Accuracy\n","print('Training_Accuracy = [', end='')\n","for acc in np.nditer(training_acc_arr):\n","  print('%.5f, ' % acc, end='')\n","print('];')\n","\n","# Print Testing Accuracy\n","print('Testing_Accuracy = [', end='')\n","for subject in range(9):\n","  for acc in np.nditer(testing_acc_arr[subject, :]):\n","    print('%.5f, ' % acc, end='')\n","  print('; ', end='')\n","print('];')"],"execution_count":170,"outputs":[{"output_type":"stream","text":["Training_Accuracy = [0.24460, 0.24460, 0.24460, 0.24460, 0.24460, 0.24820, 0.24460, 0.28417, 0.32734, 0.36691, 0.39928, 0.43525, 0.50719, 0.46763, 0.44604, 0.51079, 0.51079, 0.53957, 0.57914, 0.55036, 0.58273, 0.58633, 0.61871, 0.61871, 0.64029, 0.65108, 0.65468, 0.61151, 0.64748, 0.66187, 0.71223, 0.72302, 0.71223, 0.70504, 0.73381, 0.74101, 0.71583, 0.75180, 0.75899, 0.72662, 0.72662, 0.76978, 0.79496, 0.78417, 0.79856, 0.77698, 0.80216, 0.78058, 0.81655, 0.79137, 0.83094, 0.82374, 0.84532, 0.85252, 0.84173, 0.80935, 0.83453, 0.85252, 0.84532, 0.87050, 0.87770, 0.86331, 0.87410, 0.87770, 0.88129, 0.89209, 0.89928, 0.91007, 0.92446, 0.92806, 0.91727, 0.93165, 0.88489, 0.94604, 0.94604, 0.96043, 0.94604, 0.94604, 0.91007, 0.88489, 0.96043, 0.97842, 0.97482, 0.97482, 0.97122, 0.97482, 0.98201, 0.91007, 0.94604, 0.98201, 0.99281, 0.98921, 0.99640, 0.98561, 0.99640, 0.99281, 0.99281, 0.99281, 0.99640, 0.99640, 0.99281, 0.99640, 0.98921, 0.99640, 0.99281, 0.99281, 0.99640, 0.99640, 1.00000, 0.99640, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, 1.00000, ];\n","Testing_Accuracy = [0.25087, 0.25087, 0.25087, 0.25087, 0.25087, 0.25436, 0.25436, 0.29617, 0.29965, 0.29617, 0.33449, 0.34843, 0.33101, 0.31010, 0.34146, 0.33798, 0.35192, 0.36934, 0.32404, 0.36585, 0.36237, 0.30662, 0.36585, 0.35192, 0.29268, 0.33101, 0.32404, 0.29268, 0.30662, 0.35540, 0.32056, 0.32753, 0.31707, 0.32404, 0.30662, 0.32404, 0.34495, 0.33101, 0.31010, 0.34146, 0.34843, 0.29965, 0.32404, 0.30314, 0.34146, 0.31707, 0.31010, 0.35540, 0.35192, 0.31707, 0.30314, 0.35889, 0.34495, 0.34495, 0.36237, 0.29965, 0.29268, 0.37282, 0.34495, 0.33449, 0.33798, 0.33798, 0.31707, 0.37282, 0.38328, 0.36237, 0.34843, 0.34495, 0.36237, 0.36237, 0.34146, 0.36237, 0.37631, 0.36585, 0.35540, 0.35889, 0.35192, 0.37979, 0.37282, 0.37979, 0.35540, 0.36237, 0.35889, 0.36237, 0.35192, 0.35540, 0.34843, 0.37282, 0.36585, 0.34495, 0.36585, 0.36934, 0.35540, 0.36934, 0.35192, 0.38328, 0.35889, 0.34146, 0.35889, 0.36934, 0.35889, 0.35192, 0.36934, 0.36585, 0.36237, 0.36237, 0.35192, 0.36585, 0.36585, 0.35889, 0.37979, 0.37282, 0.36585, 0.36585, 0.37282, 0.36237, 0.36934, 0.36585, 0.36934, 0.37282, 0.36237, 0.36237, 0.36585, 0.36934, 0.36237, 0.36585, 0.36934, 0.36934, 0.36934, 0.36934, 0.36934, 0.36237, 0.36585, 0.36237, 0.36237, 0.36934, 0.36585, 0.36934, 0.36934, 0.36934, 0.36934, 0.36585, 0.36585, 0.36585, 0.36934, 0.36585, 0.36934, 0.36585, 0.36585, 0.36934, 0.36585, 0.36585, 0.36934, 0.36237, 0.36585, 0.36237, 0.36585, 0.36585, 0.36585, 0.36237, 0.36934, 0.36237, 0.36585, 0.36585, 0.36585, 0.36237, 0.36237, 0.36585, 0.36934, 0.36585, 0.36585, 0.36237, 0.36237, 0.36237, 0.36237, 0.36585, 0.36585, 0.36585, 0.36237, 0.36237, 0.35540, 0.36934, 0.35540, 0.36585, 0.35889, 0.36585, 0.36585, 0.35889, 0.36237, 0.36237, 0.35889, 0.36585, 0.35889, 0.36585, 0.35889, 0.36237, 0.36585, 0.35889, 0.35889, 0.35889, ; 0.24476, 0.24476, 0.24476, 0.24476, 0.24476, 0.24476, 0.24476, 0.28671, 0.29021, 0.29720, 0.30769, 0.31119, 0.31119, 0.29720, 0.33916, 0.27972, 0.31469, 0.29720, 0.25874, 0.28671, 0.25874, 0.26224, 0.25175, 0.25874, 0.22378, 0.25524, 0.21678, 0.27972, 0.26923, 0.24476, 0.26573, 0.26224, 0.22727, 0.25524, 0.26224, 0.26573, 0.24825, 0.25874, 0.26224, 0.23427, 0.24476, 0.25175, 0.25524, 0.24476, 0.25175, 0.25874, 0.25175, 0.26224, 0.25874, 0.24825, 0.25874, 0.24825, 0.25874, 0.24476, 0.25524, 0.24825, 0.23776, 0.25175, 0.25524, 0.24126, 0.24825, 0.25175, 0.24476, 0.24825, 0.24825, 0.25175, 0.25874, 0.25175, 0.24825, 0.24825, 0.24825, 0.24825, 0.24126, 0.25175, 0.25175, 0.24825, 0.25524, 0.24126, 0.24476, 0.24825, 0.25175, 0.24476, 0.24476, 0.24476, 0.24825, 0.25175, 0.25175, 0.24476, 0.25524, 0.25175, 0.24476, 0.24825, 0.25175, 0.24825, 0.25175, 0.25524, 0.25175, 0.25175, 0.25874, 0.24825, 0.26224, 0.25175, 0.25175, 0.24476, 0.25524, 0.25175, 0.25524, 0.24126, 0.24825, 0.24476, 0.24126, 0.24476, 0.25524, 0.24825, 0.25175, 0.25524, 0.25175, 0.24825, 0.25524, 0.24825, 0.25524, 0.24476, 0.25524, 0.24476, 0.25874, 0.24476, 0.25524, 0.24126, 0.24126, 0.25874, 0.24825, 0.25874, 0.24476, 0.25874, 0.24126, 0.25874, 0.24825, 0.25175, 0.24825, 0.24126, 0.24126, 0.24476, 0.24476, 0.25175, 0.24126, 0.24825, 0.24126, 0.24825, 0.24476, 0.25524, 0.24825, 0.24825, 0.24476, 0.25175, 0.24476, 0.25175, 0.25175, 0.24825, 0.25175, 0.24825, 0.26224, 0.25175, 0.24825, 0.25524, 0.25175, 0.25175, 0.25175, 0.23427, 0.26224, 0.24126, 0.25175, 0.25175, 0.25524, 0.25175, 0.25524, 0.25524, 0.23776, 0.25524, 0.23776, 0.25874, 0.23776, 0.25524, 0.23776, 0.25874, 0.23776, 0.25524, 0.23776, 0.25175, 0.25175, 0.24126, 0.24825, 0.24825, 0.24825, 0.25175, 0.24126, 0.24825, 0.23427, 0.24825, 0.25175, 0.23776, ; 0.24825, 0.24825, 0.24825, 0.24825, 0.24825, 0.24825, 0.24825, 0.28322, 0.31469, 0.29720, 0.31119, 0.31119, 0.31818, 0.30070, 0.29371, 0.31469, 0.33916, 0.32168, 0.29371, 0.31818, 0.32867, 0.27622, 0.34965, 0.32867, 0.30769, 0.34266, 0.33566, 0.26573, 0.30070, 0.34965, 0.31119, 0.33217, 0.31119, 0.32867, 0.30070, 0.32517, 0.33566, 0.34266, 0.30420, 0.33916, 0.36014, 0.28671, 0.33566, 0.29371, 0.33217, 0.31818, 0.27972, 0.34615, 0.32517, 0.32867, 0.29371, 0.33916, 0.32867, 0.34965, 0.31818, 0.30420, 0.29021, 0.33916, 0.33916, 0.31119, 0.32517, 0.34266, 0.29720, 0.34965, 0.32168, 0.34965, 0.32517, 0.35315, 0.33217, 0.34965, 0.33566, 0.34965, 0.34266, 0.35315, 0.36014, 0.34615, 0.33566, 0.33916, 0.34266, 0.34266, 0.34615, 0.32867, 0.35315, 0.32517, 0.34615, 0.34965, 0.33566, 0.36364, 0.34266, 0.32168, 0.32168, 0.32168, 0.32168, 0.33916, 0.32168, 0.33566, 0.31818, 0.34266, 0.31818, 0.33217, 0.33916, 0.32517, 0.33566, 0.32517, 0.32867, 0.34266, 0.32168, 0.33566, 0.33217, 0.32517, 0.33566, 0.31119, 0.32867, 0.33217, 0.32168, 0.33566, 0.33916, 0.32517, 0.32517, 0.32517, 0.32867, 0.32867, 0.32517, 0.32517, 0.33566, 0.32517, 0.32517, 0.32517, 0.32168, 0.32867, 0.34266, 0.32517, 0.32517, 0.32867, 0.33566, 0.32867, 0.32867, 0.32517, 0.32867, 0.32517, 0.32517, 0.32168, 0.32517, 0.32517, 0.31818, 0.32517, 0.32517, 0.32517, 0.32168, 0.32517, 0.32168, 0.32517, 0.32517, 0.32867, 0.31469, 0.32517, 0.32168, 0.32517, 0.32168, 0.32168, 0.32867, 0.32168, 0.32168, 0.32168, 0.32168, 0.32168, 0.32168, 0.33916, 0.32867, 0.33217, 0.31818, 0.32517, 0.32168, 0.32168, 0.32517, 0.31818, 0.32517, 0.31818, 0.33566, 0.31818, 0.32867, 0.32517, 0.33217, 0.31818, 0.32867, 0.31818, 0.32517, 0.32517, 0.32168, 0.32517, 0.32517, 0.32517, 0.32867, 0.32517, 0.32517, 0.32168, 0.33217, 0.32517, 0.32168, 0.32517, ; 0.25000, 0.25000, 0.25000, 0.25000, 0.25000, 0.25000, 0.25000, 0.33099, 0.29225, 0.32746, 0.33099, 0.36620, 0.30986, 0.35915, 0.36268, 0.32394, 0.36972, 0.34859, 0.35915, 0.36268, 0.35211, 0.32042, 0.35211, 0.34859, 0.30282, 0.35563, 0.31690, 0.27465, 0.29577, 0.34859, 0.29577, 0.27817, 0.32042, 0.27817, 0.27817, 0.28169, 0.28521, 0.27465, 0.27465, 0.32746, 0.28873, 0.27113, 0.27465, 0.26408, 0.26761, 0.27817, 0.25352, 0.28169, 0.27817, 0.26761, 0.25000, 0.26761, 0.26408, 0.26408, 0.28169, 0.26408, 0.26056, 0.29225, 0.27465, 0.25704, 0.26056, 0.27113, 0.26056, 0.27817, 0.28873, 0.28169, 0.26761, 0.26056, 0.27817, 0.28169, 0.26408, 0.27817, 0.29225, 0.28521, 0.27113, 0.27817, 0.27465, 0.27465, 0.28521, 0.29225, 0.28521, 0.28169, 0.27465, 0.28873, 0.26761, 0.27465, 0.27465, 0.28873, 0.27465, 0.26761, 0.28521, 0.28169, 0.27465, 0.26056, 0.26408, 0.26408, 0.27465, 0.26761, 0.26408, 0.25352, 0.28169, 0.27113, 0.28521, 0.26056, 0.29225, 0.26761, 0.26408, 0.27465, 0.25704, 0.26056, 0.26408, 0.25704, 0.26408, 0.26056, 0.25704, 0.26761, 0.26408, 0.26408, 0.26408, 0.26056, 0.26408, 0.26408, 0.26056, 0.26408, 0.26761, 0.26408, 0.26056, 0.26408, 0.26408, 0.27113, 0.26408, 0.26408, 0.26408, 0.26408, 0.26408, 0.26408, 0.26056, 0.26056, 0.26408, 0.26056, 0.26408, 0.26056, 0.26408, 0.26408, 0.26056, 0.26408, 0.26408, 0.26056, 0.26408, 0.26408, 0.26408, 0.26408, 0.26056, 0.26761, 0.26056, 0.26761, 0.26408, 0.26408, 0.26761, 0.26056, 0.26761, 0.26056, 0.26408, 0.26408, 0.26056, 0.26056, 0.26056, 0.26408, 0.26761, 0.26408, 0.26408, 0.26761, 0.26408, 0.26056, 0.26761, 0.26761, 0.26056, 0.26408, 0.26761, 0.26408, 0.27113, 0.26408, 0.27113, 0.26408, 0.26408, 0.26761, 0.26056, 0.26408, 0.26056, 0.26408, 0.26408, 0.26056, 0.26408, 0.26408, 0.26408, 0.26408, 0.27113, 0.26408, 0.26408, 0.26408, ; 0.25532, 0.25532, 0.25532, 0.25532, 0.25532, 0.28723, 0.30142, 0.26596, 0.24113, 0.23759, 0.26596, 0.27660, 0.28014, 0.28369, 0.29787, 0.29787, 0.25887, 0.27660, 0.25532, 0.26596, 0.25177, 0.26950, 0.24468, 0.26241, 0.25887, 0.25532, 0.26596, 0.25887, 0.25532, 0.25887, 0.25887, 0.26241, 0.25887, 0.25887, 0.25887, 0.25887, 0.25532, 0.25532, 0.25532, 0.26241, 0.25887, 0.25532, 0.26241, 0.25532, 0.25177, 0.25177, 0.25177, 0.25887, 0.25887, 0.26241, 0.24823, 0.25532, 0.25177, 0.25887, 0.25532, 0.25887, 0.25177, 0.26241, 0.26596, 0.25532, 0.25532, 0.25887, 0.25887, 0.25532, 0.25177, 0.25177, 0.25887, 0.25887, 0.24468, 0.24823, 0.26241, 0.25532, 0.24468, 0.24113, 0.24823, 0.24823, 0.25177, 0.24823, 0.24823, 0.25532, 0.24823, 0.24823, 0.25177, 0.24468, 0.24823, 0.25177, 0.25177, 0.24823, 0.24113, 0.24823, 0.24113, 0.24113, 0.24468, 0.24823, 0.24468, 0.24113, 0.24113, 0.25887, 0.23759, 0.25532, 0.24823, 0.24468, 0.23404, 0.24113, 0.24823, 0.24823, 0.24113, 0.25532, 0.24113, 0.24468, 0.23759, 0.24823, 0.23759, 0.24113, 0.23404, 0.24468, 0.24823, 0.24113, 0.24113, 0.24823, 0.24468, 0.25177, 0.23759, 0.25177, 0.24468, 0.25532, 0.24823, 0.25532, 0.25177, 0.24468, 0.24823, 0.24468, 0.25177, 0.24823, 0.25177, 0.25177, 0.25177, 0.24823, 0.25532, 0.25177, 0.24823, 0.25177, 0.24823, 0.25177, 0.25177, 0.24823, 0.24468, 0.25177, 0.24823, 0.24823, 0.25177, 0.25177, 0.24468, 0.24823, 0.25177, 0.24823, 0.25177, 0.24468, 0.25177, 0.25177, 0.24468, 0.25177, 0.24468, 0.24468, 0.24823, 0.25177, 0.25177, 0.25177, 0.24823, 0.25177, 0.24823, 0.24823, 0.25177, 0.25177, 0.25177, 0.24823, 0.25177, 0.24823, 0.25177, 0.25177, 0.25177, 0.24468, 0.25177, 0.24823, 0.25177, 0.24468, 0.25177, 0.25177, 0.25177, 0.25177, 0.25177, 0.25177, 0.25177, 0.25177, 0.25177, 0.25177, 0.25177, 0.25177, 0.25177, 0.25177, ; 0.24912, 0.24912, 0.24912, 0.24912, 0.24912, 0.24561, 0.24912, 0.23509, 0.22807, 0.24912, 0.23158, 0.24211, 0.26667, 0.24561, 0.24211, 0.28421, 0.21754, 0.23860, 0.26667, 0.23860, 0.22807, 0.26667, 0.23509, 0.22105, 0.28070, 0.24561, 0.23158, 0.27368, 0.29123, 0.23158, 0.27719, 0.27368, 0.29123, 0.25614, 0.29474, 0.30175, 0.24561, 0.28772, 0.29825, 0.27018, 0.26667, 0.30526, 0.29123, 0.30877, 0.27368, 0.29474, 0.31579, 0.25263, 0.28421, 0.27368, 0.30175, 0.28421, 0.28421, 0.28070, 0.28421, 0.28772, 0.30175, 0.25965, 0.28070, 0.32632, 0.30175, 0.28070, 0.31930, 0.25965, 0.25263, 0.25614, 0.29474, 0.26667, 0.27018, 0.26667, 0.30877, 0.28070, 0.27018, 0.25263, 0.27368, 0.25965, 0.27018, 0.25965, 0.25263, 0.24211, 0.26667, 0.25263, 0.24912, 0.25614, 0.25614, 0.25263, 0.26667, 0.26667, 0.25614, 0.28772, 0.24912, 0.24211, 0.25614, 0.25614, 0.23509, 0.24561, 0.25614, 0.25614, 0.23860, 0.25614, 0.28772, 0.24912, 0.24211, 0.23509, 0.28070, 0.25263, 0.24561, 0.25614, 0.24912, 0.26667, 0.25614, 0.24561, 0.24912, 0.24561, 0.24912, 0.24561, 0.24561, 0.24561, 0.24211, 0.24912, 0.24211, 0.24912, 0.25263, 0.24912, 0.24912, 0.24211, 0.24912, 0.24912, 0.24561, 0.25614, 0.25263, 0.25614, 0.25263, 0.24912, 0.25614, 0.25263, 0.25263, 0.25263, 0.25614, 0.24912, 0.25263, 0.24561, 0.25614, 0.25614, 0.25263, 0.24912, 0.25263, 0.25263, 0.25614, 0.25263, 0.25263, 0.25263, 0.24912, 0.25965, 0.25263, 0.25965, 0.25263, 0.25263, 0.24912, 0.25263, 0.25965, 0.24912, 0.25263, 0.25263, 0.25614, 0.25263, 0.25614, 0.25263, 0.25263, 0.25263, 0.25263, 0.25614, 0.25614, 0.24912, 0.25263, 0.25263, 0.24561, 0.25614, 0.25614, 0.24912, 0.25614, 0.25263, 0.25614, 0.25263, 0.25614, 0.25263, 0.24561, 0.25263, 0.25263, 0.24912, 0.25614, 0.24912, 0.25263, 0.24912, 0.25263, 0.24912, 0.24912, 0.24912, 0.25263, 0.25263, ; 0.25000, 0.25000, 0.25000, 0.25000, 0.25000, 0.28125, 0.27778, 0.30556, 0.28125, 0.28472, 0.28125, 0.26736, 0.28819, 0.27778, 0.27778, 0.27431, 0.27431, 0.24653, 0.23264, 0.24306, 0.22917, 0.22222, 0.22222, 0.24653, 0.21875, 0.22569, 0.22917, 0.23264, 0.22917, 0.22917, 0.22917, 0.22569, 0.22222, 0.23264, 0.21875, 0.21528, 0.21875, 0.21528, 0.22222, 0.22917, 0.23611, 0.22222, 0.22917, 0.22569, 0.21875, 0.23264, 0.21528, 0.22569, 0.23264, 0.22917, 0.22569, 0.22222, 0.22917, 0.22569, 0.23264, 0.23611, 0.22569, 0.24306, 0.23958, 0.23264, 0.23611, 0.24306, 0.23611, 0.24306, 0.24653, 0.24306, 0.23958, 0.23958, 0.24306, 0.24306, 0.24653, 0.23958, 0.22569, 0.25347, 0.25694, 0.24306, 0.25347, 0.24653, 0.23264, 0.24653, 0.26042, 0.24653, 0.25347, 0.24653, 0.26042, 0.25694, 0.25347, 0.22569, 0.21875, 0.25694, 0.25347, 0.24306, 0.25694, 0.22222, 0.25694, 0.23611, 0.25000, 0.26042, 0.23958, 0.22222, 0.25000, 0.24653, 0.23611, 0.24653, 0.25694, 0.22917, 0.24306, 0.23958, 0.22917, 0.25000, 0.23264, 0.24306, 0.23958, 0.23264, 0.23264, 0.24653, 0.23264, 0.23264, 0.24306, 0.22222, 0.24306, 0.22569, 0.23958, 0.23264, 0.23264, 0.22569, 0.23611, 0.22222, 0.22222, 0.22569, 0.22569, 0.23264, 0.22569, 0.22917, 0.22569, 0.22917, 0.21875, 0.23611, 0.22222, 0.22917, 0.22917, 0.22222, 0.22569, 0.22569, 0.22917, 0.22222, 0.22917, 0.22917, 0.22569, 0.22569, 0.22569, 0.22569, 0.22917, 0.22917, 0.22569, 0.23264, 0.22917, 0.22917, 0.22222, 0.22569, 0.22569, 0.22569, 0.22569, 0.23264, 0.23264, 0.22917, 0.22917, 0.22917, 0.22917, 0.22222, 0.23264, 0.23264, 0.22917, 0.22917, 0.22917, 0.23264, 0.22917, 0.23264, 0.22917, 0.22569, 0.23264, 0.23264, 0.23264, 0.23264, 0.22917, 0.23264, 0.22569, 0.22917, 0.22917, 0.22569, 0.23264, 0.22917, 0.23264, 0.22917, 0.22569, 0.23611, 0.22917, 0.23264, 0.22917, 0.23264, ; 0.25532, 0.25532, 0.25532, 0.25532, 0.25532, 0.25532, 0.25532, 0.28723, 0.31560, 0.30851, 0.30851, 0.32624, 0.34397, 0.32624, 0.31915, 0.31560, 0.34397, 0.30851, 0.31206, 0.33333, 0.31560, 0.32979, 0.32979, 0.32270, 0.30851, 0.32624, 0.32270, 0.31915, 0.30142, 0.34752, 0.36525, 0.31206, 0.36525, 0.35106, 0.31560, 0.35461, 0.34043, 0.35106, 0.36525, 0.34397, 0.36525, 0.30496, 0.35106, 0.31560, 0.35106, 0.33333, 0.32270, 0.36525, 0.36879, 0.33688, 0.32979, 0.36879, 0.35816, 0.36879, 0.37589, 0.32624, 0.31206, 0.38652, 0.35106, 0.36170, 0.35461, 0.33688, 0.35106, 0.39007, 0.40071, 0.39362, 0.36170, 0.36525, 0.38652, 0.39007, 0.36525, 0.38298, 0.40071, 0.40071, 0.38652, 0.37943, 0.38652, 0.42553, 0.40780, 0.39716, 0.40071, 0.35106, 0.37234, 0.35816, 0.37234, 0.37234, 0.37589, 0.41844, 0.41489, 0.37589, 0.37234, 0.37234, 0.37589, 0.40780, 0.39362, 0.39716, 0.34752, 0.34397, 0.38652, 0.41844, 0.37943, 0.35461, 0.37943, 0.39362, 0.37943, 0.38652, 0.35106, 0.38298, 0.39716, 0.32624, 0.39716, 0.38652, 0.39007, 0.39716, 0.37943, 0.39007, 0.39716, 0.39007, 0.38298, 0.39362, 0.39362, 0.39362, 0.38652, 0.39716, 0.38652, 0.39362, 0.39007, 0.38652, 0.39007, 0.38652, 0.40426, 0.37943, 0.40071, 0.38652, 0.39716, 0.38298, 0.39362, 0.38652, 0.39716, 0.38652, 0.39007, 0.38652, 0.38652, 0.39362, 0.37943, 0.39007, 0.38652, 0.39362, 0.39007, 0.38652, 0.39362, 0.38652, 0.38298, 0.39007, 0.38298, 0.38652, 0.39007, 0.38298, 0.39362, 0.39007, 0.39007, 0.39007, 0.38652, 0.39007, 0.39007, 0.39007, 0.38652, 0.39362, 0.38298, 0.40071, 0.39007, 0.39362, 0.39007, 0.39362, 0.39362, 0.38652, 0.39362, 0.39362, 0.39362, 0.38652, 0.38652, 0.38652, 0.39007, 0.39007, 0.39362, 0.38652, 0.39007, 0.39362, 0.39007, 0.39362, 0.39362, 0.39007, 0.38652, 0.39007, 0.39007, 0.38652, 0.39716, 0.38652, 0.39007, 0.39362, ; 0.00000, 0.00000, 0.00000, 0.00000, -0.00000, 0.00000, 0.00000, -0.00000, 0.00000, 0.00000, 0.00000, 0.00000, -0.00000, 0.00000, -0.00000, 0.00000, -0.00000, -0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, -0.00000, -0.00000, 0.00000, -0.00000, -0.00000, 0.00000, -0.00000, -0.00000, 0.00000, 0.00000, -0.00000, 0.00000, -0.00000, -0.00000, 0.00000, 0.00000, 0.00000, -0.00000, -0.00000, -0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, -0.00000, 0.00000, -0.00000, -0.00000, 0.00000, 0.00000, -0.00000, -0.00000, 0.00000, 0.00000, -0.00000, 0.00000, 0.00000, -0.00000, -0.00000, -0.00000, -0.00000, 0.00000, -0.00000, 0.00000, -0.00000, -0.00000, -0.00000, -0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, -0.00000, -0.00000, -0.00000, -0.00000, 0.00000, -0.00000, -0.00000, -0.00000, -0.00000, 0.00000, -0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, -0.00000, 0.00000, -0.00000, 0.00000, -0.00000, 0.00000, 0.00000, -0.00000, 0.00000, 0.00000, 0.00000, -0.00000, 0.00000, 0.00000, -0.00000, -0.00000, 0.00000, -0.00000, 0.00000, -0.00000, -0.00000, -0.00000, -0.00000, 0.00000, 0.00000, -0.00000, 0.00000, -0.00000, -0.00000, -0.00000, 0.00000, -0.00000, 0.00000, 0.00000, 0.00000, 0.00000, -0.00000, -0.00000, -0.00000, 0.00000, 0.00000, -0.00000, 0.00000, 0.00000, 0.00000, -0.00000, -0.00000, 0.00000, 0.00000, 0.00000, -0.00000, -0.00000, -0.00000, 0.00000, 0.00000, 0.00000, 0.00000, -0.00000, 0.00000, -0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, -0.00000, 0.00000, -0.00000, -0.00000, -0.00000, -0.00000, 0.00000, 0.00000, -0.00000, 0.00000, 0.00000, 0.00000, -0.00000, 0.00000, 0.00000, -0.00000, 0.00000, -0.00000, 0.00000, -0.00000, -0.00000, 0.00000, 0.00000, -0.00000, -0.00000, -0.00000, -0.00000, -0.00000, 0.00000, -0.00000, 0.00000, 0.00000, -0.00000, 0.00000, 0.00000, -0.00000, 0.00000, ; ];\n"],"name":"stdout"}]}]}