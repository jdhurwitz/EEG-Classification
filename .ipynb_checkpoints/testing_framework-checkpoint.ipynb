{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sNbiI9AOPlq6"
   },
   "source": [
    "# Neural Network Testing Framework\n",
    "This notebook is intended to be a general framework for testing Neural Neworks on the EEG data set. While the initial iteration of this notebook is used for a simple Convolutional Neural Network (CNN), other networks using PyTorch can be implemented and assigned to the neural network variable. Many of the beginning cells are used to intialize for a Google Drive Colaboratory notebook GPU usability and can be ignored as necessary.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2hlystw2Pzbg"
   },
   "source": [
    "##Initialization\n",
    "Google Drive access, PyTorch, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "aEly-WUNrG_n"
   },
   "outputs": [],
   "source": [
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_ioKx_tQsFg"
   },
   "source": [
    "This section provides access to the user's Google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "nyJiSCniN5Sn"
   },
   "outputs": [],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eADEBx-EQNg5"
   },
   "source": [
    "This section creates a drive that links to the user's Google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2420,
     "status": "ok",
     "timestamp": 1520379354307,
     "user": {
      "displayName": "Nathan Wong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106327691903472177650"
     },
     "user_tz": 480
    },
    "id": "YzXqllGHQK6E",
    "outputId": "e14188c2-33bb-4d5d-946d-08cd33c38dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuse: mountpoint is not empty\r\n",
      "fuse: if you are sure this is safe, use the 'nonempty' mount option\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jUfqAB83QuPc"
   },
   "source": [
    "This section installs PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "vS4vRAnsQw2J"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LaZWU_TlQ7Yx"
   },
   "source": [
    "##Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uo96B36sQURz"
   },
   "source": [
    "Imports can be added as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UgT3bxtlRT0U"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.cuda\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RoLPc0SzSM2_"
   },
   "source": [
    "##Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "55Aaa8JmQZpb"
   },
   "source": [
    "###EEGDataset\n",
    "This class inherits the torch.utils.data.Dataset class to be used with the torch.utils.data.Dataloader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ak2uqN0pSPZL"
   },
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "  \"\"\"EEG dataset.\"\"\"\n",
    "  \n",
    "  def __init__(self, x, y, transform=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      x (numpy array): Input data of shape \n",
    "                       num_trials x num_electrodes x num_time_bins.\n",
    "      y (numpy array): Output data of shape num_trials x 1.\n",
    "      transform (callable, optional): Optional transform to be applied.\n",
    "    \"\"\"\n",
    "    self.x = x\n",
    "    self.y = y\n",
    "    self.transform = transform\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    x_sample = torch.from_numpy(self.x[idx])\n",
    "    y_sample = torch.IntTensor([int(self.y[idx])])\n",
    "    \n",
    "    if self.transform:\n",
    "      pass #FIXME\n",
    "    \n",
    "    return x_sample, y_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjPbOPYgQj0f"
   },
   "source": [
    "###EEGMinimalContainer\n",
    "This class holds a train and test EEGDataset. It processes the data into a (N, C, H, W) format in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "6dk7JLAftaXB"
   },
   "outputs": [],
   "source": [
    "class EEGMinimalContainer():\n",
    "  \"\"\"EEG container for training and testing datasets.\"\"\"\n",
    "  \n",
    "  def __init__(self, data_dir, train_subject=None, test_subject=None, \n",
    "               remove_eog_channels=True, seed=42):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      data_dir (string): Path to all A0iT_slice.mat files for i in [1, 9].\n",
    "      train_subject(int): Subject to train on. If None, train on all.\n",
    "      test_subject(int): Subject to test on. If None, train on all except for\n",
    "                         train_subject. Only used if train_subject is not None.\n",
    "    \"\"\"\n",
    "    self.X_train = None\n",
    "    self.y_train = None\n",
    "    self.X_test = None\n",
    "    self.y_test = None\n",
    "    self.train_dataset = None\n",
    "    self.test_dataset = None\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if train_subject is None:\n",
    "      # Step 1: Append all of the input and output data together\n",
    "      X = None\n",
    "      y = None\n",
    "      end = np.empty(9)\n",
    "      for i in np.arange(9):\n",
    "        A0iT = h5py.File(data_dir + ('/A0%dT_slice.mat' % (i+1)), 'r')\n",
    "        X_temp = np.copy(A0iT['image'])\n",
    "        y_temp = np.copy(A0iT['type'])\n",
    "        y_temp = y_temp[0,0:X_temp.shape[0]:1]\n",
    "        y_temp = np.asarray(y_temp, dtype=np.int32)\n",
    "        X = X_temp if X is None else np.append(X, X_temp, axis=0)\n",
    "        y = y_temp if y is None else np.append(y, y_temp, axis=0)\n",
    "        end[i] = X_temp.shape[0] if i == 0 else X_temp.shape[0] + end[i-1]\n",
    "      X = np.expand_dims(X, axis=1)\n",
    "      y -= 769\n",
    "      # Step 2: Remove the EOG\n",
    "      if remove_eog_channels:\n",
    "        X = X[:, :, 0:22, :] \n",
    "      # Step 3: Remove NaN trials\n",
    "      remove_list = []\n",
    "      for i in range(len(X)):\n",
    "        if np.isnan(X[i]).any():\n",
    "          remove_list.append(i)\n",
    "      for trial_row in remove_list:\n",
    "        end[end > trial_row] -= 1\n",
    "      X = np.delete(X, remove_list, axis=0)\n",
    "      y = np.delete(y, remove_list, axis=0)\n",
    "      # Step 4: Generate an train/test split\n",
    "      remove_list = []\n",
    "      self.X_test = {}\n",
    "      self.y_test = {}\n",
    "      self.test_dataset = {}\n",
    "      sloc = 0\n",
    "      for i, eloc in enumerate(end, 1):\n",
    "        t_list = np.random.choice(np.arange(sloc, eloc), 50, replace=False)\n",
    "        t_list = t_list.astype(int)\n",
    "        self.X_test[str(i)] = X[t_list, :, :, :]\n",
    "        self.y_test[str(i)] = y[t_list]\n",
    "        self.test_dataset[str(i)] = EEGDataset(X[t_list, :, :, :], y[t_list])\n",
    "        remove_list = remove_list + t_list.tolist()\n",
    "        sloc = eloc\n",
    "      self.X_train = np.delete(X, remove_list, axis=0)\n",
    "      self.y_train = np.delete(y, remove_list, axis=0)\n",
    "      self.train_dataset = EEGDataset(self.X_train, self.y_train)\n",
    "      \n",
    "      print('EEGContainer X_train: ' + str(self.X_train.shape))\n",
    "      print('EEGContainer y_train: ' + str(self.y_train.shape))\n",
    "      for i in range(1, 10):\n",
    "        print(('EEGContainer X_test%d: ' %i) + str(self.X_test[str(i)].shape))\n",
    "        print(('EEGContainer y_test%d: ' %i) + str(self.y_test[str(i)].shape))\n",
    "    \n",
    "    else:\n",
    "      pass #FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqvKa42SB80Z"
   },
   "source": [
    "###Fully-Connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fWSfDiQfiTKx"
   },
   "source": [
    "####FNN1\n",
    "\n",
    "Extremely Vanilla FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JB85J15zCA3e"
   },
   "outputs": [],
   "source": [
    "class FNN1(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(FNN1, self).__init__()\n",
    "    self.input_size = 1 * 22 * 1000\n",
    "    self.fc1 = nn.Linear(self.input_size, 1000)\n",
    "    self.fc2 = nn.Linear(1000, 500)\n",
    "    self.fc3 = nn.Linear(500, 120)\n",
    "    self.fc4 = nn.Linear(120, 80)\n",
    "    self.fc5 = nn.Linear(80, 4)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = x.view(-1, self.input_size)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = F.relu(self.fc3(x))\n",
    "    x = F.relu(self.fc4(x))\n",
    "    x = F.relu(self.fc5(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vdkmP_PkYU-B"
   },
   "source": [
    "###Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O8qhkxygMgcI"
   },
   "source": [
    "####CNN1\n",
    "Extremely Vanilla CNN. Note the 3x3 convolutions do not take advantage of the temporal information.\n",
    "\n",
    "conv+relu - conv+relu - pool - fc+relu - fc+relu - fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "1Cq6x1TpQ5v7"
   },
   "outputs": [],
   "source": [
    "class CNN1(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN1, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 4, 3, stride=1, padding=1)\n",
    "    self.conv2 = nn.Conv2d(4, 8, 3, stride=1, padding=1)\n",
    "    self.pool = nn.MaxPool2d(2, 2)\n",
    "    self.fc1 = nn.Linear(8 * 11 * 500, 120)\n",
    "    self.fc2 = nn.Linear(120, 80)\n",
    "    self.fc3 = nn.Linear(80, 4)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # x is 1 x 22 x 1000\n",
    "    x = self.pool(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
    "    # x is 8 x 11 x  500\n",
    "    x = x.view(-1, 8 * 11 * 500)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bF93DV3g4nKf"
   },
   "source": [
    "##Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ZtX31_wU67Iu"
   },
   "outputs": [],
   "source": [
    "data_dir = 'drive/ee239as/project_datasets'\n",
    "batch_size = 17\n",
    "num_epochs = 20\n",
    "learning_rate = 1e-3\n",
    "\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7174,
     "status": "ok",
     "timestamp": 1520379368811,
     "user": {
      "displayName": "Nathan Wong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106327691903472177650"
     },
     "user_tz": 480
    },
    "id": "TSyYi0jr5jMk",
    "outputId": "659525d1-9f61-4bfe-ba33-ea5e2c24558a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGContainer X_train: (2108, 1, 22, 1000)\n",
      "EEGContainer y_train: (2108,)\n",
      "EEGContainer X_test1: (50, 1, 22, 1000)\n",
      "EEGContainer y_test1: (50,)\n",
      "EEGContainer X_test2: (50, 1, 22, 1000)\n",
      "EEGContainer y_test2: (50,)\n",
      "EEGContainer X_test3: (50, 1, 22, 1000)\n",
      "EEGContainer y_test3: (50,)\n",
      "EEGContainer X_test4: (50, 1, 22, 1000)\n",
      "EEGContainer y_test4: (50,)\n",
      "EEGContainer X_test5: (50, 1, 22, 1000)\n",
      "EEGContainer y_test5: (50,)\n",
      "EEGContainer X_test6: (50, 1, 22, 1000)\n",
      "EEGContainer y_test6: (50,)\n",
      "EEGContainer X_test7: (50, 1, 22, 1000)\n",
      "EEGContainer y_test7: (50,)\n",
      "EEGContainer X_test8: (50, 1, 22, 1000)\n",
      "EEGContainer y_test8: (50,)\n",
      "EEGContainer X_test9: (50, 1, 22, 1000)\n",
      "EEGContainer y_test9: (50,)\n"
     ]
    }
   ],
   "source": [
    "EEGset = EEGMinimalContainer(data_dir)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(EEGset.train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = {}\n",
    "for i in range(1, 10):\n",
    "  test_loader[str(i)] = torch.utils.data.DataLoader(EEGset.test_dataset[str(i)],\n",
    "                                                    batch_size=10,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "1vXM-eEX7niy"
   },
   "outputs": [],
   "source": [
    "net = CNN1()\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "  net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "FdodrAOa6CyS"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dD4O5-LV7p-M"
   },
   "source": [
    "##Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2481,
     "output_extras": [
      {
       "item_id": 45
      },
      {
       "item_id": 85
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 64500,
     "status": "ok",
     "timestamp": 1520379435280,
     "user": {
      "displayName": "Nathan Wong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "106327691903472177650"
     },
     "user_tz": 480
    },
    "id": "S_EVgnxX7rEa",
    "outputId": "a6aaea2c-bacb-499c-845d-9d7044779582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [31/124], Loss: 1.5090\n",
      "Epoch [1/20], Step [62/124], Loss: 1.3263\n",
      "Epoch [1/20], Step [93/124], Loss: 1.3644\n",
      "Epoch [1/20], Step [124/124], Loss: 1.4613\n",
      "Training Accuracy: 0.46395\n",
      "Testing Accuracy: [0.26 0.3  0.36 0.28 0.28 0.3  0.32 0.22 0.26]\n",
      "Testing Accuracy Average: 0.28667\n",
      "Epoch [2/20], Step [31/124], Loss: 1.1848\n",
      "Epoch [2/20], Step [62/124], Loss: 1.3234\n",
      "Epoch [2/20], Step [93/124], Loss: 1.2599\n",
      "Epoch [2/20], Step [124/124], Loss: 1.2096\n",
      "Training Accuracy: 0.60104\n",
      "Testing Accuracy: [0.28 0.28 0.24 0.32 0.36 0.2  0.38 0.38 0.26]\n",
      "Testing Accuracy Average: 0.30000\n",
      "Epoch [3/20], Step [31/124], Loss: 0.6771\n",
      "Epoch [3/20], Step [62/124], Loss: 0.5387\n",
      "Epoch [3/20], Step [93/124], Loss: 0.6532\n",
      "Epoch [3/20], Step [124/124], Loss: 0.7100\n",
      "Training Accuracy: 0.89374\n",
      "Testing Accuracy: [0.38 0.32 0.34 0.3  0.32 0.28 0.5  0.36 0.4 ]\n",
      "Testing Accuracy Average: 0.35556\n",
      "Epoch [4/20], Step [31/124], Loss: 0.3586\n",
      "Epoch [4/20], Step [62/124], Loss: 0.2464\n",
      "Epoch [4/20], Step [93/124], Loss: 0.2360\n",
      "Epoch [4/20], Step [124/124], Loss: 0.3071\n",
      "Training Accuracy: 0.98814\n",
      "Testing Accuracy: [0.38 0.38 0.4  0.38 0.36 0.3  0.46 0.28 0.5 ]\n",
      "Testing Accuracy Average: 0.38222\n",
      "Epoch [5/20], Step [31/124], Loss: 0.0715\n",
      "Epoch [5/20], Step [62/124], Loss: 0.0306\n",
      "Epoch [5/20], Step [93/124], Loss: 0.0370\n",
      "Epoch [5/20], Step [124/124], Loss: 0.0255\n",
      "Training Accuracy: 0.99051\n",
      "Testing Accuracy: [0.36 0.42 0.36 0.42 0.42 0.38 0.56 0.36 0.4 ]\n",
      "Testing Accuracy Average: 0.40889\n",
      "Epoch [6/20], Step [31/124], Loss: 0.0160\n",
      "Epoch [6/20], Step [62/124], Loss: 0.1162\n",
      "Epoch [6/20], Step [93/124], Loss: 0.0306\n",
      "Epoch [6/20], Step [124/124], Loss: 0.0863\n",
      "Training Accuracy: 0.99099\n",
      "Testing Accuracy: [0.46 0.4  0.34 0.42 0.38 0.36 0.44 0.3  0.46]\n",
      "Testing Accuracy Average: 0.39556\n",
      "Epoch [7/20], Step [31/124], Loss: 0.0065\n",
      "Epoch [7/20], Step [62/124], Loss: 0.0018\n",
      "Epoch [7/20], Step [93/124], Loss: 0.0062\n",
      "Epoch [7/20], Step [124/124], Loss: 0.0059\n",
      "Training Accuracy: 0.99905\n",
      "Testing Accuracy: [0.5  0.34 0.3  0.44 0.38 0.34 0.46 0.4  0.52]\n",
      "Testing Accuracy Average: 0.40889\n",
      "Epoch [8/20], Step [31/124], Loss: 0.0030\n",
      "Epoch [8/20], Step [62/124], Loss: 0.0010\n",
      "Epoch [8/20], Step [93/124], Loss: 0.0012\n",
      "Epoch [8/20], Step [124/124], Loss: 0.0006\n",
      "Training Accuracy: 0.99953\n",
      "Testing Accuracy: [0.5  0.4  0.28 0.44 0.44 0.38 0.52 0.46 0.52]\n",
      "Testing Accuracy Average: 0.43778\n",
      "Epoch [9/20], Step [31/124], Loss: 0.0003\n",
      "Epoch [9/20], Step [62/124], Loss: 0.1775\n",
      "Epoch [9/20], Step [93/124], Loss: 0.0698\n",
      "Epoch [9/20], Step [124/124], Loss: 0.1361\n",
      "Training Accuracy: 0.98529\n",
      "Testing Accuracy: [0.42 0.34 0.32 0.44 0.38 0.32 0.44 0.4  0.48]\n",
      "Testing Accuracy Average: 0.39333\n",
      "Epoch [10/20], Step [31/124], Loss: 0.0142\n",
      "Epoch [10/20], Step [62/124], Loss: 0.0046\n",
      "Epoch [10/20], Step [93/124], Loss: 0.1439\n",
      "Epoch [10/20], Step [124/124], Loss: 0.1045\n",
      "Training Accuracy: 0.98767\n",
      "Testing Accuracy: [0.42 0.42 0.34 0.44 0.36 0.34 0.5  0.46 0.38]\n",
      "Testing Accuracy Average: 0.40667\n",
      "Epoch [11/20], Step [31/124], Loss: 0.0055\n",
      "Epoch [11/20], Step [62/124], Loss: 0.0015\n",
      "Epoch [11/20], Step [93/124], Loss: 0.0706\n",
      "Epoch [11/20], Step [124/124], Loss: 0.0361\n",
      "Training Accuracy: 0.99004\n",
      "Testing Accuracy: [0.42 0.38 0.44 0.38 0.32 0.34 0.48 0.38 0.42]\n",
      "Testing Accuracy Average: 0.39556\n",
      "Epoch [12/20], Step [31/124], Loss: 0.0632\n",
      "Epoch [12/20], Step [62/124], Loss: 0.0069\n",
      "Epoch [12/20], Step [93/124], Loss: 0.0289\n",
      "Epoch [12/20], Step [124/124], Loss: 0.0151\n",
      "Training Accuracy: 0.99953\n",
      "Testing Accuracy: [0.4  0.32 0.24 0.36 0.44 0.32 0.44 0.42 0.44]\n",
      "Testing Accuracy Average: 0.37556\n",
      "Epoch [13/20], Step [31/124], Loss: 0.0050\n",
      "Epoch [13/20], Step [62/124], Loss: 0.0005\n",
      "Epoch [13/20], Step [93/124], Loss: 0.0005\n",
      "Epoch [13/20], Step [124/124], Loss: 0.0013\n",
      "Training Accuracy: 1.00000\n",
      "Testing Accuracy: [0.44 0.38 0.28 0.36 0.38 0.4  0.44 0.48 0.38]\n",
      "Testing Accuracy Average: 0.39333\n",
      "Epoch [14/20], Step [31/124], Loss: 0.0006\n",
      "Epoch [14/20], Step [62/124], Loss: 0.0005\n",
      "Epoch [14/20], Step [93/124], Loss: 0.0002\n",
      "Epoch [14/20], Step [124/124], Loss: 0.0002\n",
      "Training Accuracy: 1.00000\n",
      "Testing Accuracy: [0.46 0.38 0.28 0.4  0.4  0.38 0.44 0.48 0.44]\n",
      "Testing Accuracy Average: 0.40667\n",
      "Epoch [15/20], Step [31/124], Loss: 0.0005\n",
      "Epoch [15/20], Step [62/124], Loss: 0.0005\n",
      "Epoch [15/20], Step [93/124], Loss: 0.0003\n",
      "Epoch [15/20], Step [124/124], Loss: 0.0000\n",
      "Training Accuracy: 1.00000\n",
      "Testing Accuracy: [0.48 0.38 0.28 0.4  0.4  0.36 0.44 0.48 0.44]\n",
      "Testing Accuracy Average: 0.40667\n",
      "Epoch [16/20], Step [31/124], Loss: 0.0000\n",
      "Epoch [16/20], Step [62/124], Loss: 0.0003\n",
      "Epoch [16/20], Step [93/124], Loss: 0.0004\n",
      "Epoch [16/20], Step [124/124], Loss: 0.0002\n",
      "Training Accuracy: 1.00000\n",
      "Testing Accuracy: [0.48 0.38 0.28 0.4  0.42 0.38 0.44 0.48 0.44]\n",
      "Testing Accuracy Average: 0.41111\n",
      "Epoch [17/20], Step [31/124], Loss: 0.0001\n",
      "Epoch [17/20], Step [62/124], Loss: 0.0003\n",
      "Epoch [17/20], Step [93/124], Loss: 0.0001\n",
      "Epoch [17/20], Step [124/124], Loss: 0.0001\n",
      "Training Accuracy: 1.00000\n",
      "Testing Accuracy: [0.48 0.38 0.28 0.4  0.42 0.38 0.44 0.48 0.44]\n",
      "Testing Accuracy Average: 0.41111\n",
      "Epoch [18/20], Step [31/124], Loss: 0.0001\n",
      "Epoch [18/20], Step [62/124], Loss: 0.0002\n",
      "Epoch [18/20], Step [93/124], Loss: 0.0002\n",
      "Epoch [18/20], Step [124/124], Loss: 0.0002\n",
      "Training Accuracy: 1.00000\n",
      "Testing Accuracy: [0.46 0.38 0.3  0.4  0.4  0.38 0.44 0.48 0.44]\n",
      "Testing Accuracy Average: 0.40889\n",
      "Epoch [19/20], Step [31/124], Loss: 0.0002\n",
      "Epoch [19/20], Step [62/124], Loss: 0.0001\n",
      "Epoch [19/20], Step [93/124], Loss: 0.0001\n",
      "Epoch [19/20], Step [124/124], Loss: 0.0002\n",
      "Training Accuracy: 1.00000\n",
      "Testing Accuracy: [0.48 0.38 0.3  0.4  0.4  0.38 0.44 0.5  0.44]\n",
      "Testing Accuracy Average: 0.41333\n",
      "Epoch [20/20], Step [31/124], Loss: 0.0000\n",
      "Epoch [20/20], Step [62/124], Loss: 0.0000\n",
      "Epoch [20/20], Step [93/124], Loss: 0.0002\n",
      "Epoch [20/20], Step [124/124], Loss: 0.0001\n",
      "Training Accuracy: 1.00000\n",
      "Testing Accuracy: [0.48 0.38 0.3  0.4  0.4  0.38 0.44 0.5  0.44]\n",
      "Testing Accuracy Average: 0.41333\n"
     ]
    }
   ],
   "source": [
    "loss_arr = np.empty(num_epochs * (len(EEGset.train_dataset)//batch_size))\n",
    "training_acc_arr = np.empty(num_epochs)\n",
    "testing_acc_arr = np.empty((9, num_epochs))\n",
    "\n",
    "j = 0\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (signals, labels) in enumerate(train_loader):\n",
    "    \n",
    "    signals = signals.type(torch.FloatTensor)\n",
    "    signals = Variable(signals)\n",
    "    labels = labels.type(torch.LongTensor)\n",
    "    labels = Variable(torch.squeeze(labels))\n",
    "    \n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "      signals = signals.cuda()\n",
    "      labels = labels.cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(signals)\n",
    "    \n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_arr[j] = loss.data[0]\n",
    "    j += 1\n",
    "    \n",
    "    if (i+1) % 31 == 0:\n",
    "      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "            % (epoch+1, num_epochs, i+1, len(EEGset.train_dataset)//batch_size, \n",
    "               loss.data[0]))\n",
    "  \n",
    "  # Training accuracy\n",
    "  total = 0\n",
    "  correct = 0\n",
    "  for signals, labels in train_loader:\n",
    "    signals = signals.type(torch.FloatTensor)\n",
    "    signals = Variable(signals)\n",
    "    labels = torch.squeeze(labels.type(torch.LongTensor))\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "      signals = signals.cuda()\n",
    "      labels = labels.cuda()\n",
    "    outputs = net(signals)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "  training_acc_arr[epoch] = (correct/total)\n",
    "  print ('Training Accuracy: %.5f' % training_acc_arr[epoch])\n",
    "  \n",
    "  \n",
    "  # Testing accuracy\n",
    "  for subject in range(9):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for signals, labels in test_loader[str(subject+1)]:\n",
    "      signals = signals.type(torch.FloatTensor)\n",
    "      signals = Variable(signals)\n",
    "      labels = torch.squeeze(labels.type(torch.LongTensor))\n",
    "      if use_cuda and torch.cuda.is_available():\n",
    "        signals = signals.cuda()\n",
    "        labels = labels.cuda()\n",
    "      outputs = net(signals)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum()\n",
    "    testing_acc_arr[subject, epoch] = (correct/total)\n",
    "  print ('Testing Accuracy: ' + str(testing_acc_arr[:, epoch]))\n",
    "  print ('Testing Accuracy Average: %.5f' % np.average(testing_acc_arr[:, epoch]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JwUcaseoXXV"
   },
   "source": [
    "###Print MATLAB Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0nSce2gzkAZa"
   },
   "outputs": [],
   "source": [
    "# Print Loss\n",
    "print('Loss = [', end='')\n",
    "for lossval in np.nditer(loss_arr):\n",
    "  print('%.5f, ' % lossval, end='')\n",
    "print('];')\n",
    "\n",
    "# Print Training Accuracy\n",
    "print('Training_Accuracy = [', end='')\n",
    "for acc in np.nditer(training_acc_arr):\n",
    "  print('%.5f, ' % acc, end='')\n",
    "print('];')\n",
    "\n",
    "# Print Testing Accuracy\n",
    "print('Testing_Accuracy = [', end='')\n",
    "for subject in range(9):\n",
    "  for acc in np.nditer(testing_acc_arr[subject, :]):\n",
    "    print('%.5f, ' % acc, end='')\n",
    "  print('; ', end='')\n",
    "print('];')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "testing_framework.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
