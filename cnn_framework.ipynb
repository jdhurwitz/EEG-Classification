{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_framework.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": [
        "kT0Nn-z7pq0j",
        "fWSfDiQfiTKx",
        "O8qhkxygMgcI",
        "O5r5PaKXr91n",
        "Wa658LXEi5fH",
        "gGZSyB7rF92k",
        "naI1DnC3XpIS",
        "jboIGrdVeQ7Y",
        "iyL4m-XUgqpq",
        "Ra-LrmnbtSa0",
        "ndrqpYoTIL2d",
        "cazF-KMmGb3b",
        "CUQrG0-PlEnh",
        "irM2tZhLSEuY",
        "0AMb7ZxOFuV_",
        "qwRCHmhJYTCn",
        "dxiFDoBDuoTX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "sNbiI9AOPlq6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Network Testing Framework\n",
        "This notebook is intended to be a general framework for testing Neural Neworks on the EEG data set. While the initial iteration of this notebook is used for a simple Convolutional Neural Network (CNN), other networks using PyTorch can be implemented and assigned to the neural network variable. Many of the beginning cells are used to intialize for a Google Drive Colaboratory notebook GPU usability and can be ignored as necessary.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2hlystw2Pzbg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Initialization\n",
        "Google Drive access, PyTorch, etc."
      ]
    },
    {
      "metadata": {
        "id": "aEly-WUNrG_n",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_ioKx_tQsFg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This section provides access to the user's Google drive."
      ]
    },
    {
      "metadata": {
        "id": "nyJiSCniN5Sn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 4
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "0446282c-1da0-4734-c484-f1ec51de5b77",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520960537269,
          "user_tz": 420,
          "elapsed": 15159,
          "user": {
            "displayName": "Nathan Wong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106327691903472177650"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eADEBx-EQNg5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This section creates a drive that links to the user's Google drive."
      ]
    },
    {
      "metadata": {
        "id": "YzXqllGHQK6E",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUfqAB83QuPc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This section installs PyTorch."
      ]
    },
    {
      "metadata": {
        "id": "vS4vRAnsQw2J",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LaZWU_TlQ7Yx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ]
    },
    {
      "metadata": {
        "id": "Uo96B36sQURz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Imports can be added as necessary."
      ]
    },
    {
      "metadata": {
        "id": "UgT3bxtlRT0U",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.cuda\n",
        "from torch.utils.data import Dataset\n",
        "from torch.autograd import Variable\n",
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RoLPc0SzSM2_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Classes"
      ]
    },
    {
      "metadata": {
        "id": "55Aaa8JmQZpb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###EEGDataset\n",
        "This class inherits the torch.utils.data.Dataset class to be used with the torch.utils.data.Dataloader class."
      ]
    },
    {
      "metadata": {
        "id": "ak2uqN0pSPZL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class EEGDataset(Dataset):\n",
        "  \"\"\"EEG dataset.\"\"\"\n",
        "  \n",
        "  def __init__(self, x, y, transform=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      x (numpy array): Input data of shape \n",
        "                       num_trials x num_electrodes x num_time_bins.\n",
        "      y (numpy array): Output data of shape num_trials x 1.\n",
        "      transform (callable, optional): Optional transform to be applied.\n",
        "    \"\"\"\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.transform = transform\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    x_sample = torch.from_numpy(self.x[idx])\n",
        "    y_sample = torch.IntTensor([int(self.y[idx])])\n",
        "    \n",
        "    if self.transform:\n",
        "      pass #FIXME\n",
        "    \n",
        "    return x_sample, y_sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PjPbOPYgQj0f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###EEGMinimalContainer\n",
        "This class holds a train and test EEGDataset. It processes the data into a (N, C, H, W) format in time."
      ]
    },
    {
      "metadata": {
        "id": "6dk7JLAftaXB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class EEGMinimalContainer():\n",
        "  \"\"\"EEG container for training and testing datasets.\"\"\"\n",
        "  \n",
        "  def __init__(self, data_dir, train_subject=None, test_subject=None, \n",
        "               remove_eog_channels=True, seed=42):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      data_dir (string): Path to all A0iT_slice.mat files for i in [1, 9].\n",
        "      train_subject(int): Subject to train on. If None, train on all.\n",
        "      test_subject(int): Subject to test on. If None, train on all except for\n",
        "                         train_subject. Only used if train_subject is not None.\n",
        "    \"\"\"\n",
        "    self.X_train = None\n",
        "    self.y_train = None\n",
        "    self.X_test = None\n",
        "    self.y_test = None\n",
        "    self.train_dataset = None\n",
        "    self.test_dataset = None\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    if train_subject is None:\n",
        "      # Step 1: Append all of the input and output data together\n",
        "      X = None\n",
        "      y = None\n",
        "      end = np.empty(9)\n",
        "      for i in np.arange(9):\n",
        "        A0iT = h5py.File(data_dir + ('/A0%dT_slice.mat' % (i+1)), 'r')\n",
        "        X_temp = np.copy(A0iT['image'])\n",
        "        y_temp = np.copy(A0iT['type'])\n",
        "        y_temp = y_temp[0,0:X_temp.shape[0]:1]\n",
        "        y_temp = np.asarray(y_temp, dtype=np.int32)\n",
        "        X = X_temp if X is None else np.append(X, X_temp, axis=0)\n",
        "        y = y_temp if y is None else np.append(y, y_temp, axis=0)\n",
        "        end[i] = X_temp.shape[0] if i == 0 else X_temp.shape[0] + end[i-1]\n",
        "      X = np.expand_dims(X, axis=1)\n",
        "      y -= 769\n",
        "      # Step 2: Remove the EOG\n",
        "      if remove_eog_channels:\n",
        "        X = X[:, :, 0:22, :] \n",
        "      # Step 3: Remove NaN trials\n",
        "      remove_list = []\n",
        "      for i in range(len(X)):\n",
        "        if np.isnan(X[i]).any():\n",
        "          remove_list.append(i)\n",
        "      for trial_row in remove_list:\n",
        "        end[end > trial_row] -= 1\n",
        "      X = np.delete(X, remove_list, axis=0)\n",
        "      y = np.delete(y, remove_list, axis=0)\n",
        "      # Step 4: Generate an train/test split\n",
        "      remove_list = []\n",
        "      self.X_test = {}\n",
        "      self.y_test = {}\n",
        "      self.test_dataset = {}\n",
        "      sloc = 0\n",
        "      for i, eloc in enumerate(end, 1):\n",
        "        t_list = np.random.choice(np.arange(sloc, eloc), 50, replace=False)\n",
        "        t_list = t_list.astype(int)\n",
        "        self.X_test[str(i)] = X[t_list, :, :, :]\n",
        "        self.y_test[str(i)] = y[t_list]\n",
        "        self.test_dataset[str(i)] = EEGDataset(X[t_list, :, :, :], y[t_list])\n",
        "        remove_list = remove_list + t_list.tolist()\n",
        "        sloc = eloc\n",
        "      self.X_train = np.delete(X, remove_list, axis=0)\n",
        "      self.y_train = np.delete(y, remove_list, axis=0)\n",
        "      self.train_dataset = EEGDataset(self.X_train, self.y_train)\n",
        "      \n",
        "      print('EEGContainer X_train: ' + str(self.X_train.shape))\n",
        "      print('EEGContainer y_train: ' + str(self.y_train.shape))\n",
        "      for i in range(1, 10):\n",
        "        print(('EEGContainer X_test%d: ' %i) + str(self.X_test[str(i)].shape))\n",
        "        print(('EEGContainer y_test%d: ' %i) + str(self.y_test[str(i)].shape))\n",
        "    \n",
        "    else:\n",
        "      pass #FIXME"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kT0Nn-z7pq0j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####EEGCroppedContainer\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ZTWeouZDpyFP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class EEGCroppedContainer():\n",
        "  \"\"\"EEG container for training and testing datasets.\"\"\"\n",
        "  \n",
        "  def __init__(self, data_dir, crop_size, train_subject=None, test_subject=None, \n",
        "               remove_eog_channels=True, seed=42):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      data_dir (string): Path to all A0iT_slice.mat files for i in [1, 9].\n",
        "      train_subject(int): Subject to train on. If None, train on all.\n",
        "      test_subject(int): Subject to test on. If None, train on all except for\n",
        "                         train_subject. Only used if train_subject is not None.\n",
        "    \"\"\"\n",
        "    self.X_train = None\n",
        "    self.y_train = None\n",
        "    self.X_test = None\n",
        "    self.y_test = None\n",
        "    self.train_dataset = None\n",
        "    self.test_dataset = None\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    if train_subject is None:\n",
        "      # Step 1: Append all of the input and output data together\n",
        "      X = None\n",
        "      y = None\n",
        "      end = np.empty(9)\n",
        "      for i in np.arange(9):\n",
        "        A0iT = h5py.File(data_dir + ('/A0%dT_slice.mat' % (i+1)), 'r')\n",
        "        X_temp = np.copy(A0iT['image'])\n",
        "        y_temp = np.copy(A0iT['type'])\n",
        "        y_temp = y_temp[0,0:X_temp.shape[0]:1]\n",
        "        y_temp = np.asarray(y_temp, dtype=np.int32)\n",
        "        X = X_temp if X is None else np.append(X, X_temp, axis=0)\n",
        "        y = y_temp if y is None else np.append(y, y_temp, axis=0)\n",
        "        end[i] = X_temp.shape[0] if i == 0 else X_temp.shape[0] + end[i-1]\n",
        "      X = np.expand_dims(X, axis=1)\n",
        "      y -= 769\n",
        "      # Step 2: Remove the EOG\n",
        "      if remove_eog_channels:\n",
        "        X = X[:, :, 0:22, :] \n",
        "      # Step 3: Remove NaN trials\n",
        "      remove_list = []\n",
        "      for i in range(len(X)):\n",
        "        if np.isnan(X[i]).any():\n",
        "          remove_list.append(i)\n",
        "      for trial_row in remove_list:\n",
        "        end[end > trial_row] -= 1\n",
        "      X = np.delete(X, remove_list, axis=0)\n",
        "      y = np.delete(y, remove_list, axis=0)\n",
        "      # Step 4: Generate an test split\n",
        "      remove_list = []\n",
        "      self.X_test = {}\n",
        "      self.y_test = {}\n",
        "      self.test_dataset = {}\n",
        "      sloc = 0\n",
        "      for i, eloc in enumerate(end, 1):\n",
        "        t_list = np.random.choice(np.arange(sloc, eloc), 50, replace=False)\n",
        "        t_list = t_list.astype(int)\n",
        "        self.X_test[str(i)] = X[t_list, :, :, :]\n",
        "        self.y_test[str(i)] = y[t_list]\n",
        "        self.test_dataset[str(i)] = EEGDataset(X[t_list, :, :, :], y[t_list])\n",
        "        remove_list = remove_list + t_list.tolist()\n",
        "        sloc = eloc\n",
        "      # Step 5: Go through and create a cropped train split\n",
        "      X_train = np.delete(X, remove_list, axis=0)\n",
        "      y_train = np.delete(y, remove_list, axis=0)\n",
        "      self.X_train = None\n",
        "      for i in range(1000 - crop_size):\n",
        "        X_train_temp = X_train[:, :, :, i:(i+crop_size)]\n",
        "        if self.X_train is None:\n",
        "          self.X_train = X_train_temp\n",
        "        else:\n",
        "          self.X_train = np.concatenate((self.X_train, X_train_temp), 0)\n",
        "      self.y_train = np.tile(y_train, 1000 - crop_size)\n",
        "      self.train_dataset = EEGDataset(self.X_train, self.y_train)\n",
        "      \n",
        "      print('EEGContainer X_train: ' + str(self.X_train.shape))\n",
        "      print('EEGContainer y_train: ' + str(self.y_train.shape))\n",
        "      for i in range(1, 10):\n",
        "        print(('EEGContainer X_test%d: ' %i) + str(self.X_test[str(i)].shape))\n",
        "        print(('EEGContainer y_test%d: ' %i) + str(self.y_test[str(i)].shape))\n",
        "    \n",
        "    else:\n",
        "      pass #FIXME"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mqvKa42SB80Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Fully-Connected Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "fWSfDiQfiTKx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####FNN1\n",
        "\n",
        "Extremely Vanilla FNN"
      ]
    },
    {
      "metadata": {
        "id": "JB85J15zCA3e",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class FNN1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FNN1, self).__init__()\n",
        "    self.input_size = 1 * 22 * 1000\n",
        "    self.fc1 = nn.Linear(self.input_size, 1000)\n",
        "    self.fc2 = nn.Linear(1000, 500)\n",
        "    self.fc3 = nn.Linear(500, 200)\n",
        "    self.fc4 = nn.Linear(200, 100)\n",
        "    self.fc5 = nn.Linear(100, 4)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, self.input_size)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = F.relu(self.fc4(x))\n",
        "    x = F.relu(self.fc5(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vdkmP_PkYU-B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "O8qhkxygMgcI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN1 (CNN1)\n",
        "Extremely Vanilla CNN. Note the 3x3 convolutions do not take advantage of the temporal information.\n",
        "\n",
        "conv+relu - conv+relu - pool - fc+relu - fc+relu - fc"
      ]
    },
    {
      "metadata": {
        "id": "1Cq6x1TpQ5v7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class CNN1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN1, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 4, 3, stride=1, padding=1)\n",
        "    self.conv2 = nn.Conv2d(4, 8, 3, stride=1, padding=1)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(8 * 11 * 500, 120)\n",
        "    self.fc2 = nn.Linear(120, 80)\n",
        "    self.fc3 = nn.Linear(80, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # x is 1 x 22 x 1000\n",
        "    x = self.pool(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "    # x is 8 x 11 x  500\n",
        "    x = x.view(-1, 8 * 11 * 500)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O5r5PaKXr91n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN2\n",
        "\n",
        "CNN now consider temporal dependencies. Does marginally better than first CNN; we may need to add BatchNorm / Dropout / Weight Normalization.\n",
        "\n",
        "[conv - conv - pool] x 2 - [conv - pool] x 3 - [fc] x 3"
      ]
    },
    {
      "metadata": {
        "id": "SI2gWYZssBcZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class CNN2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN2, self).__init__()\n",
        "    self.conv1 = nn.Conv2d( 1, 16, (1, 11), stride=(1, 1), padding=0)\n",
        "    self.conv2 = nn.Conv2d(16, 16, (22, 1), stride=(1, 1), padding=0)\n",
        "    self.conv3 = nn.Conv2d( 1, 16, (1, 11), stride=(1, 1), padding=0)\n",
        "    self.conv4 = nn.Conv2d(16, 16, (16, 1), stride=(1, 1), padding=0)\n",
        "    self.conv5 = nn.Conv2d( 1, 16, 3, stride=1, padding=1)\n",
        "    self.conv6 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
        "    self.conv7 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
        "    self.fc_1 = nn.Linear(64 * 2 * 10, 200)\n",
        "    self.fc_2 = nn.Linear(200, 100)\n",
        "    self.fc_3 = nn.Linear(100, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = x.permute(0, 2, 1, 3)\n",
        "    x = F.max_pool2d(x, (1, 3), (1, 3))\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = x.permute(0, 2, 1, 3)\n",
        "    x = F.max_pool2d(x, (1, 4), (1, 4))\n",
        "    x = F.max_pool2d(F.relu(self.conv5(x)), 2, 2)\n",
        "    x = F.max_pool2d(F.relu(self.conv6(x)), 2, 2)\n",
        "    x = F.max_pool2d(F.relu(self.conv7(x)), 2, 2)\n",
        "    x = x.view(-1, 64 * 2 * 10)\n",
        "    x = F.relu(self.fc_1(x))\n",
        "    x = F.relu(self.fc_2(x))\n",
        "    x = self.fc_3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wa658LXEi5fH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN3 (CNN2)\n",
        "\n",
        "An attempt to simplify CNN2. Did not come to expectation, due to less layers.\n",
        "\n",
        "[conv - conv - pool] x 1 - [conv - pool] x 1 - [fc] x 3"
      ]
    },
    {
      "metadata": {
        "id": "QuD_7cypi8ZW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class CNN3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN3, self).__init__()\n",
        "    self.conv1 = nn.Conv2d( 1, 16, (1, 11), stride=1, padding=0)\n",
        "    self.conv2 = nn.Conv2d(16, 16, (22, 1), stride=1, padding=0)\n",
        "    self.pool_1 = nn.MaxPool2d((1, 3), (1, 3))\n",
        "    self.conv3 = nn.Conv2d(1, 16, 3, stride=1, padding=1)\n",
        "    self.pool_2 = nn.MaxPool2d(2, 2)\n",
        "    self.fc_1 = nn.Linear(16 * 8 * 165, 120)\n",
        "    self.fc_2 = nn.Linear(120, 80)\n",
        "    self.fc_3 = nn.Linear(80, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool_1(x.permute(0, 2, 1, 3))\n",
        "    x = self.pool_2(F.relu(self.conv3(x)))\n",
        "    x = x.view(-1, 16 * 8 * 165)\n",
        "    x = F.relu(self.fc_1(x))\n",
        "    x = F.relu(self.fc_2(x))\n",
        "    x = self.fc_3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gGZSyB7rF92k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN4 (CNN3)\n",
        "\n",
        "Let's consider long time dependencies.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "JxzbgVbsGB69",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class CNN4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN4, self).__init__()\n",
        "    self.conv1 = nn.Conv2d( 1, 16, (1, 11), stride=1, padding=0)\n",
        "    self.conv2 = nn.Conv2d(16, 16, (22, 1), stride=1, padding=0)\n",
        "    self.conv3 = nn.Conv2d( 1, 16, (1, 75), stride=1, padding=0)\n",
        "    self.conv4 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
        "    self.conv5 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
        "    self.fc1 = nn.Linear(64 * 2 * 32, 120)\n",
        "    self.fc2 = nn.Linear(120, 80)\n",
        "    self.fc3 = nn.Linear(80, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = x.permute(0, 2, 1, 3)\n",
        "    x = F.max_pool2d(x, (1, 3), (1, 3))\n",
        "    x = F.max_pool2d(F.relu(self.conv3(x)), 2, 2)\n",
        "    x = F.max_pool2d(F.relu(self.conv4(x)), 2, 2)\n",
        "    x = F.max_pool2d(F.relu(self.conv5(x)), 2, 2)\n",
        "    x = x.view(-1, 64 * 2 * 32)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "naI1DnC3XpIS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN5\n",
        "\n",
        "CNN4 with BatchNorm and Dropout..."
      ]
    },
    {
      "metadata": {
        "id": "FMuRlWqmX202",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class CNN5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN5, self).__init__()\n",
        "    self.conv1 = nn.Conv2d( 1, 16, (1, 11), stride=1, padding=0)\n",
        "    self.bnc1 = nn.BatchNorm2d(16)\n",
        "    self.conv2 = nn.Conv2d(16, 16, (22, 1), stride=1, padding=0)\n",
        "    self.bnc2 = nn.BatchNorm2d(16)\n",
        "    self.conv3 = nn.Conv2d( 1, 16, (1, 75), stride=1, padding=0)\n",
        "    self.bnc3 = nn.BatchNorm2d(16)\n",
        "    self.conv4 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
        "    self.bnc4 = nn.BatchNorm2d(32)\n",
        "    self.conv5 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
        "    self.bnc5 = nn.BatchNorm2d(64)\n",
        "    self.fc1 = nn.Linear(64 * 2 * 32, 120)\n",
        "    self.bnf1 = nn.BatchNorm1d(120)\n",
        "    self.fc2 = nn.Linear(120, 80)\n",
        "    self.bnf2 = nn.BatchNorm1d(80)\n",
        "    self.fc3 = nn.Linear(80, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.dropout(self.bnc1(F.relu(self.conv1(x))), p=0.2)\n",
        "    x = F.dropout(self.bnc2(F.relu(self.conv2(x))))\n",
        "    x = x.permute(0, 2, 1, 3)\n",
        "    x = F.max_pool2d(x, (1, 3), (1, 3))\n",
        "    x = F.dropout(self.bnc3(F.relu(self.conv3(x))))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = F.dropout(self.bnc4(F.relu(self.conv4(x))))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = F.dropout(self.bnc5(F.relu(self.conv5(x))))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = x.view(-1, 64 * 2 * 32)\n",
        "    x = F.dropout(self.bnf1(F.relu(self.fc1(x))))\n",
        "    x = F.dropout(self.bnf2(F.relu(self.fc2(x))))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jboIGrdVeQ7Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN6\n",
        "\n",
        "CNN2 with BatchNorm and Dropout...\n",
        "\n",
        "BatchNorm is a disaster, dropping the validation accuracy to 0.34"
      ]
    },
    {
      "metadata": {
        "id": "KYzGkR4reUJL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class CNN6(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN6, self).__init__()\n",
        "    self.conv1 = nn.Conv2d( 1, 16, (1, 11), stride=(1, 1), padding=0)\n",
        "    self.bnc1 = nn.BatchNorm2d(16)\n",
        "    self.conv2 = nn.Conv2d(16, 16, (22, 1), stride=(1, 1), padding=0)\n",
        "    self.bnc2 = nn.BatchNorm2d(16)\n",
        "    self.conv3 = nn.Conv2d( 1, 16, (1, 11), stride=(1, 1), padding=0)\n",
        "    self.bnc3 = nn.BatchNorm2d(16)\n",
        "    self.conv4 = nn.Conv2d(16, 16, (16, 1), stride=(1, 1), padding=0)\n",
        "    self.bnc4 = nn.BatchNorm2d(16)\n",
        "    self.conv5 = nn.Conv2d( 1, 16, 3, stride=1, padding=1)\n",
        "    self.bnc5 = nn.BatchNorm2d(16)\n",
        "    self.conv6 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
        "    self.bnc6 = nn.BatchNorm2d(32)\n",
        "    self.conv7 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
        "    self.bnc7 = nn.BatchNorm2d(64)\n",
        "    self.fc1 = nn.Linear(64 * 2 * 10, 200)\n",
        "    self.bnf1 = nn.BatchNorm1d(200)\n",
        "    self.fc2 = nn.Linear(200, 100)\n",
        "    self.bnf2 = nn.BatchNorm1d(100)\n",
        "    self.fc3 = nn.Linear(100, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.dropout(self.bnc1(F.relu(self.conv1(x))), p=0.2)\n",
        "    x = F.dropout(self.bnc2(F.relu(self.conv2(x))))\n",
        "    x = x.permute(0, 2, 1, 3)\n",
        "    x = F.max_pool2d(x, (1, 3), (1, 3))\n",
        "    x = F.dropout(self.bnc3(F.relu(self.conv3(x))))\n",
        "    x = F.dropout(self.bnc4(F.relu(self.conv4(x))))\n",
        "    x = x.permute(0, 2, 1, 3)\n",
        "    x = F.max_pool2d(x, (1, 4), (1, 4))\n",
        "    x = F.dropout(self.bnc5(F.relu(self.conv5(x))))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = F.dropout(self.bnc6(F.relu(self.conv6(x))))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = F.dropout(self.bnc7(F.relu(self.conv7(x))))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = x.view(-1, 64 * 2 * 10)\n",
        "    x = F.dropout(self.bnf1(F.relu(self.fc1(x))))\n",
        "    x = F.dropout(self.bnf2(F.relu(self.fc2(x))))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iyL4m-XUgqpq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN7 (CNN4)\n",
        "\n",
        "CNN2 with only Dropout? Best validation accuracy: 0.50"
      ]
    },
    {
      "metadata": {
        "id": "q-dStTU5gXv9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class CNN7(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN7, self).__init__()\n",
        "    self.conv1 = nn.Conv2d( 1, 16, (1, 11), stride=(1, 1), padding=0)\n",
        "    self.conv2 = nn.Conv2d(16, 16, (22, 1), stride=(1, 1), padding=0)\n",
        "    self.conv3 = nn.Conv2d( 1, 16, (1, 11), stride=(1, 1), padding=0)\n",
        "    self.conv4 = nn.Conv2d(16, 16, (16, 1), stride=(1, 1), padding=0)\n",
        "    self.conv5 = nn.Conv2d( 1, 16, 3, stride=1, padding=1)\n",
        "    self.conv6 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
        "    self.conv7 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
        "    self.fc1 = nn.Linear(64 * 2 * 10, 200)\n",
        "    self.fc2 = nn.Linear(200, 100)\n",
        "    self.fc3 = nn.Linear(100, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    dropval = 0.7\n",
        "    x = F.dropout2d(F.relu(self.conv1(x)), p=0.2)\n",
        "    x = F.dropout2d(F.relu(self.conv2(x)), p=dropval)\n",
        "    x = x.permute(0, 2, 1, 3)\n",
        "    x = F.max_pool2d(x, (1, 3), (1, 3))\n",
        "    x = F.dropout2d(F.relu(self.conv3(x)), p=dropval)\n",
        "    x = F.dropout2d(F.relu(self.conv4(x)), p=dropval)\n",
        "    x = x.permute(0, 2, 1, 3)\n",
        "    x = F.max_pool2d(x, (1, 4), (1, 4))\n",
        "    x = F.dropout2d(F.relu(self.conv5(x)), p=dropval)\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = F.dropout2d(F.relu(self.conv6(x)), p=dropval)\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = F.dropout2d(F.relu(self.conv7(x)), p=dropval)\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = x.view(-1, 64 * 2 * 10)\n",
        "    x = F.dropout(F.relu(self.fc1(x)), p=dropval)\n",
        "    x = F.dropout(F.relu(self.fc2(x)), p=dropval)\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ra-LrmnbtSa0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN8 (CNN5)\n",
        "\n",
        "Brand new CNN. Attempts to use the average pool. Similar validation accuracy: 0.48."
      ]
    },
    {
      "metadata": {
        "id": "OHUhSieLtU42",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class CNN8(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN8, self).__init__()\n",
        "    self.conv1 = nn.Conv2d( 1, 20, ( 1, 8))\n",
        "    self.conv2 = nn.Conv2d(20, 20, (22, 1))\n",
        "    self.conv3 = nn.Conv2d( 1,  8, ( 1, 4))\n",
        "    self.conv4 = nn.Conv2d( 8, 16, 3, padding=1)\n",
        "    self.conv5 = nn.Conv2d(16, 32, 5, padding=2)\n",
        "    self.conv6 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "    self.conv7 = nn.Conv2d(32, 64, 5, padding=2)\n",
        "    self.conv8 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "    self.fc1 = nn.Linear(64 * 5 * 41, 200)\n",
        "    self.fc2 = nn.Linear(200, 100)\n",
        "    self.fc3 = nn.Linear(100, 100)\n",
        "    self.fc4 = nn.Linear(100, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    dropval = 0.75\n",
        "    x = F.dropout2d(F.relu(self.conv1(x)), p=0.2)\n",
        "    x = F.dropout2d(F.relu(self.conv2(x)), p=dropval)\n",
        "    x = x.permute(0, 2, 1, 3)\n",
        "    x = F.avg_pool2d(x, (1, 3), (1, 3))\n",
        "    x = F.dropout2d(F.relu(self.conv3(x)), p=dropval)\n",
        "    x = F.dropout2d(F.relu(self.conv4(x)), p=dropval)\n",
        "    x = F.avg_pool2d(x, (1, 2), (1, 2))\n",
        "    x = F.dropout2d(F.relu(self.conv5(x)), p=dropval)\n",
        "    x = F.dropout2d(F.relu(self.conv6(x)), p=dropval)\n",
        "    x = F.avg_pool2d(x, 2, 2)\n",
        "    x = F.dropout2d(F.relu(self.conv7(x)), p=dropval)\n",
        "    x = F.dropout2d(F.relu(self.conv8(x)), p=dropval)\n",
        "    x = F.avg_pool2d(x, 2, 2)\n",
        "    x = x.view(-1, 64 * 5 * 41)\n",
        "    x = F.dropout(F.relu(self.fc1(x)), p=dropval)\n",
        "    x = F.dropout(F.relu(self.fc2(x)), p=dropval)\n",
        "    x = F.dropout(F.relu(self.fc3(x)), p=dropval)\n",
        "    x = self.fc4(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ndrqpYoTIL2d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN9 (CNN6)\n",
        "\n",
        "Introduces a feature called \"Sprinkle Shuffle\", a method similar to the Google Inception method. \n",
        "\n",
        "Ideas: \"Nerf\" the depth of the network. "
      ]
    },
    {
      "metadata": {
        "id": "mrCxGbotJvo3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# N x 1 x 22 x 1000\n",
        "\n",
        "class CNN9(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN9, self).__init__()\n",
        "    self.sprinkle1 = nn.Conv2d(1,  7, ( 1, 75), padding=(0, 37))\n",
        "    self.sprinkle2 = nn.Conv2d(1,  7, ( 1, 43), padding=(0, 21))\n",
        "    self.sprinkle3 = nn.Conv2d(1,  7, ( 1, 25), padding=(0, 12))\n",
        "    self.sprinkle4 = nn.Conv2d(1,  7, ( 1, 11), padding=(0,  5))\n",
        "    self.sprinkle5 = nn.Conv2d(1, 22, (22,  1))\n",
        "    self.sprinkle6 = nn.Conv2d(1, 22, (22,  5), padding=(0,  2))\n",
        "    self.sprinkle7 = nn.Conv2d(1, 22, (22,  9), padding=(0,  4))\n",
        "    self.sprinkle8 = nn.Conv2d(1, 22, (22, 11), padding=(0,  5))\n",
        "    self.inception1_1 = nn.Conv2d(32, 8, 1, padding=0)\n",
        "    self.inception1_3 = nn.Conv2d( 8, 8, 3, padding=1)\n",
        "    self.inception1_5 = nn.Conv2d( 8, 8, 5, padding=2)\n",
        "    self.reduce1 = nn.Conv2d(32, 32, (5, 4), stride=(1, 2), padding=(0, 1))\n",
        "    self.conv1 = nn.Conv2d( 32,  64, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d( 64,  64, 3, padding=1)\n",
        "    self.conv3 = nn.Conv2d( 64, 128, 3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "    self.fc = nn.Linear(128 * 10 * 125, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    dropval = 0.5\n",
        "    xold = x\n",
        "    # Collect all the sprinkles\n",
        "    s1 = F.relu(self.sprinkle1(x))\n",
        "    s2 = F.relu(self.sprinkle2(x))\n",
        "    s3 = F.relu(self.sprinkle3(x))\n",
        "    s4 = F.relu(self.sprinkle4(x))\n",
        "    s5 = (F.relu(self.sprinkle5(x))).permute(0, 2, 1, 3)\n",
        "    s6 = (F.relu(self.sprinkle6(x))).permute(0, 2, 1, 3)\n",
        "    s7 = (F.relu(self.sprinkle7(x))).permute(0, 2, 1, 3)\n",
        "    s8 = (F.relu(self.sprinkle8(x))).permute(0, 2, 1, 3)\n",
        "    # Concatenate the sprinkles together\n",
        "    xp = torch.cat((s1, s2, s3, s4, s5, s6, s7, s8), 1)\n",
        "    # Create a \"new\" x\n",
        "    x = -x[:, :, np.random.permutation(22), :]\n",
        "    s1 = F.relu(self.sprinkle1(x))\n",
        "    s2 = F.relu(self.sprinkle2(x))\n",
        "    s3 = F.relu(self.sprinkle3(x))\n",
        "    s4 = F.relu(self.sprinkle4(x))\n",
        "    s5 = (F.relu(self.sprinkle5(x))).permute(0, 2, 1, 3)\n",
        "    s6 = (F.relu(self.sprinkle6(x))).permute(0, 2, 1, 3)\n",
        "    s7 = (F.relu(self.sprinkle7(x))).permute(0, 2, 1, 3)\n",
        "    s8 = (F.relu(self.sprinkle8(x))).permute(0, 2, 1, 3)\n",
        "    # Concatenate the sprinkles together\n",
        "    xn = torch.cat((s1, s2, s3, s4, s5, s6, s7, s8), 1)\n",
        "    x = torch.cat((xp + xold, xn + xold), 2) # Residual?\n",
        "    x = F.dropout2d(x, p=0.2)\n",
        "    xold = x\n",
        "    # Inception Round 1\n",
        "    i_temp = self.inception1_1(x)\n",
        "    i1 = F.relu(i_temp)\n",
        "    i2 = F.relu(self.inception1_3(i_temp))\n",
        "    i3 = F.relu(self.inception1_5(i_temp))\n",
        "    i4 = self.inception1_1(F.max_pool2d(x, 3, stride=1, padding=1))\n",
        "    x = torch.cat((i1, i2, i3, i4), 1) + xold\n",
        "    x = F.dropout2d(x, p=dropval)\n",
        "    # Reduce Dimensions\n",
        "    x = F.relu(self.reduce1(x))\n",
        "    x = F.dropout(x, p=dropval)\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = F.dropout(x, p=dropval)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = F.dropout(x, p=dropval)\n",
        "    x = x.view(-1, 128 * 10 * 125)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cazF-KMmGb3b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN10"
      ]
    },
    {
      "metadata": {
        "id": "a5ZBZXTVGcMb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# N x 1 x 22 x 250\n",
        "\n",
        "class CNN10(nn.Module):\n",
        "  def __init__(self, time_batch=400):\n",
        "    super(CNN10, self).__init__()\n",
        "    self.sprinkle1 = nn.Conv2d(1,  7, ( 1, 75), padding=(0, 37))\n",
        "    self.sprinkle2 = nn.Conv2d(1,  7, ( 1, 43), padding=(0, 21))\n",
        "    self.sprinkle3 = nn.Conv2d(1,  7, ( 1, 25), padding=(0, 12))\n",
        "    self.sprinkle4 = nn.Conv2d(1,  7, ( 1, 11), padding=(0,  5))\n",
        "    self.sprinkle5 = nn.Conv2d(1, 22, (22,  1))\n",
        "    self.sprinkle6 = nn.Conv2d(1, 22, (22,  5), padding=(0,  2))\n",
        "    self.sprinkle7 = nn.Conv2d(1, 22, (22,  9), padding=(0,  4))\n",
        "    self.sprinkle8 = nn.Conv2d(1, 22, (22, 11), padding=(0,  5))\n",
        "    self.inception1_1 = nn.Conv2d(32, 8, 1, padding=0)\n",
        "    self.inception1_3 = nn.Conv2d( 8, 8, 3, padding=1)\n",
        "    self.inception1_5 = nn.Conv2d( 8, 8, 5, padding=2)\n",
        "    self.inception2_1 = nn.Conv2d(32, 4, 1, padding=0)\n",
        "    self.inception2_3 = nn.Conv2d( 4, 4, 3, padding=1)\n",
        "    self.inception2_5 = nn.Conv2d( 4, 4, 5, padding=2)\n",
        "    self.conv1 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "    if   time_batch == 250:\n",
        "      self.fc = nn.Linear(64 * 11 * 31, 4) # For T=250\n",
        "    elif time_batch == 400:\n",
        "      self.fc = nn.Linear(64 * 11 * 49, 4) # For T=400\n",
        "  \n",
        "  def forward(self, x):\n",
        "    time_batch = x.size(3)\n",
        "    dropval = 0.5\n",
        "    xold = x\n",
        "    # Collect all the sprinkles\n",
        "    s1 = F.relu(self.sprinkle1(x))\n",
        "    s2 = F.relu(self.sprinkle2(x))\n",
        "    s3 = F.relu(self.sprinkle3(x))\n",
        "    s4 = F.relu(self.sprinkle4(x))\n",
        "    s5 = (F.relu(self.sprinkle5(x))).permute(0, 2, 1, 3)\n",
        "    s6 = (F.relu(self.sprinkle6(x))).permute(0, 2, 1, 3)\n",
        "    s7 = (F.relu(self.sprinkle7(x))).permute(0, 2, 1, 3)\n",
        "    s8 = (F.relu(self.sprinkle8(x))).permute(0, 2, 1, 3)\n",
        "    # Concatenate the sprinkles together\n",
        "    xp = torch.cat((s1, s2, s3, s4, s5, s6, s7, s8), 1)\n",
        "    # Create a \"new\" x\n",
        "    x = -x[:, :, np.random.permutation(22), :]\n",
        "    s1 = F.relu(self.sprinkle1(x))\n",
        "    s2 = F.relu(self.sprinkle2(x))\n",
        "    s3 = F.relu(self.sprinkle3(x))\n",
        "    s4 = F.relu(self.sprinkle4(x))\n",
        "    s5 = (F.relu(self.sprinkle5(x))).permute(0, 2, 1, 3)\n",
        "    s6 = (F.relu(self.sprinkle6(x))).permute(0, 2, 1, 3)\n",
        "    s7 = (F.relu(self.sprinkle7(x))).permute(0, 2, 1, 3)\n",
        "    s8 = (F.relu(self.sprinkle8(x))).permute(0, 2, 1, 3)\n",
        "    # Concatenate the sprinkles together\n",
        "    xn = torch.cat((s1, s2, s3, s4, s5, s6, s7, s8), 1)\n",
        "    x = torch.cat((xp + xold, xn + xold), 2) # Residual?\n",
        "    x = F.dropout2d(x, p=0.2)\n",
        "    xold = x\n",
        "    # Inception Round 1\n",
        "    i_temp = self.inception1_1(x)\n",
        "    i1 = F.relu(i_temp)\n",
        "    i2 = F.relu(self.inception1_3(i_temp))\n",
        "    i3 = F.relu(self.inception1_5(i_temp))\n",
        "    i4 = self.inception1_1(F.max_pool2d(x, 3, stride=1, padding=1))\n",
        "    x = torch.cat((i1, i2, i3, i4), 1) + xold\n",
        "    x = F.dropout2d(x, p=dropval)\n",
        "    xold = x\n",
        "    # Inception Round 2\n",
        "    i_temp = self.inception2_1(x)\n",
        "    i1 = F.relu(i_temp)\n",
        "    i2 = F.relu(self.inception2_3(i_temp))\n",
        "    i3 = F.relu(self.inception2_5(i_temp))\n",
        "    i4 = self.inception2_1(F.max_pool2d(x, 3, stride=1, padding=1))\n",
        "    x = torch.cat((i1, i2, i3, i4), 1)\n",
        "    x = F.dropout2d(x, p=dropval)\n",
        "    # Reduce dimensions\n",
        "    if   time_batch == 250:\n",
        "      x = F.max_pool2d(x, (1, 4), stride=(1, 2))  # For T=250\n",
        "    elif time_batch == 400:\n",
        "      x = F.max_pool2d(x, (1, 10), stride=(1, 2)) # For T=400\n",
        "    x = F.dropout(x, p=dropval)\n",
        "    # Run through a standard neural net\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = F.dropout(x, p=dropval)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = F.dropout(x, p=dropval)\n",
        "    if   time_batch == 250:\n",
        "      x = x.view(-1, 64 * 11 * 31) # For T=250\n",
        "    elif time_batch == 400:\n",
        "      x = x.view(-1, 64 * 11 * 49) # For T=400\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CUQrG0-PlEnh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN11\n",
        "\n",
        "Shallow ConvNet for raw EEG signals (Schirrmeister)\n",
        "\n",
        "Testing Accuracy: [0.56 0.38 0.72 0.62 0.38 0.48 0.54 0.68 0.7 ]\n",
        "\n",
        "Testing Accuracy Average: 0.56222\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "Ran for 200 epochs"
      ]
    },
    {
      "metadata": {
        "id": "Nf7kEdb8lKpO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# N x 1 x 22 x 534\n",
        "class CNN11(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN11, self).__init__()\n",
        "    self.conv1 = nn.Conv2d( 1, 40, (1, 25))\n",
        "    #nn.init.xavier_uniform(self.conv1.weight)\n",
        "    self.bnc1 = nn.BatchNorm2d(40)\n",
        "    self.conv2 = nn.Conv2d(40, 40, (22, 1))\n",
        "    #nn.init.xavier_uniform(self.conv2.weight)\n",
        "    self.bnc2 = nn.BatchNorm2d(40)\n",
        "    self.fc = nn.Linear(30 * 40, 4)\n",
        "    #nn.init.xavier_uniform(self.fc.weight)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.elu(self.bnc1(self.conv1(x)))\n",
        "    x = F.elu(self.bnc2(self.conv2(x)))\n",
        "    x = F.dropout2d(x, p=0.5)\n",
        "    x = F.max_pool2d(x.permute(0, 2, 1, 3), (1, 75), stride=(1, 15))\n",
        "    x = x.view(-1, 30 * 40)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "irM2tZhLSEuY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN12\n",
        "\n",
        "Deep ConvNet for raw EEG signals (Schirrmeister)\n",
        "\n",
        "Validation Accuracy: 0.56444\n",
        "\n",
        "learning_rate = 1e-4"
      ]
    },
    {
      "metadata": {
        "id": "6-9BAUNaSO5v",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# N x 1 x 22 x 522\n",
        "class CNN12(nn.Module):\n",
        "  def __init__(self, time_batch=400):\n",
        "    super(CNN12, self).__init__()\n",
        "    self.conv1 = nn.Conv2d( 1,  25, (  1, 10))\n",
        "    self.bnc1 = nn.BatchNorm2d(25)\n",
        "    self.conv2 = nn.Conv2d(25,  25, ( 22,  1))\n",
        "    self.bnc2 = nn.BatchNorm2d(25)\n",
        "    self.conv3 = nn.Conv2d( 1,  50, ( 25, 10))\n",
        "    self.bnc3 = nn.BatchNorm2d(50)\n",
        "    self.conv4 = nn.Conv2d( 1, 100, ( 50, 10))\n",
        "    self.bnc4 = nn.BatchNorm2d(100)\n",
        "    self.conv5 = nn.Conv2d( 1, 200, (100, 10))\n",
        "    self.bnc5 = nn.BatchNorm2d(200)\n",
        "    self.fc = nn.Linear(200 * 2, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.elu(self.bnc1(self.conv1(x)))\n",
        "    x = F.elu(self.bnc2(self.conv2(x)))\n",
        "    x = F.dropout2d(x, p=0.5)\n",
        "    x = F.max_pool2d(x.permute(0, 2, 1, 3), (1, 3))\n",
        "    x = F.elu(self.bnc3(self.conv3(x)))\n",
        "    x = F.dropout2d(x, p=0.5)\n",
        "    x = F.max_pool2d(x.permute(0, 2, 1, 3), (1, 3))\n",
        "    x = F.elu(self.bnc4(self.conv4(x)))\n",
        "    x = F.dropout2d(x, p=0.5)\n",
        "    x = F.max_pool2d(x.permute(0, 2, 1, 3), (1, 3))\n",
        "    x = F.elu(self.bnc5(self.conv5(x)))\n",
        "    x = F.dropout2d(x, p=0.5)\n",
        "    x = F.max_pool2d(x.permute(0, 2, 1, 3), (1, 3))\n",
        "    x = x.view(-1, 200 * 2)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0AMb7ZxOFuV_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN13\n",
        "\n",
        "EEGNet\n",
        "\n",
        "Validation Accuracy: 0.56000 but varies a lot\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "zzHLmJlyFwCe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# N x 1 x 22 x 512\n",
        "class CNN13(nn.Module):\n",
        "  def __init__(self, time_batch=400):\n",
        "    super(CNN13, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 16, (22,  1))\n",
        "    self.bnc1 = nn.BatchNorm2d(16)\n",
        "    self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
        "    self.conv2 = nn.Conv2d(1,  4, ( 2, 32))\n",
        "    self.bnc2 = nn.BatchNorm2d(4)\n",
        "    self.padding2 = nn.ZeroPad2d(( 2,  1, 4, 3))\n",
        "    self.conv3 = nn.Conv2d(4,  4, ( 8,  4))\n",
        "    self.bnc3 = nn.BatchNorm2d(4)\n",
        "    self.fc = nn.Linear(4 * 4 * 32, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.elu(self.conv1(x))\n",
        "    x = self.bnc1(x)\n",
        "    x = F.dropout(x, p=0.25)\n",
        "    x = x.permute(0, 2, 1, 3)\n",
        "    x = self.padding1(x)\n",
        "    x = F.elu(self.conv2(x))\n",
        "    x = self.bnc2(x)\n",
        "    x = F.dropout(x, p=0.25)\n",
        "    x = F.max_pool2d(x, (2, 4))\n",
        "    x = self.padding2(x)\n",
        "    x = F.elu(self.conv3(x))\n",
        "    x = self.bnc2(x)\n",
        "    x = F.dropout(x, p=0.25)\n",
        "    x = F.max_pool2d(x, (2, 4))\n",
        "    x = x.view(-1, 4 * 4 * 32)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qwRCHmhJYTCn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN14\n",
        "\n",
        "CNN11 with Google Inception Input\n",
        "\n",
        "Testing Accuracy: [0.64 0.46 0.64 0.44 0.42 0.52 0.58 0.62 0.68]\n",
        "\n",
        "Testing Accuracy Average: 0.55556"
      ]
    },
    {
      "metadata": {
        "id": "Lv77otriYYWX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# N x 1 x 22 x 510\n",
        "class CNN14(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN14, self).__init__()\n",
        "    self.conv1_1 = nn.Conv2d(1, 10, ( 1, 75), padding=(0, 37))\n",
        "    self.conv1_2 = nn.Conv2d(1, 10, ( 1, 43), padding=(0, 21))\n",
        "    self.conv1_3 = nn.Conv2d(1, 10, ( 1, 25), padding=(0, 12))\n",
        "    self.conv1_4 = nn.Conv2d(1, 10, ( 1, 11), padding=(0,  5))\n",
        "    self.bnc1 = nn.BatchNorm2d(40)\n",
        "    self.conv2 = nn.Conv2d(40, 40, (22, 1))\n",
        "    self.bnc2 = nn.BatchNorm2d(40)\n",
        "    self.fc = nn.Linear(30 * 40, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    xold = x\n",
        "    c1 = self.conv1_1(x)\n",
        "    c2 = self.conv1_2(x)\n",
        "    c3 = self.conv1_3(x)\n",
        "    c4 = self.conv1_4(x)\n",
        "    x = torch.cat((c1, c2, c3, c4), 1)\n",
        "    x = self.bnc1(F.elu(x))\n",
        "    x = F.elu(self.bnc2(self.conv2(x)))\n",
        "    x = F.dropout2d(x, p=0.5)\n",
        "    x = F.max_pool2d(x.permute(0, 2, 1, 3), (1, 75), stride=(1, 15))\n",
        "    x = x.view(-1, 30 * 40)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cqYvHLC8tDwT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN15\n",
        "\n",
        "CNN12 with Google Inception Input"
      ]
    },
    {
      "metadata": {
        "id": "vt3OCld3tCvH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# N x 1 x 22 x 513\n",
        "class CNN15(nn.Module):\n",
        "  def __init__(self, time_batch=400):\n",
        "    super(CNN15, self).__init__()\n",
        "    self.conv1_1 = nn.Conv2d(1,  6, ( 1, 75), padding=(0, 37))\n",
        "    self.conv1_2 = nn.Conv2d(1,  6, ( 1, 43), padding=(0, 21))\n",
        "    self.conv1_3 = nn.Conv2d(1,  6, ( 1, 25), padding=(0, 12))\n",
        "    self.conv1_4 = nn.Conv2d(1,  6, ( 1, 11), padding=(0,  5))\n",
        "    self.bnc1 = nn.BatchNorm2d(24)\n",
        "    self.conv2 = nn.Conv2d(24,  25, ( 22,  1))\n",
        "    self.bnc2 = nn.BatchNorm2d(25)\n",
        "    self.conv3 = nn.Conv2d( 1,  50, ( 25, 10))\n",
        "    self.bnc3 = nn.BatchNorm2d(50)\n",
        "    self.conv4 = nn.Conv2d( 1, 100, ( 50, 10))\n",
        "    self.bnc4 = nn.BatchNorm2d(100)\n",
        "    self.conv5 = nn.Conv2d( 1, 200, (100, 10))\n",
        "    self.bnc5 = nn.BatchNorm2d(200)\n",
        "    self.fc = nn.Linear(200 * 2, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    c1 = self.conv1_1(x)\n",
        "    c2 = self.conv1_2(x)\n",
        "    c3 = self.conv1_3(x)\n",
        "    c4 = self.conv1_4(x)\n",
        "    x = torch.cat((c1, c2, c3, c4), 1)\n",
        "    x = self.bnc1(F.elu(x))\n",
        "    x = F.elu(self.bnc2(self.conv2(x)))\n",
        "    x = F.dropout2d(x, p=0.5)\n",
        "    x = F.max_pool2d(x.permute(0, 2, 1, 3), (1, 3))\n",
        "    x = F.elu(self.bnc3(self.conv3(x)))\n",
        "    x = F.dropout2d(x, p=0.5)\n",
        "    x = F.max_pool2d(x.permute(0, 2, 1, 3), (1, 3))\n",
        "    x = F.elu(self.bnc4(self.conv4(x)))\n",
        "    x = F.dropout2d(x, p=0.5)\n",
        "    x = F.max_pool2d(x.permute(0, 2, 1, 3), (1, 3))\n",
        "    x = F.elu(self.bnc5(self.conv5(x)))\n",
        "    x = F.dropout2d(x, p=0.5)\n",
        "    x = F.max_pool2d(x.permute(0, 2, 1, 3), (1, 3))\n",
        "    x = x.view(-1, 200 * 2)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dxiFDoBDuoTX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####CNN16\n",
        "\n",
        "CNN13 with Google Inception Input\n",
        "\n",
        "Negligible result"
      ]
    },
    {
      "metadata": {
        "id": "x9aM3oav-w6b",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# N x 1 x 22 x 512\n",
        "class CNN16(nn.Module):\n",
        "  def __init__(self, time_batch=400):\n",
        "    super(CNN16, self).__init__()\n",
        "    self.conv1_1 = nn.Conv2d(1, 4, (22,  1))\n",
        "    self.conv1_2 = nn.Conv2d(1, 4, (22,  5), padding=(0,  2))\n",
        "    self.conv1_3 = nn.Conv2d(1, 4, (22, 11), padding=(0,  5))\n",
        "    self.conv1_4 = nn.Conv2d(1, 4, (22, 25), padding=(0, 12))\n",
        "    self.bnc1 = nn.BatchNorm2d(16)\n",
        "    self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
        "    self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
        "    self.bnc2 = nn.BatchNorm2d(4)\n",
        "    self.padding2 = nn.ZeroPad2d(( 2,  1, 4, 3))\n",
        "    self.conv3 = nn.Conv2d(4, 4, (8,  4))\n",
        "    self.bnc3 = nn.BatchNorm2d(4)\n",
        "    self.fc = nn.Linear(4 * 4 * 32, 4)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    c1 = self.conv1_1(x)\n",
        "    c2 = self.conv1_2(x)\n",
        "    c3 = self.conv1_3(x)\n",
        "    c4 = self.conv1_4(x)\n",
        "    x = torch.cat((c1, c2, c3, c4), 1)\n",
        "    x = self.bnc1(F.elu(x))\n",
        "    x = F.dropout(x, p=0.25)\n",
        "    x = x.permute(0, 2, 1, 3)\n",
        "    x = self.padding1(x)\n",
        "    x = F.elu(self.conv2(x))\n",
        "    x = self.bnc2(x)\n",
        "    x = F.dropout(x, p=0.25)\n",
        "    x = F.max_pool2d(x, (2, 4))\n",
        "    x = self.padding2(x)\n",
        "    x = F.elu(self.conv3(x))\n",
        "    x = self.bnc2(x)\n",
        "    x = F.dropout(x, p=0.25)\n",
        "    x = F.max_pool2d(x, (2, 4))\n",
        "    x = x.view(-1, 4 * 4 * 32)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bF93DV3g4nKf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ]
    },
    {
      "metadata": {
        "id": "ZtX31_wU67Iu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data_dir = 'drive/ee239as/project_datasets'\n",
        "#batch_size = 31\n",
        "batch_size = 17\n",
        "#batch_size = 4\n",
        "time_batch = 513"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSyYi0jr5jMk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "5deb66f1-afc7-4b28-a65f-771e17eba490",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1520960921275,
          "user_tz": 420,
          "elapsed": 7147,
          "user": {
            "displayName": "Nathan Wong",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106327691903472177650"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "EEGset = EEGMinimalContainer(data_dir)\n",
        "#EEGset = EEGCroppedContainer(data_dir, time_batch)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(EEGset.train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = {}\n",
        "for i in range(1, 10):\n",
        "  test_loader[str(i)] = torch.utils.data.DataLoader(EEGset.test_dataset[str(i)],\n",
        "                                                    batch_size=1,\n",
        "                                                    shuffle=False)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EEGContainer X_train: (2108, 1, 22, 1000)\n",
            "EEGContainer y_train: (2108,)\n",
            "EEGContainer X_test1: (50, 1, 22, 1000)\n",
            "EEGContainer y_test1: (50,)\n",
            "EEGContainer X_test2: (50, 1, 22, 1000)\n",
            "EEGContainer y_test2: (50,)\n",
            "EEGContainer X_test3: (50, 1, 22, 1000)\n",
            "EEGContainer y_test3: (50,)\n",
            "EEGContainer X_test4: (50, 1, 22, 1000)\n",
            "EEGContainer y_test4: (50,)\n",
            "EEGContainer X_test5: (50, 1, 22, 1000)\n",
            "EEGContainer y_test5: (50,)\n",
            "EEGContainer X_test6: (50, 1, 22, 1000)\n",
            "EEGContainer y_test6: (50,)\n",
            "EEGContainer X_test7: (50, 1, 22, 1000)\n",
            "EEGContainer y_test7: (50,)\n",
            "EEGContainer X_test8: (50, 1, 22, 1000)\n",
            "EEGContainer y_test8: (50,)\n",
            "EEGContainer X_test9: (50, 1, 22, 1000)\n",
            "EEGContainer y_test9: (50,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4DQOGwwWo0TB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 200\n",
        "learning_rate = 1e-4\n",
        "\n",
        "use_cuda = True\n",
        "\n",
        "net = CNN15()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "ss = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FdodrAOa6CyS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "if use_cuda and torch.cuda.is_available():\n",
        "  net.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=ss, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dD4O5-LV7p-M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Training"
      ]
    },
    {
      "metadata": {
        "id": "kvJ0BZmwPM6X",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "training_acc_arr = np.empty(num_epochs)\n",
        "testing_acc_arr = np.empty((9, num_epochs))\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  \n",
        "  net.train()\n",
        "  \n",
        "  #scheduler.step()\n",
        "  \n",
        "  total = 0\n",
        "  correct = 0\n",
        "  \n",
        "  for i, (signals, labels) in enumerate(train_loader):\n",
        "    \n",
        "    signals = signals.type(torch.FloatTensor)\n",
        "    signals = Variable(signals)\n",
        "    labels = labels.type(torch.LongTensor)\n",
        "    labels_check = torch.squeeze(labels)\n",
        "    labels = Variable(torch.squeeze(labels))\n",
        "    loc = np.random.choice(1000-time_batch, 4, replace=False)\n",
        "    s0 = signals[:, :, :, loc[0]:(loc[0]+time_batch)]\n",
        "    s1 = signals[:, :, :, loc[1]:(loc[1]+time_batch)]\n",
        "    s2 = signals[:, :, :, loc[2]:(loc[2]+time_batch)]\n",
        "    s3 = signals[:, :, :, loc[3]:(loc[3]+time_batch)]\n",
        "    signals = torch.cat((s0, s1, s2, s3), 0)\n",
        "    labels_more = torch.cat([labels] * 4)\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "      signals = signals.cuda()\n",
        "      labels_more = labels_more.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(signals)\n",
        "    loss = criterion(outputs, labels_more)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    predicted = predicted.cpu()\n",
        "    predicted = predicted.view(-1, 4).numpy()\n",
        "    predicted, _ = stats.mode(predicted, axis=1)\n",
        "    predicted = np.squeeze(predicted)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels_check.numpy()).sum()\n",
        "    \n",
        "    if (i+1) % 31 == 0:\n",
        "      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Learning Rate: %.3e' \n",
        "            % (epoch+1, num_epochs, i+1, len(EEGset.train_dataset)//batch_size, \n",
        "               loss.data[0], scheduler.get_lr()[0]))\n",
        "  \n",
        "  # Training accuracy\n",
        "  training_acc_arr[epoch] = (correct/total)\n",
        "  print ('Training Accuracy: %.5f' % training_acc_arr[epoch])\n",
        "  \n",
        "  net.eval()\n",
        "  \n",
        "  # Testing accuracy\n",
        "  for subject in range(9):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for signals, labels in test_loader[str(subject+1)]:\n",
        "      signals = signals.type(torch.FloatTensor)\n",
        "      signals = Variable(signals)\n",
        "      labels = labels.type(torch.LongTensor)\n",
        "      labels_check = torch.squeeze(labels)\n",
        "      labels = Variable(torch.squeeze(labels))\n",
        "      loc = np.random.choice(1000-time_batch, 4, replace=False)\n",
        "      s0 = signals[:, :, :, loc[0]:(loc[0]+time_batch)]\n",
        "      s1 = signals[:, :, :, loc[1]:(loc[1]+time_batch)]\n",
        "      s2 = signals[:, :, :, loc[2]:(loc[2]+time_batch)]\n",
        "      s3 = signals[:, :, :, loc[3]:(loc[3]+time_batch)]\n",
        "      signals = torch.cat((s0, s1, s2, s3), 0)\n",
        "      labels_more = torch.cat([labels] * 4)\n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "        signals = signals.cuda()\n",
        "        labels_more = labels_more.cuda()\n",
        "      outputs = net(signals)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      predicted = predicted.cpu()\n",
        "      predicted = predicted.view(-1, 4).numpy()\n",
        "      predicted, _ = stats.mode(predicted, axis=1)\n",
        "      predicted = np.squeeze(predicted)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels_check.numpy()).sum()\n",
        "    testing_acc_arr[subject, epoch] = (correct/total)\n",
        "  print ('Testing Accuracy: ' + str(testing_acc_arr[:, epoch]))\n",
        "  print ('Testing Accuracy Average: %.5f' % np.average(testing_acc_arr[:, epoch]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_EVgnxX7rEa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "loss_arr = []\n",
        "training_acc_arr = np.empty(num_epochs)\n",
        "testing_acc_arr = np.empty((9, num_epochs))\n",
        "\n",
        "j = 0\n",
        "for epoch in range(num_epochs):\n",
        "  \n",
        "  net.train()\n",
        "  \n",
        "  #scheduler.step()\n",
        "  \n",
        "  for i, (signals, labels) in enumerate(train_loader):\n",
        "    \n",
        "    signals = signals.type(torch.FloatTensor)\n",
        "    signals = Variable(signals)\n",
        "    labels = labels.type(torch.LongTensor)\n",
        "    labels = Variable(torch.squeeze(labels))\n",
        "    \n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "      signals = signals.cuda()\n",
        "      labels = labels.cuda()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(signals)\n",
        "    \n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    #loss_arr[j] = loss.data[0]\n",
        "    #j += 1\n",
        "    \n",
        "    if (i+1) % 31 == 0:\n",
        "      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Learning Rate: %.3e' \n",
        "            % (epoch+1, num_epochs, i+1, len(EEGset.train_dataset)//batch_size, \n",
        "               loss.data[0], scheduler.get_lr()[0]))\n",
        "  \n",
        "  net.eval()\n",
        "  \n",
        "  # Training accuracy\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  for signals, labels in train_loader:\n",
        "    signals = signals.type(torch.FloatTensor)\n",
        "    signals = Variable(signals)\n",
        "    labels = torch.squeeze(labels.type(torch.LongTensor))\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "      signals = signals.cuda()\n",
        "      labels = labels.cuda()\n",
        "    outputs = net(signals)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "  training_acc_arr[epoch] = (correct/total)\n",
        "  print ('Training Accuracy: %.5f' % training_acc_arr[epoch])\n",
        "  \n",
        "  \n",
        "  # Testing accuracy\n",
        "  for subject in range(9):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for signals, labels in test_loader[str(subject+1)]:\n",
        "      signals = signals.type(torch.FloatTensor)\n",
        "      signals = Variable(signals)\n",
        "      labels = torch.squeeze(labels.type(torch.LongTensor))\n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "        signals = signals.cuda()\n",
        "        labels = labels.cuda()\n",
        "      outputs = net(signals)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum()\n",
        "    testing_acc_arr[subject, epoch] = (correct/total)\n",
        "  print ('Testing Accuracy: ' + str(testing_acc_arr[:, epoch]))\n",
        "  print ('Testing Accuracy Average: %.5f' % np.average(testing_acc_arr[:, epoch]))\n",
        "  '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2JwUcaseoXXV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Print MATLAB Format"
      ]
    },
    {
      "metadata": {
        "id": "0nSce2gzkAZa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Print Loss\n",
        "#print('Loss = [', end='')\n",
        "#for lossval in np.nditer(loss_arr):\n",
        "#  print('%.5f, ' % lossval, end='')\n",
        "#print('];')\n",
        "\n",
        "# Print Training Accuracy\n",
        "print('Training_Accuracy = [', end='')\n",
        "for acc in np.nditer(training_acc_arr):\n",
        "  print('%.5f, ' % acc, end='')\n",
        "print('];')\n",
        "\n",
        "# Print Testing Accuracy\n",
        "print('Testing_Accuracy = [', end='')\n",
        "for subject in range(9):\n",
        "  for acc in np.nditer(testing_acc_arr[subject, :]):\n",
        "    print('%.5f, ' % acc, end='')\n",
        "  print('; ', end='')\n",
        "print('];')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}